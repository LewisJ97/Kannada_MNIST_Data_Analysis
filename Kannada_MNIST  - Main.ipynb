{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvK4EcyrZ_0A"
   },
   "source": [
    "# Kannada MNIST Classification Problem - Group S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cs-HZoXrbbVw"
   },
   "source": [
    "# Team Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJem0ci3beKw"
   },
   "source": [
    "1. Stewart Anderson - 201994184\n",
    "2. Lewis Johnston - 201979646\n",
    "3. Scott Davies - 201988979\n",
    "4. Annie Benzie - 201971007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otWs6J-1T-le"
   },
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMsso5NoUEIn"
   },
   "source": [
    "The Kaggle dataset that we will be using is the Kannada MNIST dataset which consists of 70,000 images of digits (60,000 for training and 10,000 for testing). Furthermore, every image in the dataset is labelled with it's corresponding digit. The digits range from 0 to 9 and have been handwritten by volunteers in India. The language of Kannada is one of 22 languages in India and is the official language of the Karnataka state. \n",
    "\n",
    "With respect to the Kannada MNIST dataset we are using, there are only 3 variables: Id, Label and Pixels. However, there are 786 columns due to these pixels. Each image contains 784 features because an image is represented by 28 x 28 pixels. Therefore, each feature is a representation of a single pixels intensity, ranging from 0 (white) to 255 (black).\n",
    "\n",
    "The main aim of this assignment is to use machine learning in the form of deep neural networks (DNN) to be able to classify each digit in the test dataset correctly. Firstly, we tried to implement an original artificial neural network (ANN) and then moved to more complex models in the form of convolutional neural networks (CNN) and convolutional recurrent neural networks (CRNN).\n",
    "\n",
    "With reference to the CNN model, CNN's are known for performing very well in image analysis and classification and so choosing to implement this method was an obvious choice. In addition, the CRNN was also utilised to determine if any benefits could be obtained from the Recurrent Neural Network (RNN) architecture situated at the end of the model. RNN models are better suited to sentiment analysis, however, there has been extensive work carried out using the combination of these two prominent networks. As a result, we wanted to investigate if a mixed model could be utilised for the image classification of the Kannada MNIST dataset, and compare it to the obvious choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbEd5XZDk1Yu"
   },
   "source": [
    "# 2. Retrieving Datasets from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYvR4PiTtjDy"
   },
   "source": [
    "**NB**: If the Kannada MNIST training and test sets are already on the system then there is no need for section 2. Therefore, proceed to section 3 where relevant packages are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "RnKkT5BLeWE0",
    "outputId": "ad5f2cda-daae-47a3-81a3-b271791034b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-00e36f8f-d29f-43fa-ab19-5b6e32077cd0\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-00e36f8f-d29f-43fa-ab19-5b6e32077cd0\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle (1).json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"stewarta96\",\"key\":\"9c9b4a7a39fb128a98c63dd47e3e5350\"}'}"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files \n",
    "files.upload() # Uploading the files from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7rUqxgnfLmP"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/kaggle.json\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ghHKEcofgO9e",
    "outputId": "16476266-b236-4e26-d192-b2ac65caf91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "training.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    " ## Retrieving the training and test datasets from the Kaggle competition page\n",
    "\n",
    "!kaggle competitions download -c cs98x-kannada-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2kTrah5btfe"
   },
   "source": [
    "# 3. Importing Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "7NQvz_qwaFgp",
    "outputId": "93b175fc-3373-4729-8eb0-72f853bf4a45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
      "You set: `1.x # Certain aspects will not run in tensorflow 2.x so this will revert back to 1.x`. This will be interpreted as: `1.x`.\n",
      "\n",
      "\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        Importing Packages and Libraries\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "import numpy as np # Import the numpy package for working with arrays\n",
    "import pandas as pd # Import the pandas package for working with dataframes\n",
    "import matplotlib.pyplot as plt # Import the matplotlib package for any relevant plots we wish to visualise\n",
    "import seaborn as sns # Import the seaborn package for data visualisation\n",
    "\n",
    "\n",
    "%tensorflow_version 1.x # Certain aspects will not run in tensorflow 2.x so this will revert back to 1.x\n",
    "import tensorflow as tf # Import tensorflow for working with deep neural networks\n",
    "from tensorflow import keras # Keras is the essential API from tensorflow to work with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hLBFfymZbzKh"
   },
   "source": [
    "# 4. Importing and Viewing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS2uIR1hmDeh"
   },
   "source": [
    "Once the essential libraries are imported above, we will now investigate the data we will be working on. As can be seen below, the Kannada MNIST dataset has already been separated into a training and test set. The shapes of both datasets have been given to show that the data has been imported correctly. As it is clearly shown, the test dataset has a column missing (\"label\") which should be the case as we are trying to predict these digit labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqhcDo4daW7C"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "        Importing Kannada MNIST Datasets (Training and Testing)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "mnist_train = pd.read_csv(\"/content/training.csv.zip\", low_memory=False) # Importing the spotify training dataset\n",
    "mnist_test = pd.read_csv(\"/content/test.csv.zip\", low_memory=False) # Importing the spotify test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_CObfpUAcW9a",
    "outputId": "322cd381-d95e-4a49-90b0-760a30b3d29e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 786)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.shape # Determining the size of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZZM6w85MjmYa",
    "outputId": "4cc9de1f-ca48-44bf-a9ff-3fc6cb45d773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.shape # Determining the size of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "7P1XMtugjrCU",
    "outputId": "5419ae6d-64d5-43a3-d972-b8361677a843"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  pixel0  pixel1  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0   1      0       0       0  ...         0         0         0         0\n",
       "1   2      1       0       0  ...         0         0         0         0\n",
       "2   3      2       0       0  ...         0         0         0         0\n",
       "3   4      3       0       0  ...         0         0         0         0\n",
       "4   5      4       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head() # Allows us to visualise the first five values for each attribute in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "qpI8EiOzllMX",
    "outputId": "2b5b2cbe-d846-40c3-da06-671a369801ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30000.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.075933</td>\n",
       "      <td>0.115883</td>\n",
       "      <td>0.176117</td>\n",
       "      <td>0.24455</td>\n",
       "      <td>0.222183</td>\n",
       "      <td>0.205267</td>\n",
       "      <td>0.129350</td>\n",
       "      <td>0.051617</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.053050</td>\n",
       "      <td>0.142250</td>\n",
       "      <td>0.286950</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927767</td>\n",
       "      <td>0.571633</td>\n",
       "      <td>0.469783</td>\n",
       "      <td>0.525783</td>\n",
       "      <td>0.370483</td>\n",
       "      <td>0.278017</td>\n",
       "      <td>0.144767</td>\n",
       "      <td>0.056617</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>0.013667</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.145167</td>\n",
       "      <td>0.215550</td>\n",
       "      <td>0.362900</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.415833</td>\n",
       "      <td>0.424733</td>\n",
       "      <td>0.405717</td>\n",
       "      <td>0.303267</td>\n",
       "      <td>0.123933</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.02570</td>\n",
       "      <td>0.015617</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17320.652413</td>\n",
       "      <td>2.872305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820579</td>\n",
       "      <td>0.661362</td>\n",
       "      <td>1.474271</td>\n",
       "      <td>2.700491</td>\n",
       "      <td>2.918309</td>\n",
       "      <td>3.993023</td>\n",
       "      <td>4.795036</td>\n",
       "      <td>5.874145</td>\n",
       "      <td>7.06010</td>\n",
       "      <td>6.652400</td>\n",
       "      <td>6.195649</td>\n",
       "      <td>5.053904</td>\n",
       "      <td>3.016660</td>\n",
       "      <td>2.088539</td>\n",
       "      <td>1.128635</td>\n",
       "      <td>0.938511</td>\n",
       "      <td>0.780784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820579</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>0.854689</td>\n",
       "      <td>3.512156</td>\n",
       "      <td>5.652343</td>\n",
       "      <td>7.745724</td>\n",
       "      <td>11.982185</td>\n",
       "      <td>...</td>\n",
       "      <td>13.285810</td>\n",
       "      <td>10.345211</td>\n",
       "      <td>9.184474</td>\n",
       "      <td>10.524802</td>\n",
       "      <td>8.894604</td>\n",
       "      <td>7.845722</td>\n",
       "      <td>5.752243</td>\n",
       "      <td>3.650589</td>\n",
       "      <td>2.387222</td>\n",
       "      <td>1.673836</td>\n",
       "      <td>1.177785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.472231</td>\n",
       "      <td>3.499396</td>\n",
       "      <td>5.680598</td>\n",
       "      <td>6.666483</td>\n",
       "      <td>8.808337</td>\n",
       "      <td>9.385912</td>\n",
       "      <td>9.496864</td>\n",
       "      <td>9.584616</td>\n",
       "      <td>9.389786</td>\n",
       "      <td>7.937053</td>\n",
       "      <td>4.885612</td>\n",
       "      <td>3.179446</td>\n",
       "      <td>1.650426</td>\n",
       "      <td>1.788061</td>\n",
       "      <td>1.659641</td>\n",
       "      <td>2.21439</td>\n",
       "      <td>1.920868</td>\n",
       "      <td>1.225551</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15000.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30000.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45000.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label  ...      pixel782  pixel783\n",
       "count  60000.000000  60000.000000  ...  60000.000000   60000.0\n",
       "mean   30000.500000      4.500000  ...      0.002717       0.0\n",
       "std    17320.652413      2.872305  ...      0.665445       0.0\n",
       "min        1.000000      0.000000  ...      0.000000       0.0\n",
       "25%    15000.750000      2.000000  ...      0.000000       0.0\n",
       "50%    30000.500000      4.500000  ...      0.000000       0.0\n",
       "75%    45000.250000      7.000000  ...      0.000000       0.0\n",
       "max    60000.000000      9.000000  ...    163.000000       0.0\n",
       "\n",
       "[8 rows x 786 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.describe() # Gives a summary of statistics (count, mean, standard deviation etc) of the training set attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "xQIk_XPXmEiS",
    "outputId": "d619eada-2a7d-4f17-a427-a0238d831ab0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0  60001       0       0       0  ...         0         0         0         0\n",
       "1  60002       0       0       0  ...         0         0         0         0\n",
       "2  60003       0       0       0  ...         0         0         0         0\n",
       "3  60004       0       0       0  ...         0         0         0         0\n",
       "4  60005       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.head() # Allows us to visualise the first five values for each attribute in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImKljS7UqVA2"
   },
   "source": [
    "# 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqIB3sx22uwm"
   },
   "source": [
    "**5.1 Visualising the Distribution of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "nJmJU6NzqeIb",
    "outputId": "75c78358-524c-4595-d658-9052306fc380"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVErySIiImolWURERK0ki4iIqPX/Aa7EpFZhgJ22AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_of_labels = mnist_train.label.value_counts()\n",
    "sns.barplot(num_of_labels.index, num_of_labels)\n",
    "\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Frequency of Each Label\")\n",
    "plt.title(\"Distribution of Labels in the Kannada MNIST Dataset\")\n",
    "\n",
    "num = num_of_labels.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jP_UdLnSxFWy"
   },
   "source": [
    "Upon examination of the bar chart, it can be seen that all 10 digits have an evenly split frequency of occurences in the training dataset. As a result, the data can be described as being homogeneously distributed. However, if the data was somewhat skewed and imbalanced, then we could have applied two techniques to combat this:\n",
    "\n",
    "1. Data augmentation could have been used to provide more data for labels which had a low frequency of occurences.\n",
    "2. As the Kannada MNIST dataset is relatively large, we could have simply dropped data from the labels with a high frequency of occurences.\n",
    "\n",
    "As you can imagine, both of these techniques involve striking a balance on all 10 digit labels. This would then provide the training data with a low bias, which is what we would be aiming for if this needed to be carried out.\n",
    "\n",
    "**NB**: It is worth noting that data augmentation was still carried out to improve the CNN and CRNN models during this investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lfJJ1EG20SA"
   },
   "source": [
    "**5.2 Visualising Images of Handwritten Digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "ZVuzwvx9qggE",
    "outputId": "c240201c-a9e7-45d7-c780-49b5614597eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualisation of the digit 2 in Kannada Style\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0kQdiAJwg4kQdiBJAg7kARhB5L4Fxw0BxQvEeBfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = 2\n",
    "pixels = mnist_train.iloc[digit, 2:].values.reshape(28,28)\n",
    "print(\"Visualisation of the digit \" + str(digit) + \" in Kannada Style\")\n",
    "plt.imshow(pixels, cmap = plt.get_cmap(\"gray\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DoukZOQZCKBI"
   },
   "source": [
    "As we are using a variant of the original MNIST dataset, we believed it was beneficial to include an image of one of the digits. By referring to the image of the single handwritten digit above, it is clear to see that these digits are difficult to classify. Therefore, this shows the complexity of the Kannada MNIST dataset and is the reason why DNN's are used for machine learning.\n",
    "\n",
    "**NB**: To change the digit from \"2\" to any other digit between 0 and 9, we would simply change the value of the variable \"digit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pB6aepb9LbXZ"
   },
   "source": [
    "# 6. Preparing the Data for Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWVaonAAVN3d"
   },
   "source": [
    "Firstly, we have separated the training data into features (mnist_train) and labels (mnist_labels). We have also created a new test dataset with the \"id\" column removed (mnist_test_new). In the next 3 sub-sections, we completed our preparation of our training dataset by carrying out the following:\n",
    "\n",
    "1. Reshaping the Training and Testing Datasets\n",
    "2. One-Hot-Encoding of Training Label Values\n",
    "3. Normalisation of the Training Data\n",
    "4. Training-Validation set split (Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ERPqPseLj5d"
   },
   "source": [
    "**6.1 Separating the Datasets into Features and Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Psdd8t2dsBiS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Separating the training data into data and labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "mnist_labels = mnist_train[\"label\"].copy() # Creating a labels variable for the 'label' attribute\n",
    "\n",
    "mnist_train = mnist_train.drop([\"id\", \"label\"], axis=1) # Creating a new dataset with the id and target variables removed\n",
    "mnist_test_new = mnist_test.drop(\"id\", axis=1) # Creating a new dataset with the id variable removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atQL2_FHmIUj"
   },
   "outputs": [],
   "source": [
    "mnist_train=mnist_train.iloc[:,:].values\n",
    "mnist_labels=mnist_labels.iloc[:,].values\n",
    "\n",
    "mnist_test_new = mnist_test_new.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nbtigMnrG_cR"
   },
   "source": [
    "**6.2 Reshaping the Training and Testing Datasets for CNN and DCGAN** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3g8KasyLgGZZ"
   },
   "source": [
    "The original shape of the Kannada MNIST dataset, mnist_train, has the dimensions: 60,000 x 784. This flattened image data is still compatible for our original ANN. However, this is not quite the case for our CNN and CRNN models. The shape for both of these models needs to be converted to the dimensions: 60,000 x 28 x 28 x 1. The dimensions have to be changed because the images are created by 28 x 28 pixels, with a single colour channel (greyscale). \n",
    "\n",
    "**NB**: If we were working with the Kannada MNIST dataset consisting of coloured images, our training data shape would change to the following dimensions: 60,000 x 28 x 28 x 3. The colour channel will change from a \"1\" to a \"3\" as we would essentially be using the RGB (red, green, blue) colour channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73MOMk3UG_ut"
   },
   "outputs": [],
   "source": [
    "mnist_train_cnn = mnist_train.reshape(mnist_train.shape[0],28,28,1)\n",
    "mnist_test_new_cnn = mnist_test_new.reshape(mnist_test_new.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zAYicuYjj8FY",
    "outputId": "d107ad44-f741-4426-f6e2-a74aeb69d2a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uLWT5zEoj8As",
    "outputId": "7dfd9363-97d9-46bc-f6ae-bbb5be37a438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_new_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoY1cB7uDq2K"
   },
   "outputs": [],
   "source": [
    "mnist_train_crnn = mnist_train.reshape(mnist_train.shape[0],28,28,1)\n",
    "mnist_test_new_crnn = mnist_test_new.reshape(mnist_test_new.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OvxGR5evDrlY",
    "outputId": "585edfdc-a026-4757-ef37-75e772ed90b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_crnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w5FIeauyDr0F",
    "outputId": "35026fa4-38f4-4904-a9d1-c4a2a2a46be3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_new_crnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ea-dGEfcHfy2"
   },
   "source": [
    "**6.3 One-Hot-Encoding Of MNIST label Values** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKRzWd2WlQDA"
   },
   "source": [
    "With respect to all three of our models, we had to convert the labelled values to one-hot-encoding values. As the Kannada MNIST dataset provides numeric labels, this step was not essential as only categorical data is ineligible for our models to work. Having said that, one-hot-encoding allows us to categorize the labels, which allows our models to operate more effectively. For example, the digit label \"6\" would be categorized as: [0,0,0,0,0,0,1,0,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-l7nmK0HfMI"
   },
   "outputs": [],
   "source": [
    "mnist_labels = keras.utils.to_categorical(mnist_labels,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3NWLIu0HNqF"
   },
   "source": [
    "**6.4 Normalisation of the Training Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76F23SAjtVIi"
   },
   "source": [
    "Normalisation, from a statistics reference, is a method in which data values on different scales are adjusted to fit onto a notionally common scale. It is preferrable that we normalise our training data here as ANN's generally have small weight values, whereas, our inputs are relatively large. Therefore, training our models will be much slower if we do not normalise the data.\n",
    "\n",
    "For image processing applications such as this, generally the inputs are normalised to the scale 0-1. As shown below, this is done by dividing by 255.0. It is worth noting that as we are now working in the range 0-1, we need to make the division a floating point number, otherwise all inputs will be either a \"0\" or a \"1\". Furthermore, we are dividing the data by 255.0 because every pixel has an integer value between 0 (white) and 255 (black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeE-ANsqujoW"
   },
   "outputs": [],
   "source": [
    "mnist_train = mnist_train / 255.0 # Normalizing the training data for the original ANN\n",
    "mnist_train_cnn = mnist_train_cnn / 255.0 # Normalizing the training data for the CNN\n",
    "mnist_train_crnn = mnist_train_crnn / 255.0 # Normalizing the training data for the CRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7j_L2xjuyxV"
   },
   "source": [
    "**6.5 Training-Validation Set Split (Cross-Validation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U65Uv1ISu8tK"
   },
   "source": [
    "In order for our models to generalise well while training, we need to use cross-validation. This technique splits the training data into a new training set and a validation set. The validation set is needed to compare with the new training set to check specifically for overfitting. If the new training data has a much higher accuracy than the validation data, then overfitting is likely to be occuring in that model.\n",
    "\n",
    "In this Kaggle competition, the test dataset has been given without the digit labels for predictions. Therefore, the accuracy of the training data relative to the validation data mentioned above, is crucial in determining whether our models will have accurate test predictions before uploading onto Kaggle. For this task, we decided to give the training and validation data a split of 90:10, respectively. As the Kannada MNIST dataset has 60,000 training samples, we believed a 10% validation split was sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAH9XOQrxe-2"
   },
   "source": [
    "**6.5.1 Original ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pml8YjC02fTU"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Separating the data and labels into a validation set and a normal training set\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_valid, X_train = mnist_train[:6000], mnist_train[6000:]\n",
    "y_valid, y_train = mnist_labels[:6000], mnist_labels[6000:]\n",
    "\n",
    "## Means we have a 10% validation set and 90% training set\n",
    "\n",
    "X_test = mnist_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehNMZFTTxz3G"
   },
   "source": [
    "**6.5.2 CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVb2o_Qgx4RC"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Separating the data and labels into a validation set and a normal training set\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_valid_cnn, X_train_cnn = mnist_train_cnn[:6000], mnist_train_cnn[6000:]\n",
    "y_valid_cnn, y_train_cnn = mnist_labels[:6000], mnist_labels[6000:]\n",
    "\n",
    "## Means we have a 10% validation set and 90% training set\n",
    "\n",
    "X_test_cnn = mnist_test_new_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a4OjZHuqaPcA",
    "outputId": "b8a29d18-a394-4159-e186-57fd4a7f87d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yQKI15Gx4qy"
   },
   "source": [
    "**6.5.3 CRNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXujqD_Cx8gx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Separating the data and labels into a validation set and a normal training set\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_valid_crnn, X_train_crnn = mnist_train_crnn[:6000], mnist_train_crnn[6000:]\n",
    "y_valid_crnn, y_train_crnn = mnist_labels[:6000], mnist_labels[6000:]\n",
    "\n",
    "## Means we have a 10% validation set and 90% training set\n",
    "\n",
    "X_test_crnn = mnist_test_new_crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XEMJoGmQvUoD",
    "outputId": "11329d35-c9c1-47f7-81bd-b6b8e999d8e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_crnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eezMNlf3CrDR"
   },
   "source": [
    "# 7. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtZQlLDqCuTa"
   },
   "source": [
    "Data augmentation is essentially a regularisation technique to prevent overfitting of the data. This method artificially creates more training data samples by generating very similar variants of each training sample instance. To be able to carry out this process, we cannot simply add white noise to these samples. By referring to our code below, we can implement the following variations:\n",
    "\n",
    "1. Image rotation\n",
    "2. Shift in the width of an image\n",
    "3. Shift in the height of an image\n",
    "4. Shearing change of an image\n",
    "5. A zoomed in variant of an image\n",
    "6. Flipping an image horizontally\n",
    "\n",
    "From the 6 variations described above, the images should change their appearance slightly, giving us more training data to work with. Crucially, these transformations do not change a samples label, otherwise this could not be implemented. Moreover, earlier in this notebook we stated that the training data was homogeneously distributed. However, despite this, CNN  and CRNN models require data augmentation to improve the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x1k5DOy-Culr",
    "outputId": "0ae2f956-c266-4df1-9087-76a83fc8002d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(rotation_range = 10, width_shift_range = 0.25, height_shift_range = 0.30,\n",
    "                               shear_range = 0.15, zoom_range = 0.30, horizontal_flip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J700Sy4bC10r"
   },
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmsKcERiPioI"
   },
   "source": [
    "# 8. Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJqK1cepv8Ty"
   },
   "source": [
    "The three neural network models we have decided to use for the Kannada MNIST classification problem are:\n",
    "\n",
    "1. An original ANN\n",
    "2. A CNN\n",
    "3. A CRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kc3ebZCDPxve"
   },
   "source": [
    "# 8.1 Original Artifical Neural Networks (ANNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lchdLHFhHRBc"
   },
   "source": [
    "All three of our neural network models use the Sequential model. The reason for this is that it is the simplest model that can be implemented using keras and is composed of a single stack of layers connected sequentially. With respect to our original ANN model, we decided that this simple model would start us off for two reasons:\n",
    "\n",
    "1. To make sure that our training data was fitting correctly to the model and that our code was also working effectively.\n",
    "2. To determine a baseline accuracy which would then allow us to create two more complex models to achieve higher accuracy on the Kannada MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N91fvtUVhOkQ"
   },
   "source": [
    "**8.1.1 Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "UUxKCv2Ho2OK",
    "outputId": "72518c71-77bb-46ab-bac8-0c991182aabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape = [784]))\n",
    "model.add(keras.layers.Dropout(rate=0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dropout(rate=0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dropout(rate=0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKftB4qgi0hl"
   },
   "source": [
    "For our original ANN model architecture, we decided to keep the training data as a flattened input shape of 60,000 x 784. We also used two hidden layers which incorporated the \"ELU\" activation function. The exponential linear unit (ELU) was proposed in 2015 and was said to have outperformed all variants of the rectifying linear unit (ReLU). There were certain differences between these two activation functions that stand out, one of which being that the ELU has a non-zero gradient at z < 0, which eliminates the problem regarding dead neurons.\n",
    "\n",
    "Two other key factors in our architecture here, and which have also been applied to our other two models, is that of dropout and batch normalisation. In terms of regularisation techniques, dropout has perhaps been the most common since it was first introduced back in 2012. The process simply gives each neuron a probability (0.3 in our case) of being temporarily \"dropped out\" from training. This is extremely effective in DNN architecture because there are so many neurons which have the potential to overfit the data. With regards now to batch normalisation, this was first introduced in 2015 and this addressed the problem of vanishing/exploding gradients reappearing during model training. The process simply normalises each input and introduces two new parameter vectors; one for shifting the data and one for scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "_ByQ1IV5gmmp",
    "outputId": "c8088fa9-1c1c-435a-a7f7-11c7b63bec78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48gbszgWIDX-"
   },
   "source": [
    "The \"summary()\" method above is an excellent way to view how the data is passed through the network from the input layer to the output layer. This will become more beneficial when analysing our two complex models as it is difficult to refer to the code. Furthermore, this method allows us to distinguish how many parameters are being used in our model.\n",
    "\n",
    "It is worth noting that the \"Dense\" layers associated with the Sequential models inherit many parameters. For example, there are 235,500 parameters in the first hidden layer alone! This is because there are 784 x 300 connection weights and 300 bias terms which are carried forward as inputs to the next layer. The problem with having so many parameters is the risk of overfitting the models, however, as discussed already, dropout is key to limiting this phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "w5HmAoZ9gmkk",
    "outputId": "0704d03b-f6a4-44fc-c608-c91ca84011a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dropout at 0x7f9587b59a90>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f9587b59f98>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f9587b6c278>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f9587b59dd8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f9587a82f60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f9587a82dd8>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f9587ab7ef0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f9587b234a8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f95879ecd68>]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZhI6PDshU03"
   },
   "source": [
    "**8.1.2 Compiling the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yiUolCihbym"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", # as we are using one-hot encode for the label data\n",
    "              optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              #optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VG4hZRhZKcW6"
   },
   "source": [
    "We will compile all three models using the exact same loss function, optimiser and metric. In terms of the loss function, we have used categorical cross-entropy as this is  a classification problem. Moreover, we don't use sparse categorical cross-entropy as we have one-hot encoded our labels. In regards to the optimiser, stochastic gradient descent is perhaps the most common. However, for our particular dataset, the two most effective that were tried were \"Nadam\" and \"RMSprop\", with \"Nadam\" giving slightly better results.\n",
    "\n",
    "The Nadam optimiser we have decided to use is a variation of adaptive moment estimation (Adam) and Nesterov accelerated gradient (NAG). The Adam variant is essential for moment optimisation. On the other hand, the NAG variant measures the cost function gradient slightly ahead of it's local position. This allows the momentum vector to be tweaked to it's optimal direction. Therefore, we believe Nadam was the most viable optimiser to use for this specific investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LjfFNe_Pi3-s"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Callbacks\n",
    "\"\"\"\n",
    "\n",
    "#Learning Rate Scheduler/Reduction\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = \"val_loss\", patience=20, verbose=1, factor = 0.005, min_lr = 0.00001)\n",
    "\n",
    "early_stopping_lr = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esvF-d6vwsgC"
   },
   "source": [
    "Above we have implemented callbacks. These are functions that are utilised during the training phase of our model and can aid with making sure our model is continually learning and improving. The learning rate scheduler has been built to alter the learning rate when there is an insignificant improvement in the validation loss of the model for 20 epochs in a row. The parameter \"factor\" refers to the amount by which the learning rate will be decreased (0.005 in our case).\n",
    "\n",
    "Similarly, the early stopping function evaluates the model based on performance and halts the model if the validation loss has not improved for 20 consecutive epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oltyB1syjFQA"
   },
   "source": [
    "**8.1.3 Fitting the Model to the Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ew_melQdk9hD",
    "outputId": "d3611ccf-b568-42b6-e333-c7db705f215f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "54000/54000 [==============================] - 12s 231us/sample - loss: 0.3759 - acc: 0.8838 - val_loss: 0.2449 - val_acc: 0.9353\n",
      "Epoch 2/100\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.2354 - acc: 0.9266 - val_loss: 0.2370 - val_acc: 0.9412\n",
      "Epoch 3/100\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.1929 - acc: 0.9408 - val_loss: 0.2117 - val_acc: 0.9493\n",
      "Epoch 4/100\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.1662 - acc: 0.9479 - val_loss: 0.2039 - val_acc: 0.9533\n",
      "Epoch 5/100\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.1511 - acc: 0.9530 - val_loss: 0.2072 - val_acc: 0.9538\n",
      "Epoch 6/100\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.1372 - acc: 0.9565 - val_loss: 0.2073 - val_acc: 0.9568\n",
      "Epoch 7/100\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.1290 - acc: 0.9586 - val_loss: 0.1943 - val_acc: 0.9593\n",
      "Epoch 8/100\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.1222 - acc: 0.9614 - val_loss: 0.2010 - val_acc: 0.9562\n",
      "Epoch 9/100\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.1163 - acc: 0.9629 - val_loss: 0.2148 - val_acc: 0.9545\n",
      "Epoch 10/100\n",
      "54000/54000 [==============================] - 12s 227us/sample - loss: 0.1110 - acc: 0.9647 - val_loss: 0.1980 - val_acc: 0.9617\n",
      "Epoch 11/100\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.1087 - acc: 0.9651 - val_loss: 0.2037 - val_acc: 0.9623\n",
      "Epoch 12/100\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.1040 - acc: 0.9668 - val_loss: 0.1929 - val_acc: 0.9633\n",
      "Epoch 13/100\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.1007 - acc: 0.9684 - val_loss: 0.1999 - val_acc: 0.9622\n",
      "Epoch 14/100\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.0965 - acc: 0.9689 - val_loss: 0.2073 - val_acc: 0.9585\n",
      "Epoch 15/100\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.0946 - acc: 0.9687 - val_loss: 0.2060 - val_acc: 0.9602\n",
      "Epoch 16/100\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.0914 - acc: 0.9706 - val_loss: 0.2069 - val_acc: 0.9590\n",
      "Epoch 17/100\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.0927 - acc: 0.9703 - val_loss: 0.1995 - val_acc: 0.9622\n",
      "Epoch 18/100\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.0886 - acc: 0.9714 - val_loss: 0.1951 - val_acc: 0.9648\n",
      "Epoch 19/100\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.0828 - acc: 0.9725 - val_loss: 0.2155 - val_acc: 0.9618\n",
      "Epoch 20/100\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.0854 - acc: 0.9727 - val_loss: 0.1911 - val_acc: 0.9645\n",
      "Epoch 21/100\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.0846 - acc: 0.9718 - val_loss: 0.1973 - val_acc: 0.9628\n",
      "Epoch 22/100\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.0852 - acc: 0.9723 - val_loss: 0.2047 - val_acc: 0.9648\n",
      "Epoch 23/100\n",
      "54000/54000 [==============================] - 11s 210us/sample - loss: 0.0819 - acc: 0.9738 - val_loss: 0.2037 - val_acc: 0.9665\n",
      "Epoch 24/100\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.0790 - acc: 0.9744 - val_loss: 0.2096 - val_acc: 0.9642\n",
      "Epoch 25/100\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.0803 - acc: 0.9741 - val_loss: 0.2097 - val_acc: 0.9628\n",
      "Epoch 26/100\n",
      "54000/54000 [==============================] - 12s 215us/sample - loss: 0.0782 - acc: 0.9740 - val_loss: 0.2284 - val_acc: 0.9615\n",
      "Epoch 27/100\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.0788 - acc: 0.9744 - val_loss: 0.2056 - val_acc: 0.9638\n",
      "Epoch 28/100\n",
      "54000/54000 [==============================] - 12s 230us/sample - loss: 0.0755 - acc: 0.9751 - val_loss: 0.2298 - val_acc: 0.9625\n",
      "Epoch 29/100\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.0732 - acc: 0.9765 - val_loss: 0.2160 - val_acc: 0.9633\n",
      "Epoch 30/100\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.0733 - acc: 0.9767 - val_loss: 0.2118 - val_acc: 0.9635\n",
      "Epoch 31/100\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.0747 - acc: 0.9754 - val_loss: 0.2192 - val_acc: 0.9603\n",
      "Epoch 32/100\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.0714 - acc: 0.9764 - val_loss: 0.2119 - val_acc: 0.9653\n",
      "Epoch 33/100\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.0740 - acc: 0.9758 - val_loss: 0.2017 - val_acc: 0.9650\n",
      "Epoch 34/100\n",
      "54000/54000 [==============================] - 11s 213us/sample - loss: 0.0702 - acc: 0.9772 - val_loss: 0.2158 - val_acc: 0.9662\n",
      "Epoch 35/100\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.0709 - acc: 0.9770 - val_loss: 0.2146 - val_acc: 0.9650\n",
      "Epoch 36/100\n",
      "54000/54000 [==============================] - 13s 241us/sample - loss: 0.0699 - acc: 0.9767 - val_loss: 0.2189 - val_acc: 0.9632\n",
      "Epoch 37/100\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.0726 - acc: 0.9768 - val_loss: 0.2175 - val_acc: 0.9657\n",
      "Epoch 38/100\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.0725 - acc: 0.9768 - val_loss: 0.2332 - val_acc: 0.9633\n",
      "Epoch 39/100\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.0694 - acc: 0.9776 - val_loss: 0.2229 - val_acc: 0.9628\n",
      "Epoch 40/100\n",
      "53792/54000 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9768\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.0706 - acc: 0.9768 - val_loss: 0.2320 - val_acc: 0.9637\n",
      "Epoch 00040: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), \n",
    "                    callbacks=[learning_rate_reduction, early_stopping_lr], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I8xzvc0ovt3"
   },
   "source": [
    "**8.1.4 Evaluating the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "P3Afe3RdoY5C",
    "outputId": "8c92029f-5261-43ee-bae4-c9812f492b86"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt4T+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMTbJvlFCpUp"
   },
   "source": [
    "From the plot above, this provides clear details of the normal training loss and accuracy, aswell as the cross-validation training loss and accuracy. In terms of the accuracy, the normal model begins at 0.8838, while the cross-validation model begins at 0.9353. This is not particularly surprising given there is a 90:10 split, respectively. After approximately 5 epochs, both models achieve a consistent accuracy until the training is stopped due to the early stopping callback at 40 epochs.\n",
    "\n",
    "If we now take our interest towards the losses achieved in both models, these are much more interesting. The loss achieved by the normal model was 0.3759 at the first epoch, compared to 0.2449 from the cross-validation model. The interesting view after this is that the loss of the normal model continues to decrease in short amounts. On the other hand, the cross-validation model loss remains close to the same value after 5 epochs, but fluctuates around on more than one occasion. Furthermore, as the normal model loss is much less than the cross-validation model loss, it is safe to confirm that overfitting is occuring during the training of this model.\n",
    "\n",
    "**NB**: The accuracy and loss values follow a similar pattern for our two other models. However, the loss curves are much closer together as overfitting is not significantly affecting these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z3gxiUYw8reG",
    "outputId": "cd247fd4-588e-4563-ee34-03261e55d82f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred = model.predict_classes(X_train)\n",
    "model_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fm8K5z4CDA0i",
    "outputId": "d5e70ec9-abe9-423f-8f4a-f036ee901b73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_cv = model.predict_classes(X_valid)\n",
    "model_pred_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zdAbSDhEBsfV",
    "outputId": "3ff24693-1e48-41e0-893e-e91917c225fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert the training labels back to single digits rather than one hot encoding\n",
    "\n",
    "rounded_labels=np.argmax(y_train, axis=1)\n",
    "rounded_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S2NKuEfdDV_I",
    "outputId": "8ac12826-9bef-4c84-89d3-05e9ba5d36eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert the cross-val labels back to single digits rather than one hot encoding\n",
    "\n",
    "rounded_labels_cv=np.argmax(y_valid, axis=1)\n",
    "rounded_labels_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RkPRfKrm-VD-",
    "outputId": "8c25ec77-69d4-4dfd-c8ad-022a2473b92f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9941111111111111\n",
      "Cross-Val Accuracy: 0.9636666666666667\n"
     ]
    }
   ],
   "source": [
    "## Comparing accuracy scores from training data and cross-val data\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_acc = accuracy_score(rounded_labels, model_pred)\n",
    "model_acc_cv = accuracy_score(rounded_labels_cv, model_pred_cv)\n",
    "\n",
    "print(\"Training Accuracy:\", model_acc)\n",
    "print(\"Cross-Val Accuracy:\", model_acc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "-w79p3lmHMhC",
    "outputId": "b5245401-e9bf-42b8-bab4-d72bbc056ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5347,   47,    0,    2,    1,    0,    2,    0,    0,    1],\n",
       "       [   4, 5388,    0,    1,    0,    0,    3,    2,    0,    2],\n",
       "       [   2,    5, 5384,    0,    0,    0,    1,    1,    1,    6],\n",
       "       [   2,    0,    0, 5376,    0,    1,    2,   16,    0,    3],\n",
       "       [   3,    0,    0,    0, 5390,    1,    3,    0,    0,    3],\n",
       "       [   1,   17,    2,    2,    9, 5359,    5,    2,    3,    0],\n",
       "       [   1,    0,    0,    1,    1,    0, 5318,   67,    0,   12],\n",
       "       [   2,    1,    0,    3,    0,    0,   21, 5373,    0,    0],\n",
       "       [   7,    1,    0,    1,    2,    0,    2,    0, 5375,   12],\n",
       "       [   4,    1,    0,    0,    2,    0,   18,    2,    1, 5372]])"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Implementing confusion matrix to evaluate the classified digits in the training data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_cm = confusion_matrix(rounded_labels, model_pred)\n",
    "model_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "-XxjdyYFJs-d",
    "outputId": "18074bac-1cea-4218-86f2-5ba429778091"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEcCAYAAAAPyOtuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(model_cm, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix Image Representation\", x=0.5, y=1)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "suTPl46cKHE1",
    "outputId": "ee5e4b98-f02d-4cb6-f387-9e3b687d737a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAEcCAYAAACrolO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njjgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Now lets check where the errors are occuring most\n",
    "\n",
    "row_sums = model_cm.sum(axis=1, keepdims=True)\n",
    "norm_model_cm = model_cm / row_sums\n",
    "\n",
    "## Filling the leading diagonal with zeros to only keep the errors and plot results\n",
    "\n",
    "np.fill_diagonal(norm_model_cm, 0)\n",
    "plt.matshow(norm_model_cm, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix Image Representation of Errors\", x=0.5, y=1)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWw_H1yxEgaI"
   },
   "source": [
    "In terms of the first confusion matrix, this is a visualisation of how many of each digit was classified correctly. Unfortunately, due to the vast size of the training dataset, this does not give us much information as to which digits are being classified incorrectly. However, this is the reason the second confusion matrix has been drawn upon. This evidently points to which digits have been classified incorrectly the most often. In the case of the original ANN, the model seems to be classifying the digit \"6\" with the digit \"7\" more often than any other digit. Furthermore, the digit \"0\" is being classified as the digit \"1\". This may seem unusual, however, let us not forget this is the Kannada version of MNIST and that the labelled digits look very different to our native digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VZqMyxLeEyLD",
    "outputId": "4aef018a-f4b1-4755-83a5-e5fd57007987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision: 0.9941381881598715\n",
      "Training Recall: 0.9941111111111111\n"
     ]
    }
   ],
   "source": [
    "## Comparing precision and recall scores from training data\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Training Precision:\", precision_score(rounded_labels, model_pred, average='weighted'))\n",
    "print(\"Training Recall:\", recall_score(rounded_labels, model_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LlvEDPdFdQb"
   },
   "source": [
    "The scores of precision and recall shown above are determined from the first confusion matrix. They are formulated by the following expressions: True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN). TP and TN are assigned when a digit is classified correctly as being that digit and not being that digit, respectively. On the other hand, FP and FN are assigned when a digit has been classified incorrectly as being that digit and not being that digit, respectively. In terms of precision, this can be defined as the accuracy of the positive predictions. Whereas, recall can be defined as the ratio of positive instances that have been correctly identified. Moreover, the formulas for both precision and recall are shown below:\n",
    "\n",
    "1. Precision = TP / TP + FP\n",
    "\n",
    "2. Recall = TP / TP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIgYLuhBdyk5"
   },
   "source": [
    "# 8.2 Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-aK4Ua5imwEu"
   },
   "source": [
    "**8.2.1 Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrHk21kUmIAI"
   },
   "outputs": [],
   "source": [
    "## Will use my CNN but use this to improve comments below this code\n",
    "\n",
    "model_cnn = keras.models.Sequential()\n",
    "model_cnn.add(keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model_cnn.add(keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n",
    "model_cnn.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_cnn.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model_cnn.add(keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "model_cnn.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model_cnn.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "model_cnn.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n",
    "model_cnn.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_cnn.add(keras.layers.BatchNormalization()) \n",
    "\n",
    "model_cnn.add(keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "model_cnn.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model_cnn.add(keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model_cnn.add(keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model_cnn.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_cnn.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model_cnn.add(keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2)))\n",
    "model_cnn.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model_cnn.add(keras.layers.Flatten())\n",
    "model_cnn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "model_cnn.add(keras.layers.LeakyReLU(alpha = 0.1)) \n",
    "model_cnn.add(keras.layers.Dropout(0.25))\n",
    "model_cnn.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEWE-_83mBg0"
   },
   "source": [
    "The architecture of our CNN consists of a convolutional layer with the input shape, followed by another convolutional layer. These convolutional layers in a network systematically apply learned filters to input images in order to create feature maps that summarize the presence of those features in the input. This stacking of convolutional layers allows for a hierarchical decomposition of the input. \n",
    "\n",
    "The convolutional layers are then followed by the addition of a layer that utilises the LeakyRelu activation function. This was found to give a better score on the Kaggle competition than simply utilising the relu activation function and also had a slight improvement in training time. This improvement could be down to the fact that it fixes the â€œdying ReLUâ€ problem, as it does not have zero-slope parts. Use of this activation function therefore mitigates the chance of a vanishing gradient and can help make sure our model is continually learning. \n",
    "\n",
    "The next step of our CNN is the implementation of a max pooling layer. The pooling layer works by analysing each feature map separately to create a new set of the same number of pooled feature maps. This downsamples the image sizes/feature maps, thus reducing the number of parameters and calculations in the network. This improves the efficiency of the network and avoids over-learning. In our model the pooling layers downsample the feature maps to a size of 2 x 2 pixels, with a stride of 2. This means it reduces the image size from 28 x 28 to 14 x 14. The max pooling function simply calculates the maximum value for each patch of the feature map. \n",
    "\n",
    "A dropout layer is then added after each pooling layer, these layers drop nodes during traning and is a useful technique to reduce the chance of overfitting and improve generalisation error, as discussed previously.\n",
    "\n",
    "The combination of the above architecture is repeated three times until we implement the fully connected and output layers. The flatten operation and fully connected layers interpret the features and an output layer with a softmax activation for ten-class predictions is implemented. The final dense/fully connected layer outputs 10 (0 - 9) results in which these results of the convolutional layers are fed through the neural layers to generate a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "-VXGaWodWax0",
    "outputId": "a55dc5c4-45d9-49cb-f82b-b0805a784be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               344192    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 632,810\n",
      "Trainable params: 632,362\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "pWSjLEPQddwe",
    "outputId": "9113f6ac-a77e-40bb-d318-63ece9c40a3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f952a36da20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f952a36db70>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f952a36db38>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f952a3741d0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f952a376fd0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f952a376ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f952a3743c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f952a13ac50>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f952a116a20>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f952a37a470>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f952a12bbe0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f952a0e1390>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f952a14bdd8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f952a1403c8>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f952a0fe470>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f952a14be10>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f952a0903c8>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f952a0c0f28>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7f952a1404a8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f952a0667f0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f952a06fe80>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f952a0f4fd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f952a05ed68>]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSFn777jeF8d"
   },
   "source": [
    "**8.2.2 Compiling the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WRVUeoPdzBX"
   },
   "outputs": [],
   "source": [
    "model_cnn.compile(loss = \"categorical_crossentropy\", # as we are using one-hot encode for the label data\n",
    "              optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              #optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pu3HH-ieac2"
   },
   "source": [
    "**8.2.3 Fitting the Model to the Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B7hSgnmaePeV",
    "outputId": "98d893eb-77eb-46fe-b563-fafaf6841c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.8403 - acc: 0.7150Epoch 1/100\n",
      "211/211 [==============================] - 23s 109ms/step - loss: 0.8378 - acc: 0.7159 - val_loss: 7.0662 - val_acc: 0.1007\n",
      "Epoch 2/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.2467 - acc: 0.9189Epoch 1/100\n",
      "211/211 [==============================] - 18s 87ms/step - loss: 0.2460 - acc: 0.9191 - val_loss: 1.2637 - val_acc: 0.6573\n",
      "Epoch 3/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9422Epoch 1/100\n",
      "211/211 [==============================] - 19s 90ms/step - loss: 0.1787 - acc: 0.9422 - val_loss: 0.1269 - val_acc: 0.9595\n",
      "Epoch 4/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9504Epoch 1/100\n",
      "211/211 [==============================] - 18s 87ms/step - loss: 0.1512 - acc: 0.9504 - val_loss: 0.0677 - val_acc: 0.9823\n",
      "Epoch 5/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9582Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.1297 - acc: 0.9581 - val_loss: 0.0600 - val_acc: 0.9845\n",
      "Epoch 6/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9592Epoch 1/100\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 0.1252 - acc: 0.9591 - val_loss: 0.0706 - val_acc: 0.9783\n",
      "Epoch 7/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9643Epoch 1/100\n",
      "211/211 [==============================] - 19s 90ms/step - loss: 0.1097 - acc: 0.9644 - val_loss: 0.0656 - val_acc: 0.9800\n",
      "Epoch 8/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9664Epoch 1/100\n",
      "211/211 [==============================] - 19s 91ms/step - loss: 0.1030 - acc: 0.9663 - val_loss: 0.0438 - val_acc: 0.9897\n",
      "Epoch 9/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9682Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.1011 - acc: 0.9683 - val_loss: 0.0343 - val_acc: 0.9913\n",
      "Epoch 10/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9689Epoch 1/100\n",
      "211/211 [==============================] - 19s 90ms/step - loss: 0.0963 - acc: 0.9688 - val_loss: 0.0737 - val_acc: 0.9797\n",
      "Epoch 11/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9712Epoch 1/100\n",
      "211/211 [==============================] - 19s 92ms/step - loss: 0.0883 - acc: 0.9713 - val_loss: 0.0845 - val_acc: 0.9783\n",
      "Epoch 12/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9711Epoch 1/100\n",
      "211/211 [==============================] - 19s 92ms/step - loss: 0.0900 - acc: 0.9711 - val_loss: 0.0492 - val_acc: 0.9913\n",
      "Epoch 13/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9732Epoch 1/100\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 0.0824 - acc: 0.9732 - val_loss: 0.0612 - val_acc: 0.9868\n",
      "Epoch 14/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9750Epoch 1/100\n",
      "211/211 [==============================] - 19s 90ms/step - loss: 0.0789 - acc: 0.9751 - val_loss: 0.0474 - val_acc: 0.9907\n",
      "Epoch 15/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9746Epoch 1/100\n",
      "211/211 [==============================] - 18s 87ms/step - loss: 0.0779 - acc: 0.9746 - val_loss: 0.0496 - val_acc: 0.9898\n",
      "Epoch 16/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9753Epoch 1/100\n",
      "211/211 [==============================] - 19s 91ms/step - loss: 0.0773 - acc: 0.9753 - val_loss: 0.0498 - val_acc: 0.9870\n",
      "Epoch 17/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9767Epoch 1/100\n",
      "211/211 [==============================] - 19s 88ms/step - loss: 0.0742 - acc: 0.9767 - val_loss: 0.0508 - val_acc: 0.9890\n",
      "Epoch 18/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9752Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.0753 - acc: 0.9752 - val_loss: 0.0483 - val_acc: 0.9893\n",
      "Epoch 19/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9758Epoch 1/100\n",
      "211/211 [==============================] - 19s 90ms/step - loss: 0.0730 - acc: 0.9758 - val_loss: 0.0396 - val_acc: 0.9925\n",
      "Epoch 20/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9772Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.0707 - acc: 0.9772 - val_loss: 0.0404 - val_acc: 0.9912\n",
      "Epoch 21/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9780Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.0669 - acc: 0.9779 - val_loss: 0.0511 - val_acc: 0.9835\n",
      "Epoch 22/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9783Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.0667 - acc: 0.9784 - val_loss: 0.0541 - val_acc: 0.9870\n",
      "Epoch 23/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9782Epoch 1/100\n",
      "211/211 [==============================] - 19s 92ms/step - loss: 0.0686 - acc: 0.9783 - val_loss: 0.0621 - val_acc: 0.9850\n",
      "Epoch 24/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9780Epoch 1/100\n",
      "211/211 [==============================] - 19s 91ms/step - loss: 0.0683 - acc: 0.9781 - val_loss: 0.0357 - val_acc: 0.9912\n",
      "Epoch 25/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9790Epoch 1/100\n",
      "211/211 [==============================] - 20s 92ms/step - loss: 0.0627 - acc: 0.9790 - val_loss: 0.0513 - val_acc: 0.9893\n",
      "Epoch 26/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9785Epoch 1/100\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 0.0649 - acc: 0.9785 - val_loss: 0.0475 - val_acc: 0.9897\n",
      "Epoch 27/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9799Epoch 1/100\n",
      "211/211 [==============================] - 19s 92ms/step - loss: 0.0631 - acc: 0.9799 - val_loss: 0.0416 - val_acc: 0.9932\n",
      "Epoch 28/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9795Epoch 1/100\n",
      "211/211 [==============================] - 19s 91ms/step - loss: 0.0634 - acc: 0.9795 - val_loss: 0.0434 - val_acc: 0.9905\n",
      "Epoch 29/100\n",
      "210/211 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9803Epoch 1/100\n",
      " 23/211 [==>...........................] - ETA: 6s - loss: 0.0391 - acc: 0.9903\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 0.0633 - acc: 0.9803 - val_loss: 0.0376 - val_acc: 0.9905\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_cnn.fit_generator(train_gen.flow(X_train_cnn, y_train_cnn, batch_size = 256), epochs=100, \n",
    "                                        validation_data=valid_datagen.flow(X_valid_cnn, y_valid_cnn, batch_size = 256), \n",
    "                                        callbacks=[learning_rate_reduction, early_stopping_lr], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0TPVONum1J5"
   },
   "source": [
    "When training and validating our model, we have used the fit generator function, instead of the standard fit function. This is neccessary as we have applied data augmentation, which makes our data non-static. Since our image generator function loops infinitely, keras cannot know when an epoch starts and when it ends. The chosen batch size of 256 was found to be an ideal middle ground between keeping training time as low as possible while still ensuring the model was training and gaining accurate insights into the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwtP9JxMonfg"
   },
   "source": [
    "**8.2.4 Evaluating the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "Narl-uwDetTB",
    "outputId": "08ec4f2b-3fa8-4206-ee14-69d86ba8d948"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZxcdZ3/+9f3nNq7unqrTndIh3QS\nspCFAElYhbSAAiow4iAjosAdYUYURGccUQTRcbmD29WfKDJeEFAGcIUZUUYgTdgFQgIJSZqQfa/q\n7vRW+znn98epqq7eq7qrF6o/z8ejHnXq1KlT3zqd1Ls+Z/l+lWVZCCGEEGLyaJPdACGEEGK6kzAW\nQgghJpmEsRBCCDHJJIyFEEKISSZhLIQQQkwyCWMhhBBiko0Yxkqpe5RSR5RSm4Z4XimlfqyU2q6U\nekMpdXLxmymEEEKUrnwq418CFwzz/IXAgvTtOuBnY2+WEEIIMX2MGMaWZa0D2oZZ5BLgfsv2ElCp\nlJpZrAYKIYQQpa4Yx4xnAXtzHu9LzxNCCCFEHhwT+WZKqeuwd2Xj9XpXzp49u2jrNk0TTRvbb4sO\no4NOo5PZruK1ayopxjYqZbJ9RibbaHiyfUY2nbdRS0tL2LKs2sGeK0YY7wdy06shPW8Ay7LuBu4G\nWLVqlfXqq68W4e1tzc3NNDU1jWkd92y6hx++9kNevuJlfE5fcRo2hRRjG42GZVlYySRWPJ69mfEE\nViIzHcfq8ziBcuh4li7F1diImqD/uKPZPsnDh4muXw+WhV5dg15dhaOmBr2yEqXrRW2fZVmYPT0Y\nRzswOo6CadrvoTtQDt2edjjS83RUdrrf80qNug2T9W8IwEomMbq7Mbu6MLq6cu67Mbt7p42uTnte\nPIZyOtFcLpTTicrc504PMc8xow5X4xwcM2YUtL0mc/vkwzJNUqEwqUMHSR46DIDmcaPc9k3zeFBu\nD5rbhcpMe9woR/Hqtuann+aslSsxurowOjowOzsxOjrtv1tmujM9v7MLo7MTs6MDM5lA8/nQysrQ\ny8rQysqyj7M3XxlaWf95vtH/X9Q03PPnF+2zK6V2D/VcMbbwY8BnlVIPAacCHZZlHSzCeiecz2EH\ncCQVKckwHk9WMkl8x07iLduIb9tGbOs24i0tGB0dWPH4qNerBQJ4TzgB74oVeE9cgXf5cvTKyiK2\nPH+WZZHcv5/I314h8uqrRF55heTevYMvrBR6ZSV6TTWOqmr0mhoc1dXo1dU4aqrRq2twVFehfL70\nF1AHxtGjdtAePdr7OPe+owNSqbF/EIej98vM7++995elv+j8OfPT89KPndta6NY0zGgMKx6z72NR\nzFgcMxbFisYw47G+97EYViIBpgmWhWVZYFlgmliWCRbZ57BMLLPv82YkgtnVjRWLjfjRlM9ntzVQ\njub22D8CM7dEYsD9iOvzenEde6x9a5yDa459cx47B8eM2jH9sLFSKfsHRDp0lK6hPF47/LzedDC6\nC/oxanR1kTxwkOTBA6QOHbKnDx0kdeAgyYMHSR45Aslk4Y3VdTS32w5ojxvldEKfv1PvdP+/MaaJ\nBdnpGZEILcMNUKTr6IEAeiCAVlGBHgjgapiFcrowo1HMnh7Mnh5SobA9HYlg9vRgjeZzjUALBFj0\nt5eLvt7BjBjGSqn/ApqAoFJqH/A1wAlgWdZdwOPAB4DtQAS4ZrwaO94yARxNRsE7/u9nJZOYsRhm\nJGp/oUXtmxWL9Z2ORLNfdJZp4KyrwzFzJs70TSsvH9OXQqFSra3Etm4lvq3FDt5t24i/8072P7ly\nOnEddxxlp5+OozaIcmV+ebvs/9CDPk5Pp29mJELszTeJbthIdONGwj/9qf2fG3DNndsbzitW4F6w\noKi/3DMsyyKxcyeRV17Nhm/q0CEA9IoKvKtXUfXxK/CtXIXmcZNqa8doayXV1obR2kaqrRWjrZ1U\nWyvxlhYira12oI5Aeb12kFdUoFdU4F6wwJ7OzKu056PrYBhYKQPLSA06jZFKz8uZTiSyX2hGTzdm\ndw/G0aMk9+2z53d3Y0Yig7atmr4niPRtuLJDxO1GeT1oHi/K47bvXS6UpkBpoBRoCpWdtu8HPm8/\n1nxeNH85WrkfvTyQvi9H85ejl/vRAgE7gP3+gv4dWJYFqdSAsDZjcVKHDpLYvZvErt0kdu8m/s47\ndDU39wky5fPZIT1nTm9Y7z9AR1e6mstWeZlKr6t3uqMTs6cnr3aqdAhq6SDUPOmgTs+zTNOudA8c\nHLhOhyP9fVGP9+STCdTX4zxmJo76epz19aBp9t6oWCznPmH/0IrFsGJx+0dVPGF/F8XteVYqNejf\nDJX7d1XpHxJ9/8Z7QmHmnbAcPVCBHii3/37p0NUDAZTPN6rvMyuRwOjpweyJYEZ60v/G7WlMs+D1\nAePyvTKUEd/JsqyPjfC8BXymaC2aRLmV8Xgwurro+P3vaX/oYRJ7946uytG0Af+wNJ8PxzEzcc48\nBmf2P1smrOtx1Nejud0DVmUZRu9u4kRiyF3IxtGjxFvezgavEQ5n1+GYMQP3okX433Mm7kWLcS9a\niHvuXPuX8xh5Fi6k8iMfAcDo7iG2qTecu9eto+OPfwTs8PIuW5YNZ8eMGcPvknS5Bq82TJPYtm12\n+L5iV79GaysAejCIb/UqfKtW4Vu9Gvdxxw1Yx8AtPJCVTGIcPWoHdlsbZiTSWwFUVKJXVgz6t5po\nlpmuSLu7swFtdHezcdMmTj7ttJxwSN97vfa2ncAfhWOllIL0v5H+3PPmUnbGGX3mWYZB8uDBdEDv\nIrF7N8nde4hv20bXU09BKkUVcCD3Pbze3iovEMA5cyaeRYvQKgJ9wygQANPsu8chfW/GonYoZvc8\nxLGiUcx4nFQoBErhamzEd9rp2f/zzpkzccyciSMYLN7hkvSeC4ykfa800PR0GKcDOA9bmpupyezK\nNw1IxcFI2LdUO7QdynmcACP9vGnY75F9v743pTQcmXb4NSjXQAVAVdqvNVM59ykwk/0e5zxvJO17\nbQqF8XQyXmEcf+cd2n/9a47+8VGsSATvySdTc955aD6vvVvK60XzeuxpX/pXr9eH5vWgeb29u6w8\nHjBNUuFWUgcPkMzdDXXwIMmDh4i99VY2QHLpNTUETZMWsEM2kSjox4ByOnEtOA7/WWfhXrQQz+LF\nuBcuxFFdXcQtNTTdX0bZaadRdtppQO8u40w4RzdupPWX9+W/C07XBwR0bcdRdkaiADhmzqTszDPw\nrV6Nb9Uq+9h1EYJGOZ04amtx1A56DseUoTQN3e9HLyuzv3hNAywDM3oU7/xjer8gU+0QiUNn+ksz\nFbe/yIx47xdpKm6vQ3eBw91773CD7h55HmTf377vbU+f6f7PmUbOl3qmXZkv92TfEDASfeflfklb\n9rQyTVxmCpeZAqcB8wxoNMAsw0rNI3k0ztFD7VTUlKO7QXdbKC0dYNZRsNp6Ay3T1qMmtJv29FCc\ngEtBYMi/Fqh37PseBe9o8I7qDS4y0ypnOj3fsveY9IZTqt9jozeYzDz+b6mccO4f1EoHpTgzEYPn\nTHs7W0YB/yongacCTv7EhLyVhHGOzG7qSHLsYWwZBt3r1tH+wK/oeeEFlNNJ4EMfourKj+NdunT0\nK9Z1nHUzcNbNGHJPuhmP28eL0gGdPHiA1MFDHNy/n2DjHJTTNfxu4/Q8zW0vp/n9uGbPLkq1WyxK\nKVwNDbgaGqj40AcB+3PHt2whdfRoznHBJFYydzrnmGG/44ed4TDzP/gBfKtW42oY5dV5pgHJaPrW\nk76P5MyLQCLSd14qCslY/vfJKKRigJXzZdf/i6//l2HODQYJMSN9vC+ngsiEXY6zAJ4b9Z9t6lOa\n/SNAc9rbT9Pt6kil7zUtfZ+ZZ9+U5sAVcOCydNxVniECqd/fp//fjKF+7A1zfBXSYW/Zy2Xv+80b\ndL7Z+1kyNz3zuZ3DP1Zael3mwB8Y2Zsx6HOHDx6iYc48+0eX7gKHKz3t7P0RlvvDLTOt9JzPMNRt\niOezfz9H79+0z+dzDP68NnHfeRLGObwOO97GUhkbnZ0c/f3vaf/1gyT37sVRV0ftTZ+j8rLLcNTU\nFKupw9Lc7uyJJrm2NTdz8lQ909Oy7F/KyUg6eGK9/5Gy/5FzKx+r32MTzTLwlpvgiUGiBxLd9n0y\n0judO7/fbYavG8eWP8MWlfO9qPp+UeZWF7nPp+J2SBqjOFlN6eD0gsOTc+8Bh9e+91T0fZy5z3wh\nZrdP7hdR/y9GMx22JnaI6+njeOlA6X8/YJ697PZdezlu0ZKcL0vnwEq2/5dp5os0WzmnK9VUfGAF\nbSTsv33uPBi8jX0Cb2Bb0fR021y9bcq2LTOd+Qzpdmpj26W7YYqfTT0VbG9upkG20QASxjnGUhnH\n33mHtl/9io5HH7N3Ra9cyYwvfJ7y886bUhVlwUwT4h05lV1uNRftrdIyIZqMpB8P91wkp8KL9j43\nUgUwFg4PuMrsm7Osd9oXzE4fOhSmoaGhtx19qg1ypgd53uEGpy9986Zvvr73rrKBzzm8djC8S+wz\nmjnulKbJboYQJUfCOEehx4wtw6D7mXW0/yq9K9rlIvDBD459V/REMFLQcwS6DkH34cHvuw7Zy5iF\nnmim0mGTqeLSlZzTZ4eit7rv40xAOTw5r/PkVDuZ4025u/0yj3N3/6XnOT3g8vcNX33kf+ryi10I\nMVkkjHMUUhkndu1iz7XX5eyKvonKj142Pic0mSZ07oe2d6DzQO/JJtmz/nJPtEim742caXu55fu3\nw5avQvch6AkzaCXqC0J5PfjrYMbx9n1ZLbh8OcHaLzgzFV4mYHVX3mdWCiGEkDDuw6N7UKi8KuOO\n//4fkvv2MeuHPyjOrmjLsivRtneg9Z2c+x32LTVyhwdAvxMtMvf2SQqulAOCC2DWyb2BW14P/noo\nr4OyGe+qXaZCCFEqJIxzKKXwOX15VcbxlhZcc+YQuPDCwt6kpxVa384J3O3Qmg7cZM4F+7oLqhqh\nej7MPweq50HNcVA5u/ekk9zQzZz9OUxF+pqcXCKEEFOShHE/PoePaCo64nLxlhbcixYN/mQqAe07\nIfy2Hbzh7en7tyGaMxql0qFqjh2yje+Bmvnp0J0PFbPHfGanEEKIdwcJ437yqYzNaJTEnj0ELjgX\ndr8A4ZZ08G6379t39b2Y3V8HNQtgycX2fXBBuso91q5shRBCTGsSxv34HL7hjxmbBvG/3guWhXvT\n96Djm/Z83W1XtPXLYOmH04G7AILH2deJCiGEEEOQMO7H6/AOHsbRo/D6A/C3u4mvDwFVeC64Fk5s\nsgNXdisLIYQYJQnjfnxOH+2x9t4Z4e3w8l2w4UH7BKs5ZxKfcRrK8yrOS79uj5wjhBBCjIGEcT8+\nh4/9qf2w/Sl46Wew/a/2mc3L/h5O+2eYuYLYNdfYw/ZJEAshhCgCCeNciR58HfuItO+CX11qX3fb\n9BVYdQ34Z2QXi7e8jb9pzeS1UwghREmRMAY4uhf+djesvw+fTyMSCMCHf26fiOXoO7ZsKhzGaG3F\ns3DhJDVWCCFEqZEw/t+vwos/taePvwhfbR3RvX/FOuHyQcevjbe0AOCWMBZCCFEk2mQ3YFJF2+GF\nn8CiC+FzG+Gj9+GrWUDKSpEcYiDtmISxEEKIIpveYbzrOcCC0z9jdzPJyINFxFveRq+pmbCxiYUQ\nQpS+6R3GO56xRxmatSo7a6RhFOMtLXgWSVUshBCieKZ3GO98Buac0WekIq/TCwxeGVuGQXz7dtwL\nJIyFEEIUz/QN484Ddp/Sc/teojRcZZzYswcrFpPjxUIIIYpq+obxjmfs+3n5h3G85W1ATt4SQghR\nXNM3jHc+A95qqFveZ/ZwJ3DFW1pAKdzHzZ+QJgohhJgepmcYW5ZdGc89G7S+m2D4yrgF15w5aF7v\nhDRTCCHE9DA9w7h1O3QdGLCLGkaujGUXtRBCiGKbnmG8o9m+nztIGKcr42gq2me+GY2S2LNHwlgI\nIUTRTd8wrpgN1fMGPOV1DH5pU3z7drAs3AsXTEQLhRBCTCPTL4xNA3Y9a++iHqTvaV3T8eieAceM\nM31SywARQgghim36hfHBjRDrgLlNQy7ic/oGVsYtLSiPB+fs2ePcQCGEENPN9Avjnenri+eePeQi\nXod3QGUca2nBvWABStfHs3VCCCGmoekXxjuegdrjobxuyEUGr4zfluPFQgghxsX0CuNkDPa8OOgl\nTbl8Dl+fyjgVDmO0tsrxYiGEEONieoXxvr9BKjboJU25+odxXMYwFkIIMY6mVxjveAaUDo1nDrtY\n/93UMQljIYQQ42h6hfHOZ2DWyeCpGHYxn8PXp9OPeMvb6DU1OGpqxruFQgghpqHpE8axDti/fsRd\n1DCwMo63tOBZJFWxEEKI8TF9wnjX82AZI568BX2PGVuGQXz7dtwLJIyFEEKMj5II42ffDvGj9TE6\nosmhF9r5DDg80HDKiOvzOr3EjTgpM0Vy716sWEyOFwshhBg3JRHGbT0JXj9iEOqKDb3Qjmfg2NPB\n6RlxfbmDRcS2yclbQgghxldJhHHQ7wYg1JUYfIGuwxDaktcuaug7jGK8pQWUwn3c/KK0VQghhOjP\nMdkNKIZMGIe744MvsHOdfZ/HyVvQWxlHUhGcLS245sxB83rH3E4hhBBiMCVSGbuAYcJ4R7N9OdPM\nFXmtLzeM4y0tsotaCCHEuCqJMK7yudDUEGFsWfbJW41ngZbfIA/Z3dRd7ST27JEwFkIIMa5KIow1\nTVHuUoQHO2bctgM69sK8przXl6mMk+/sAMuSASKEEEKMq5IIY4CASw1eGWeGTJzXlPe6MpWx8fZO\nABkgQgghxLjKK4yVUhcopbYppbYrpW4e5PljlVJrlVKvK6XeUEp9oPhNHV7FUGG84xkoPwZqjst7\nXZnKWO3Yg/J4cM6eXaxmCiGEEAOMGMZKKR24E7gQWAJ8TCm1pN9iXwUesSzrJOAfgJ8Wu6EjCbgV\n4e5+u6lN0z6Tet4aUCrvdWUqY+euA7gXLEDp+R1rFkIIIUYjn8r4FGC7ZVk7LMtKAA8Bl/RbxgIC\n6ekK4EDxmpifgEsR6o5jWVbvzMNvQrQt70uaMjKVsWf3ETleLIQQYtzlc53xLGBvzuN9wKn9lrkd\n+F+l1A1AGXDeYCtSSl0HXAdQV1dHc3Nzgc0dmocEiZTiz08243PaVfDsPX9gPvDCYReJAt+rqkfD\n1RFhn6bRUsR2Tqbu7u6ibvNSI9tnZLKNhifbZ2SyjQZXrE4/Pgb80rKs7yulTgceUEotsyzLzF3I\nsqy7gbsBVq1aZTU1NRXp7eH5/X8FEiw+cTXzav32zF/9Hwgu5IzzP1Lw+hY87wYSLP3AByg7/fSi\ntXMyNTc3U8xtXmpk+4xMttHwZPuMTLbR4PLZTb0fyD2DqSE9L9c/Ao8AWJb1IuABgsVoYL4q3HY1\nnD1unErA7hcK3kWdMS9sbxq5xlgIIcR4yyeMXwEWKKXmKqVc2CdoPdZvmT3AuQBKqeOxwzhUzIaO\nJODKhHH6jOr9r0Iyknd/1P0de8QiEnDhqKkpVhOFEEKIQY0YxpZlpYDPAk8AW7DPmt6slPqGUuri\n9GL/AlyrlNoI/BdwtdXnTKrxV+G2P0o2jHc0g9Kg8T2jWt/Mw0nCM31Fap0QQggxtLyOGVuW9Tjw\neL95t+VMvwWcWdymFabcBZqCUFcmjJ+x+6L2VhW8LsswmHE4zutnBEZeWAghhBijkumBS1OK6jKX\nXRnHu+3d1POaRrWu5N69OJMm++tKYlArIYQQU1zJhDHYQymGutInbpmpUZ+8FWtpAWD3hJ6CJoQQ\nYroquTAOd8ft/qh1Nxx72qjWE9/WgqVgZ3WqyC0UQgghBiqxME7vpt7RDLNPAad3VOuJt7TQUxeg\nQ0WL20AhhBBiECUWxm7M7iNweNOoL2kCO4wjx9YSTUUx+/ZbIoQQQhRdaYVxuZuTjU32g3nvHdU6\nzGiUxJ49xBvrsLCIpWJFbKEQQggxUGmFsd/NGdomTFc5zDxxVOuIb38HLAtjbgMAkVSkmE0UQggh\nBiixMHZxpraZjrpTQR/dZUnx9JnUzJ8DQDQpx42FEEKMr5IK45nmYeZoRzhUfcqo1xFv2YbyeHA2\nSGUshBBiYpRWGLe9DMDb/lWjXkespQX3ggX43PbITxLGQgghxltJhbH/wPMcsSp5x2oY9TriLW/j\nXrgAn9PulzqSlDAWQggxvkonjC0LbdezvKKWE+5JjGoVqdZWjNZWPAsX4nXY1yhLZSyEEGK8lUwY\nl/Xshp4QWzwn9Y7cVKDMyVvuhQulMhZCCDFhSmYkhKr2jQDsrlhNuHt0lXFs2zYgHcbpLSOVsRBC\niPFWMpVxVfsbUD0PVTl7DJXx2+jBII6aGqmMhRBCTJjSCGMjSUXHJpi7Jj1y0+h3U3sWLgDAo3tQ\nKKmMhRBCjLvSCOP963EYMZjXRLDcRSRhEEkUNuKSZRjEt2/HvWAhAEopfE6fVMZCCCHGXWmEcevb\nmMoBc88m6HcDEO4q7Lhxcu9erFgM98KF2Xk+h49oSnrgEkIIMb5KI4xPupLn3vMg+KqpTYdxqMDj\nxrGcM6kzpDIWQggxEUojjAFTt0M4WxkXGMbxbS2gFO7j5mfn+Rw+OWYshBBi3JVMGGcEy13AKMK4\npQXXnDloXm92ntfhlTAWQggx7koujGvKRnfMON7S0mcXNchuaiGEEBOj5MLY5dCo8DoLqozNaJTE\nnj0DwrjMWSaVsRBCiHFXcmEM9rjGhYRxfPs7YFm409cYZ/gcUhkLIYQYfyUaxu7Cwjh9JrVnsN3U\nUhkLIYQYZ6UZxuXugvqnjrdsQ3k8OGfP7jPf5/ARTUaxLKvYTRRCCCGySjKMa/1uwgV0iRlracG9\nYAFK1/vM9zl9pKwUSTNZ7CYKIYQQWaUZxuVuuuIpYkkjr+XjLW8POF4M9I5pLMeNhRBCjKOSDOOg\nP/9rjVOtrRitrQOOF4O9mxpkGEUhhBDjq0TDONML18jHjeODdIOZIcMoCiGEmAglHcb5DKU4bBhL\nZSyEEGIClGYYl+ffP3VsWwt6MIijpmbAc9nKWMJYCCHEOCrJMK4pSx8zzrMy9gxy8hbkVMaym1oI\nIcQ4Kskw9jh1yj2OvCrjxN69uBrnDvqcVMZCCCEmQkmGMaSvNR7hBC4zHsfs6MAxo3bQ56UyFkII\nMRFKNoyDfjehESpjIxwGwFE7RBinK+NoKlrcxgkhhBA5HJPdgPESLHex9VDXsMukQiEAHMHgoM97\ndA8glbEQQgAkk0n27dtHLBYb9ToqKirYsmVLEVs19Xg8HhoaGnA6nXm/pnTD2O8m3BUedpnUCJWx\nrul4HV45ZiyEEMC+ffsoLy+nsbERpdSo1tHV1UV5eXmRWzZ1WJZFa2sr+/btY+7cwc9HGkxJ76bu\njKWIp4buEjNTGetDVMZgd4kplbEQQkAsFqOmpmbUQTwdKKWoqakpeO9BSYcxQOswJ3GlQmHQtEGv\nMc7wOWQYRSGEyJAgHtlotlEJh/HI/VOnQiH06uoBozXl8jl9UhkLIcQU4ff7J7sJ46Jkw7g2j164\nUuHwkMeLM6QyFkIIMd5KNoyzg0V0DbebOjTkmdQZPqeEsRBCTDWWZfHFL36RZcuWsXz5ch5++GEA\nDh48yNlnn82JJ57IsmXLePbZZzEMg6uvvjq77A9/+MNJbv1AJXs2daYyHu5a41Q4POgAEbl8Dh9H\nIkeK2jYhhHi3+/p/b+atA50Fv84wDPQhDg0uOSbA1y5amtd6fv/737NhwwY2btxIOBxm9erVnH32\n2Tz44IOcf/753HLLLRiGQSQSYcOGDezfv59NmzYBcPTo0YLbPd5KtjL2OHX87qG7xLRM095NnUdl\nLJ1+CCHE1PLcc8/xsY99DF3XqaurY82aNbzyyiusXr2ae++9l9tvv50333yT8vJy5s2bx44dO7jh\nhhv4y1/+QiAQmOzmD5BXZayUugD4EaADv7As6/8dZJmPArcDFrDRsqwritjOUQn6XUN2iWl0dEAq\nNeIxY7m0SQghBsq3gu1vvK8zPvvss1m3bh1/+tOfuPrqq/nCF77AJz/5STZu3MgTTzzBXXfdxSOP\nPMI999wzbm0YjRErY6WUDtwJXAgsAT6mlFrSb5kFwJeBMy3LWgrcNA5tLVjQ7ybUNfi1Xqkj6d63\nauWYsRBCvNucddZZPPzwwxiGQSgUYt26dZxyyins3r2buro6rr32Wj71qU+xfv16wuEwpmnykY98\nhG9+85usX79+sps/QD6V8SnAdsuydgAopR4CLgHeylnmWuBOy7LaASzLmhIHWYN+N9tD3YM+l+0K\nM4+zqeNGnJSZwqGV7CF2IYR4V/nwhz/Miy++yIoVK1BKcccdd1BfX899993Hd7/7XZxOJ36/n/vv\nv5/9+/dzzTXXYJomAN/5zncmufUD5ZMus4C9OY/3Aaf2W2YhgFLqeexd2bdblvWXorRwDILlLl7a\nOfgx41Q4/zAGe7CIclfpduEmhBDvBt3ddoGllOK73/0u3/3ud/s8f9VVV3HVVVcNeN1UrIZzFavU\ncwALgCagAVinlFpuWVafU9aUUtcB1wHU1dXR3NxcpLe3/0D919cdTnA0kuTJp9fi0Pr2iOJ7+WXK\ngRe2bIEdO4Zc794u+3fIU+ueotJRWbT2TobBtpHoJdtnZLKNhlfq26eiooKuruEH4BmJYRhjXse7\nQSwWK+jfQj5hvB+YnfO4IT0v1z7gZcuyksBOpVQLdji/kruQZVl3A3cDrFq1ympqasq7oSNpbm6m\n//r2eXbzx+2bWLbydOorPH2eO/ziixwtK6Pp/POHXW9kR4SHnn2IFatXMLci/06/p6LBtpHoJdtn\nZLKNhlfq22fLli1jPvmq1AeKyPB4PJx00kl5L5/PpU2vAAuUUnOVUi7gH4DH+i3zR+yqGKVUEHu3\n9dDl5gTJdvwxyOVN+XT4Ab1jGstJXEIIIcbLiGFsWVYK+CzwBLAFeMSyrM1KqW8opS5OL/YE0KqU\negtYC3zRsqzW8Wp0vmrL7f6pB+v4IxUauStM6D1mLJc3CSGEGC95HTO2LOtx4PF+827LmbaAL6Rv\nU0Zvl5iDV8bu4xePuI5MZf3qTNwAACAASURBVCwdfwghhBgvJdsDF+Tuph7Y8Uc+g0SAVMZCCCHG\nX0mHcZnbgdepDzhmbEajmN3dOIJ5hLEcMxZCCDHOSjqMwR4won8Yp8JhYORrjMHuDhOkMhZCCDF+\nSj6M7f6p+4VxpvetfM6mdkhlLIQQU8nf/d3fsXLlSpYuXcrdd98NwF/+8hdOPvlkVqxYwbnnngvY\n131fc801LF++nBNOOIHf/e53k9nsYZV8/45Bv5vdrX2DNBVKV8YzRq6MnboTp+aUylgIIXL9+WY4\n9GbBL/MaKdCHiJ765XDhgHGIBrjnnnuorq4mGo2yevVqLrnkEq699lrWrVvH3LlzaWtrA+Df//3f\nqaio4M037Xa2t7cX3N6JUvphXO7mtd19/wCFVMYgg0UIIcRU8uMf/5g//OEPAOzdu5e7776bs88+\nm7lz7Y6ZqqurAXjyySd56KGHsq+rqqqa+MbmqfTD2O+mLZIgZZg4dHuvfCocAl1Hz/MP43P4pDIW\nQohceVSwg4mOsQeu5uZmnnzySV588UV8Ph9NTU2ceOKJbN26ddTrnApK/phxrd+FZUFbT+/lTalQ\nCEdNDUrL7+P7HFIZCyHEVNDR0UFVVRU+n4+tW7fy0ksvEYvFWLduHTt37gTI7qZ+3/vex5133pl9\n7VTeTV3yYZy51ji3F658rzHO8DmlMhZCiKngggsuIJVKcfzxx3PzzTdz2mmnUVtby913382ll17K\nihUruPzyywH46le/Snt7O8uWLWPFihWsXbt2kls/tNLfTV0+sOOPVCiEs3ZG3uuQylgIIaYGt9vN\nn//850Gfu/DCC/s89vv93HfffRPRrDGbNpVxbpeYRiic15nUGV6nVypjIYQQ42YahLE9WETmWmPL\nMEi1tqLneSY1SGUshBBifJV8GPvdDtwOLRvGRlsbmKYcMxZCCDFllHwYK6UI+t3ZY8bZrjClMhZC\nCDFFlHwYg30SV6Yyznb4UWBlHE1FMS1zXNonhBBiepsWYVzrdxHqyoRx/oNEZGT6p46lYsVvnBBC\niGlveoRxec5u6tFUxjJYhBBCiHE0LcI46HfT1hPHMC1S4TBaIIDmduf9+uyYxnISlxBCvKv4/f4h\nn9u1axfLli2bwNYMbdqEsWlBeyRhd4VZwMlbIJWxEEKI8VXyPXBBTscf3XE8BXaFCXanHyCVsRBC\nZPzH3/6DrW2FD85gGAa6rg/63OLqxXzplC8N+/qbb76Z2bNn85nPfAaA22+/HYfDwdq1a2lvbyeZ\nTPLNb36TSy65pKB2xWIxPv3pT/Pqq6/icDj4wQ9+wHvf+142b97MNddcQyKRwDRNfve733HMMcfw\n0Y9+lH379mEYBrfeemu2C87RmiZhnO74oytBfSiEd/nygl4vlbEQQkwNl19+OTfddFM2jB955BGe\neOIJbrzxRgKBAOFwmNNOO42LL74YpVTe673zzjtRSvHmm2+ydetW3v/+99PS0sJdd93F5z73OT7+\n8Y+TSCQwDIPHH3+cY445hj/96U+APXjFWE2PMC7vrYyDo6iM5ZixEEL0NVIFO5SuMQ6heNJJJ3Hk\nyBEOHDhAKBSiqqqK+vp6Pv/5z7Nu3To0TWP//v0cPnyY+vr6vNf73HPPccMNNwCwePFi5syZQ0tL\nC6effjrf+ta32LdvH5deeikLFixg+fLl/Mu//Atf+tKX+NCHPsRZZ5016s+TMW2OGQO0h9uxIhEc\ntXLMWAgh3q0uu+wyfvvb3/Lwww9z+eWX8+tf/5pQKMRrr73Ghg0bqKurIxYrzqWoV1xxBY899hhe\nr5cPfOADPP300yxcuJD169ezfPlyvvrVr/KNb3xjzO8zLSrjgMeBS9foOnAYKOyyJpDKWAghppLL\nL7+ca6+9lnA4zDPPPMMjjzzCjBkzcDqdrF27lt27dxe8zrPOOotf//rXnHPOObS0tLBnzx4WLVrE\njh07mDdvHjfeeCN79uzhjTfeYPHixVRXV3PllVdSWVnJL37xizF/pmkRxnaXmC5ih48AhXWFCVIZ\nCyHEVLJ06VK6urqYNWsWM2fO5OMf/zgXXXQRy5cvZ9WqVSxevLjgdV5//fV8+tOfZvny5TgcDn75\ny1/idrt55JFHeOCBB3A6ndTX1/OVr3yFV155hS9+8YtomobT6eRnP/vZmD/TtAhjsI8bp/YU3vsW\ngFt3oylNKmMhhJgi3nzzzex0MBjkxRdfHHS57u7uIdfR2NjIpk2bAPB4PNx7770Dlrn55pu5+eab\n+8w7//zzOf/880fT7CFNi2PGYB83Vq2tAAUNnwh2Ze1z2P1TCyGEEMU2fSpjvwvH0TZwOtErKwt+\nvYzcJIQQ705vvvkmn/jEJ/rMc7vdvPzyy5PUooGmURi78XS146ipKejaswwZ01gIId6dli9fzoYN\nGya7GcOaVmHsinVCgZc1ZXgdXqmMhRBCjItpc8y4ttxNVayLVGX1qF4vlbEQQojxMm3COOh3Ux3r\nJF5eNarXyzFjIYQQ42X6hLFXI5CI0F0WGNXrpTIWQggxXqZNGFcnutGwOOqrGNXrpTIWQoh3n+HG\nM55Kpk0Y+7rtUTVaXaP7w/icPqJJuc5YCCFE8U2bs6lToRAAhxyjDON0ZWxZ1qgujRJCiFJy6Nvf\nJr6l8PGMU4ZB2xDjGbuPX0z9V74y7OuLOZ5xd3c3l1xyyaCvu//++/ne976HUooTTjiBBx54gMOH\nD/PP//zP7NixA4Cf/exnnHHGGYV8/CFNnzAO211h7td8o3q9z+nDsAwSZgK37i5m04QQQuSpmOMZ\nezwe/vCHPwx43VtvvcU3v/lNXnjhBYLBIG1tbQDceOONrFmzhj/84Q8YhjFsV5uFmj5hnK6M91je\nUb3e67BfF0lGJIyFENPeSBXsUKbSeMaWZfGVr3xlwOuefvppLrvsMoLprpOrq+1LYp9++mnuv/9+\nAHRdp6JidOcgDWbahLERDhPzlXMoYozq9bkjN1UxusujhBBCjF1mPONDhw4NGM/Y6XTS2NiY13jG\no33deJg2J3ClQiESgUpae+JYllXw62VMYyGEmBouv/xyHnroIX77299y2WWX0dHRMarxjId63Tnn\nnMNvfvMbWtODC2V2U5977rnZ4RINw6Cjo6Non2kahXEYs6qGpGHREU0W/HoZ01gIIaaGwcYzfvXV\nV1m+fDn3339/3uMZD/W6pUuXcsstt7BmzRpWrFjBF77wBQB+9KMfsXbtWpYvX87KlSt56623ivaZ\nps1u6lQohDb3eADC3XEqfa6CXi+VsRBCTB3FGM94uNddddVVXHXVVX3m1dXV8eijj46itSObFpWx\nZVmkwmGcM2oBCHUlCl6HVMZCCCHGy7SojM2uLqx4HF/9DDhgV8aFkspYCCHenWQ84ykic41x+TH1\now/jdGUcTUkvXEII8W7ybhjPOK/d1EqpC5RS25RS25VSNw+z3EeUUpZSalXxmjh2qSP2NcYVs+rR\nNSWVsRBCiCllxDBWSunAncCFwBLgY0qpJYMsVw58Dpg6dX9apjJ21s2gpsxFeBTHjD26B5BjxkII\nIYovn8r4FGC7ZVk7LMtKAA8Bg3X6+e/AfwCTc8X0MDK9bzmCQYJ+96gqY13T8Tq8UhkLIYQounzC\neBawN+fxvvS8LKXUycBsy7L+VMS2FU0qFEK53Wjl5QTLRxfGYHeJKZWxEEJMnnfLkIiFGvMJXEop\nDfgBcHUey14HXAf29VrNzc1jffus7u7uIdcX2LwJl9/PM888g9EdZ1+bMar31lIaO/fvLGq7J9Jw\n20jI9smHbKPhlfr2qaiooKura0zrMAxjzOvo//pUKoXDMbXOR47FYgX9W8in9fuB2TmPG9LzMsqB\nZUBzeoSMeuAxpdTFlmW9mrsiy7LuBu4GWLVqldXU1JR3Q0fS3NzMUOvbfd99WLNns6ypiRcjW3jl\nhV2sWbOm4KEQf/LYTyj3lw/5PlPdcNtIyPbJh2yj4ZX69tmyZcuYBnmAsQ8UAVBeXk5zczO33nor\nVVVVbN26lZaWljGts9g8Hg8nnXRS3svnE8avAAuUUnOxQ/gfgCsyT1qW1QEEM4+VUs3Av/YP4slk\nhMO4GhsBCPrdJFImXfEUAY+zoPX4nD7ZTS2EEMCzj7QQ3lv4EIKGYaAPMZ5xcLafsz66MO91rV+/\nnk2bNjF37tyC2zHVjHjM2LKsFPBZ4AlgC/CIZVmblVLfUEpdPN4NLIbUkRCOWrv3rWC53Q1muGt0\n1xpHk3KdsRBCTAWnnHJKSQQx5HnM2LKsx4HH+827bYhlm8berOIxEwmMjg709LiUQb89FnGoK868\n2sJOBPA5fRyOHC56G4UQ4t2mkAo2VzF2U2eUlZUVZT1TQcn3TW2krzHOVsbpMA53F36tsVzaJIQQ\nYjyUfBhnOvxw9KuMR9slphwzFkIIUWxT61zwcZDt8KN2BgDVZS40NfrBIqQyFkKIyZMZErGpqamk\nzlwv/co4lNlNbVfGuqaoLnONujJOmAmSZrKobRRCCDG9TYMwDoFSOGpqsvOCfvfoxjR2yshNQggh\niq/0wzgcRq+uRuX0zlI7yi4xM8Moyq5qIYQQxVT6YRwKZU/eyhjtYBHZYRTlJC4hxDRlWdZkN2HK\nG802Kv0wDoezlzVlBP32MeNCN1imMpaOP4QQ05HH46G1tVUCeRiWZdHa2orH4ynoddPibGr3vHl9\n5gX9bmJJk56Egd+d/yaQylgIMZ01NDSwb98+QumrVEYjFosVHFTvNh6Ph4aGhoJeU9JhbFnWEJVx\n+lrjrnhhYSzHjIUQ05jT6Rxz95PNzc0FDaAwXZT0bmrj6FFIJrOXNWUEy0fX8YfX6QWkMhZCCFFc\npR3G/brCzAj604NFFBjGUhkLIYQYDyUdxtnet/qdTV2bGSyiwP6p5ZixEEKI8TA9wrhfZVxd5kKp\nwodR9DrSu6mlMhZCCFFEpR3G6d3UerBvGDt0jSpf4V1iOjUnLs0llbEQQoiiKu0wPhJC+Xzo/oFj\nXgb9LkIFVsYgg0UIIYQovtIO43B4wPHijFH3wiXDKAohhCiy0g7jUGjA8eIMO4xHN1iEDBQhhBCi\nmEo7jMerMpbd1EIIIYqotMN4uMq43EUkYRBJpApap9fpld3UQgghiqpkw9iMxTC7uoasjGuzXWIW\neK2xVMZCCCGKrGTDODVE71sZmS4xQ4X2wuWUE7iEEEIUV+mGcbbDjxEq41F0iSmVsRBCiGKaBmE8\n9NnUMMowlspYCCFEEZVuGGd2Uw9xzLgmM1hEoceM05c2mZY5tgYKIYQQaaUbxqEQaBp6dfWgzzt1\njUqfc9QjN8VSsTG3UQghhIASDmMjHEavqUbp+pDLjOZaYxm5SQghRLGVbBinjgx9jXFG0F/4YBEy\ncpMQQohiK90wDofzCOPCu8SUylgIIUSxlW4Yh0JDnryVEfS7Cx7TOHPMWCpjIYQQxVKSYWyZJqnW\n1hEr49pyN13xFLGkkfe6pTIWQghRbCUZxkZ7OxgGjuDIx4yBgsY1lspYCCFEsZVkGI/U4UfGaDr+\nkMpYCCFEsZVoGGf6pR75mDFQ0ElcUhkLIYQothIN4/wq49pyqYyFEEJMvtIM4xG6wszo7RIz/zB2\naS50pUtlLIQQomhKM4xDITS/H83rHXY5t0Mn4HGwuy3/YFVK4XPY/VMLIYQQxVCaYRwe+RrjjAuW\n1fO79ftYu+1I3uv3Or2ym1oIIUTRlGYYh0buCjPj6xcvY3F9gM/91+vsbu3J6zUyprEQQohiKskw\nNkLhEc+kzvC6dH5+5UqUUvzTA68RSaRGfI3PKWMaCyGEKJ6SDONCKmOAY2t8/PhjJ7HtcBc3/+5N\nLMsadnmpjIUQQhRTyYWx2dODGYmg53nMOGPNwlr+9f2LeGzjAf7/53YOu6xUxkIIIYqp5MI4e1lT\nAZVxxvVN8zl/aR3f+fNWXngnPORyUhkLIYQoptIN4xH6pR6MUorvXbaCxhofNzz4OgeODn75klTG\nQgghiqn0wjjP3reGUu5xcvcnVxFPmXz6V68NOqKTz+EjmpTrjIUQQhRHCYZxfv1SD2d+rZ8ffHQF\nG/d18LVHNw84ocvrsK8zHulELyGEECIfeYWxUuoCpdQ2pdR2pdTNgzz/BaXUW0qpN5RSTyml5hS/\nqflJhULgcKBXVo5pPe9fWs8N5xzHw6/u5cG/7enznM/pw7AMEmb+A0wIIYQQQxkxjJVSOnAncCGw\nBPiYUmpJv8VeB1ZZlnUC8FvgjmI3NF+pcBhHTQ1KG3vRf9N5C1mzsJbbH9vMa7vbs/Nl5CYhhBDF\nlE9inQJstyxrh2VZCeAh4JLcBSzLWmtZViaZXgIaitvM/BV6jfFwdE3x4384iZkVXq7/9Wsc6YoB\nMnKTEEKI4nLkscwsYG/O433AqcMs/4/Anwd7Qil1HXAdQF1dHc3Nzfm1Mg/d3d00NzdTvWsnZlVV\nUdd97fEW//5SnCt/upZ/W+1hZ9S+DvmZF57hGNcxRXuf8ZbZRmJwsn1GJttoeLJ9RibbaHD5hHHe\nlFJXAquANYM9b1nW3cDdAKtWrbKampqK9t7Nzc00NTXR8tVbKT9tMScWcd0AFcce4Mb/ep3numdw\n3srV3PPkPSw9aSkralcU9X3GU2YbicHJ9hmZbKPhyfYZmWyjweUTxvuB2TmPG9Lz+lBKnQfcAqyx\nLCv/AYKLyEqlMFpbi7abOtfFK47hjb1H+cVzO6mo0gE5ZiyEEKI48jlm/AqwQCk1VynlAv4BeCx3\nAaXUScDPgYsty8p/LMIiS7W1gWWN6bKm4dx84WJOm1fNz9fav0XkmLEQQohiGDGMLctKAZ8FngC2\nAI9YlrVZKfUNpdTF6cW+C/iB3yilNiilHhtideNqrB1+jMSha/zkipOp8JQBEOruGpf3EUIIMb3k\ndczYsqzHgcf7zbstZ/q8IrdrVIxsV5jjUxkDBP1u7rh0NZ99Hu59YSvnHRsn6HeP2/sJIYQofSXV\nA9d4V8YZq+fMBGBneztn37GW7z6xlY5IclzfUwghROkqrTBOV8aFDp9YKI/DA8Anz5jJOYtncOfa\nd3jPHU/zf556m+54alzfWwghROkprTA+EkKrqEBzj+9uY01peB1ePK4UP7niZP78ubM4dW4N3/9r\nC2ffsZb/XLdj0AEmhBBCiMGUVhiHw+N6vDiXz9E7jOLxMwP84qpV/PEzZ7L0mADfenwLZ9+xlgde\n3EUiZU5Ie4QQQrx7lVYYF7ErzJEMNqbxibMreeAfT+Xh605jTo2PWx/dzHu/18wjr+4lZUgoCyGE\nGFxphfFEV8ZDdPpx6rwaHvmn07nv/zmFGr+Lf/vtG7zvh+t4dMN+TFOGXRRCCNFX6YSxZU16ZZxL\nKcWahbU8+pkzufsTK3E7ND730AYu/NGzPLH5kIyFLIQQIquofVNPJhWLYcViE1oZdyVG7vRDKcX7\nl9Zz3vF1/M+bB/n//trCPz3wGgtm+Lni1GO59KQGKnzOCWixEEKIqapkKmOtowMAx4ypURn3p2mK\ni1ccw/9+/my+f9kKfG4HX//vtzjl20/yL49s5LXd7VItCyHENFUylbHW2QmMb+9bubwO76gGinDo\nGh9Z2cBHVjawaX8HD/5tD4++vp/frd/H4vpyPn7qsVxy0iwCHqmWhRBiuii9yniijhk7CquMB7Ns\nVgXf/vByXr7lPL794eXomuLWRzdz6ree4ku/fYM39h0tUmuFEEJMZSVTGesTXBn7nEOfTV0ov9vB\nFacey8dOmc0b+zp48OU9PLbxAA+/updlswJcccocLj7xGPzukvlzCSGEyFEy3+5aRyfK6USrqJiQ\n9/M5fCTMBEkziVMrzi5lpRQrZleyYnYlt3zoeB59fT+/fnkPX/nDm3zrT29xyUmz+MjJs2io8lFd\n5sKpl8yODSGEmNZKKIw70GuDKKUm5P18Th8A0VQUp6v4x3cDHiefOL2RK0+bw/o9R3nw5T387rV9\nPPjynpxlHAT9bqrLXNT4XVSXuQn6XenHbmqy811U+1xFb6MQQojiKJ0w7uycsOPFALPLZwPwizd+\nwRdWfWHc3kcpxco5VaycU8VtH1rCizvChLsTtHYnaOuJE+5J0NadYGe4h9d2t9PWk2CwfkWUgga/\nxkWxrbx38QxOml2JQyprIYSYEkonjDs6cCw5fsLeb03DGi5fdDn3br6XWl8tn1jyiXF/zwqfkwuW\nzRx2GcO06Igmae2O09rTG9pHuuL87+s7+Pm6Hfy0+R0qvE7WLKzlvYtrWbNwBtVlUjkLIcRkKZkw\n1js7J+zkLbAr1i+f8mXaYm3c8cod1Hhq+MC8D0zY+w9F15S9W7rMxYJ+z610HeSkU8/kubfDrN12\nhOZtR3hs4wGUsvvVPmfRDN67eAZLjwlM2O5+IYQQJRLGViKB1t09obupAXRN5ztnfYf2WDu3PH8L\nVZ4qTj/m9AltQ6EqvE4+eMJMPnjCTEzTYtOBDp7eeoS1W4/w/b+28P2/tjCj3E3TolrOWTyDM48L\nUi7XPAshxLgqiTBOtbUB4AhObBgDuHU3PzrnR1z9l6u5ae1N3HvBvSypWTLh7RgNTVOc0FDJCQ2V\n3HTeQkJdcZ5pCbF22xH+vOkQj7y6D6euOHF2JY01ZTRU+Wio8tq3ah/1AQ+6JhW0EEKMVWmEcSgE\nTFyHH/0FXAHuOu8urnz8Sj795Kf51YW/YnZg9qS0ZSxqy938/coG/n5lA0nDZP3udp7edoRXd7Wz\n7u0QhzvjfZZ3aIqZlR4aKjMhLWEthBCjUSJhHAbAUTtxx4z7m+GbwV3vu4tP/vmT/NOT/8QDFz5A\njbdm0tozVk5d49R5NZw6r/czxJIGBzti7GuPsK89mnMfHTKsyz0OPE4956bhcdj3XpeOx6HjTs/3\n5izjczkI+l0E/W5q/PYlW363Q45lCyFKUomE8eRWxhnzKuZx57l38qknPsX1T13PPeffQ5mzbFLb\nVEwep87cYBlzg4N/psHCujOaIpo0iCUNYkmTeMqeDnUniSXN3vlJg2jSIDXMeM9uh0YwHcz2vZua\nzHS5m2CZi2C5m1mVXsqktzIhxLtISXxjBS68gM3RCIsn8GzqoayoXcH3m77PjU/fyOfXfp47z70T\npz49ToAaKazzkTJMYimTnniKcHc8fU11PDuduT/YEWPTgQ5auxODBnh9wMO82jL7FvQzt7aM+UE/\ns6q8sutcCDHllEQY64EAqcZGlGNqfJyzG87ma6d/jdteuI1bX7iVb7/n22hKOtjIh0PX8OsafreD\nuoBnxOXN9HXVmZAOdcfZ2xbhnVA3O0I9PLbhAJ2xVHZ5l0OjscbH3GAZ82r9zEvfz6/t/QGRMkzi\nKbtqz+c+njKpKXPRWFNGY9CHzzU1/h0KId495FtjnHx4wYcJR8P8+PUfE/QE+dfV/zrZTSpJmqao\nKnNRVeZiQd3A5y3Loq0nwY5wDzvSAb0j3MP2I908vfUISaO3qnZpYPzv4xjD7CrPR13AzZyaMubW\nlNEYLGNu0MecmjIaa8rwuvQxrVsIUZokjMfRp5Z/ilA0xH1v3Uetr5arll412U2adpRSdj/dfjer\nG6uz8w3TYHv7Dp7bu4H1h97g7aNb6Ix2cVrNNcwvW4nbqeFOn2jmdui4HRoep33vdmYe28+5HBqh\nrji7WnvYFe5hZzjC7tYentp6mHB3ok976gMeGoO+dBVdxuwqH5U+JxVeJwGPfe/3OGRXuhDTjITx\nOFJK8aXVX6I12sr3Xv0e1Z5qLpp/0WQ3a9oxLZPdnbvZ3LqZzeHNvNX6FlvathBNRQHwOrwcX308\nhtHOU+3fIlDzYf519b8ScAXyfo+6gIdlswaOGNYZS7KnNcLOcDqoW3vY3Rrhr28dprUnMciabOUe\nRzacA15Hn7C25zlxOzQcuoZTVzg0DV1T9rSu4dTs++w8zV7OfqyhaQpdKTQN+14pe16/+bqm5Ax2\nISaAhPE40zWdb5/1bdrj7dz2/G3UeGo4Y9YZk92skmVZFnu79maDd3PrZra0baEn2QOAR/ewuHox\nly64lKU1S1lSs4TGQCO6pvPXtX9lc2Az926+l+cPPM/XTv8aZzecPab2BDxOls2qGDKo97dH6Ywm\n6Ygm6Yyl7PvM42iSzpg9vSscoSM9P5o0xtSmQinVG8xOZVL1t6cpdzsp9zjSN3va7+6d7v+cx6GT\nMi1SpknKsEgaJikzfW/Y85OG1W/aXsal25fB+Vx6+t5hTzvteT6XA49Tkx8N4l1NwngCuHU3P3rv\nj7jmL9dwU/NN3Hv+vSwNLp3QNrTF2ugyujAts2RPJttwZANffvbL7OveB4BLc7G4ejEXzbuIJTVL\nWBpcyryKeTi0wf/ZO5WTm1bexHlzzuPW52/lM099hovnX8y/rf43KtzFHyc74HESmFn4mfaJlEln\nLEkilQ42szfQcsPM6Bd2KdPKBqFpWRgmGJaFadrLmpaVnW/f987PTL+9aw+B6iq64yk6Yyn2H43R\nHe+iK5aiK5Ya8/H20VKKbDh7XTo+pwOvS6fMreN1OtKhrWdD3edy9Fm+LBPw6ecCXgdVPhcepxzj\nFxNDwniClLvK+dl5P+PKx6/k+qeu5+tnfJ3jKo9jZtlMdK24/+FDkRBvtb7V53YkegSAWx+4lRpP\nDTXeGoLeILW+Wmo89nT/W2bM5qnOtEzu2XQPP3n9J9SX1XPb6bexPLic+ZXzcWqFh92y4DIe/tDD\n3LXxLu7ZdA8vHniR206/jabZTcVv/Ci40tdbT4bm5sM0NZ006HOWZRFNGnTH7KDuiiXpjtshHUsa\n2V3kjsz9ILvPc+c50ssmUibRpEEkYRBJpIgm7Olo+nEkaRBLz4skc+anl2nvifZ5HEkaef9ocDs0\nKn1OKr0uKnxOKr1Oqnwu+zh/en5len6lz8WRiMnetghg/0BQSqEy06je+QDpeZnHCcMkljSJJgxi\nqcy1+Ub2evxoznTuwenXwgAAEhNJREFUc0nDRKVXqKne99Iy75/zPrnzNKWo8jmpC3ioD3ior/BQ\nF/DID5BJImE8gWp9tdz1vru4+i9Xc8PTNwDg1Jw0lDcwp3wOxwaOZU5gTvY2wzdjxCr2SOTIgOAN\nRe1OUBSKxopGVs9czfHVx7PrnV1UNVQRjoazt61tW2mNtWJa5oB1+xw+gt4gDeUNXDT/It4/5/24\n9Kk11GI4GuaW527hhQMv8P457+f2M26n3FU+5vW6dBc3nnwj5845l1ufv5Ubnr6BD877IDevvplK\nT2URWl56lFLpXcgOZuR/uH3CWZZFwjCJxDPhnUoHfW+Id0ZTHI0m6IgkORpJ0h5JcDSaZHdrhI37\njtIesfdMDGrd2nH/DEqR7cnOqWtYgGUBWJiW/Rkt7Ev/Ms9l51kWlmUPtzrYNfqVPif1AU82pOsC\nbuoqPL3zKjwEPE5iKfvHTfbHUfqHkP3Dyf4B1md+evrQwTgvRrZke96zP0fvyZIep9bvsT3t0jVM\ni+weHPsz5TzG/ozZZUywsNLbZeD2y/1xNNQ8XVPMr/UX9483BAnjCTa3Yi7/8+H/YVvbNvZ07WFX\n5y72dO5hd+duXjz4InGjt0tJt+5mdvls5gTsoG4MNBJwBdjWvi0bvOGo3RWoQjG3Yi6nzjyVJTVL\nWFKzhMXVi/v0ANYcaqbp5KYBbTJMg6Pxo4SjYVqjrYSioWxYt0Zb2dS6iS8/+2Xu+Nsd/N1xf8dl\nCy+bEn1vv3TwJb787JfpSnRx62m3ctnCy4p+3HBpzVIe/uDD/Oeb/8l/vvGfvHTgJW49/VbOPfbc\nUa8zaSZpaW9hw5ENhKNhTqw9kZV1K/G7JuY//XSnlEqfIa9TNYb1xJJGb1BHknREE7y6cROLFi0m\nnYvZMMjkgdV/ntUbli5HpktY+4x9j8PebZ4JLJcTOhIhDkb2cKDH/u7Y3bkbheITSz7Be2a9p6B/\n/5Zl0RVPcbgjxqHOGIc6YhzuzEzHOdwZ462DnYS744MGWiEyhxG8Tp1YIsVzB3YRH+rHzBQS8Dh4\n4/bzJ+S9JIwnQbmrnFX1q1hVv6rPfNMyORI50ieg93TuYUfHDp7Z9wwp0+68QlMa8yrmccYxZ7Ck\nZgnHVx/P4urFo96trGs6Nd6aIfvSNi2Tlw6+xG+2/Yb737qfezffy5nHnMlliy5jTcOaIY/BjpeU\nmeKnG37KL978BY0Vjfz8fT9nYdXCcXs/p+7k+hOv55xjz+HW52/lprU3cWHjhXz51C9T5Rn567w9\n1s7G0EY2hjay4cgGNoU3ETNigP23NC0TXeksDS7l1PpTOWXmKZxYeyIex8idnojJ43Hq1Ffo1Ff0\n/p084W00rRrbD9X2WDu7O3ezs2Mnu4/szobuns49JMzeM/D9Tj+NgUbCsTDXP3U9/7e9ew+Oq7oP\nOP793d3VrnYlrSRbL8uyZL1s7BqrgZEpiVwTBofiMHETcEvzRzrTCThDZmAyw7hpxm2Gmc60pC38\nkQ6xGZgkTSl1KA9PQtISipGhwcR2jG0wsixbNhLWCtBztZb2dfrHvVo9rJeNpNXj92F27lNXRz8f\n9rd7zrnnblq5id2bd9NQ2jCjpCwi9rgFn4eaoslbk2KJJB/3D9HRN5hK3P2DcfwZ9rfW4cF0malB\ndXZ/vd13by+97pEBdocOHWLbtm0YY1KT54xMlTuqGT4+sj4USxJLJu1R/2Oa3e2R/5ZzbWv4zgAZ\n300gGOcTxUgrwvAWV31gso8Y3Nb8ja/RZLyAWGJRHCimOFDMLSW3jDkWT8a5PHCZvqE+1gbXzmt/\nriUWt666lVtX3UpoIMQL517g+bPP8/DrD1PoL+Semnv4as1XKQpMMOvGLOsY6GBP4x6Odx5nZ/VO\nvlv/3XmLxfr89Ty741mePvU0+07u40jHEb635Xtsr9ieOieRTNDS25JKvO9+/C4X+y4C4BY36/PX\n87Xar1FXUEddYR253lze/fhdjlw+wjsd7/DM6Wd46tRTZFgZ1BXWUV9cz5aSLWxcufG6+r9V+sSS\nMcLRMOFYmIHYAP3R/jHLcCycOt4f7ac93E5rXyu9Q72pa7gtd6p1rKG0gfKcciqCFZTnlLPCtwIR\nIZaIcbDlIE+deooHX3uQDSs2sPvG3Wwr2zYrLUUel8Wq3ExW5WZ+5muNJiKpB8goEPNZ2x+u0803\n32yOHj06a9cb/rSlJjebMYon4zS2NXKg6QBvffQWLnGxrWwbu2p3ccuqW+ZkxPbrl15n7//tJZaI\nsfeP9vLlyi/P6vWvJT5NXU3sfWsvZ7rOcEf5HVTnVnOi8wSnPjlFOBYGIN+Xz40FN1JXUMfmgs1s\nXLmRTPfUb2gDsQGOhY6lkvMHXR8Adv/9TUU3saVkC/XF9azLXzcmxsYYoskog/FBrsSvjHmN3xdN\nRDGY1DgBuy/R+c9MsnTWz7eep7SslHgyPvIy8bHbo/YlkgliyZj9N3j8+N1+/B4/AU8gte53O9se\nPwG3vRy9P9ebuyBvWzLGEIqExozX+CD0AUl3knAsPKbLaTJucZOVkUXAE6A0q9ROtjkVVAQrqMip\nYFXWqhm3PMWSMX7R8gv2n9xPW7iN9fnr2X3jbm5bc9us/P94se8ijW2NNLY10trXSk5GDrneXILe\n4Jj1XG8uOV5nOyNIrs9eDs/Rv5zfq0XkmDHm5gmPaTJePuYqRh/2f8jPz/6cl5pfonuom7LsMu6t\nvZed1Ttn1Iw7nWgiyuPHHudnZ37GDfk38IM//gHlOeWzUPKxrjU+sWSMH5/+MU+++yTxZJyavBo7\n8RZupq6gjrLsss+cRLoHuzkaOsqRy0c4cvkIrX2tgP0M7eyM7FSiHUwMTjgIb7YJgttyp14ey4Nb\n7HWX5Ro5Js4xZz/AldgVBuIDRGIRIrEIA/GBGZU5053J2uBaqoJVVOZWptZXZ6+ety6S8Yn3vU/t\nyWO6BruAka6j7Gg21auryfJkpZLs8HqWJ+uq/V6Xd9Y/aMSTcX55/pfsP7mfS/2XqM2rZffm3dy+\n5vZrSsqxRIyjoaM0tjVyuP1wqoWnKljFhhUbCMfC9A710jvUS89QD71DvcRNfNLr+d1+gt4g3piX\nmpIaigPFFPmLKAoUUey3WwRXZq6c926v+aTJWAFzH6NoIsqrF1/lQNMBjncex2N52Fywmdq8Wmry\naqjNq6U6t/qampUv9V3ikcZHeP/T9/n6DV/nOzd9Z85GdF9vfHoGe3Bb7nkZgBUaCPFOxzscCx1j\nMDFIpjuTTHcmPpcPv8ePz+Wzt92+1LHUOc6+DCsDy7LsfjfE6Vcb7nOzUtti33vj3CZjn//GG2/M\nWh0yxjCUGCISjzAQc5J03EnUsQEi8QjhaJi2cBvne87T0ttCZ6Qz9fMey0N5TrmdnHOrqAxWUhms\npCJYgdd1/bd+DSfe4YQ7/BqfeIcHSm5csZHavFr8Hv+Ceh+KJ+P86sKv2H9yP619rVTnVvPA5gfY\nXr590qT8ceRjDrcfprGtkd9+9Fsi8QgZVgb1JfVsXb2VhtIGVmevnvBnjTFE4pFUcu4Z6qFvqC+V\nqIeXTR81Ec2I0jHQkRo7McwSi5WZKyn2F1MUKKLIX2Qn7UARORk5RBNRBhOD9jI+yFBiaOQVH2Iw\nMXjVdiwRI+gNUugvHPMBoNBfSGFm4bw+VW+qZLx0P4KoeZfhymBH5Q52VO6gubuZF5pf4OQnJ3np\n3EtE4pHUeWXZZdTk1qQSdE1eDWuy11x1v/Ur51/h0bcfxSUunrjtic80gnkuzeetTkWBIu6uuntJ\nTKsqIvjcPnxuH/m+/Ol/AAhHw1zovUBLbwvne89zoecCTV1NvHbptdS3bEssSrNKKQmUYDAkkgni\nxm4yT5pkaj1hEnZTukmQTDr7TYJoIpqaKtUSi6rcKhpKG1LJd13+umm7GxYCt+Xm7qq7uWvtXfy6\n9dfsO7mPR954hB8Ff8T9N97Plyq+hIhw+pPTqebnM11nACjyF7GjcgdbV2+lvrh+Rh+gRYSAJ0DA\nE2BV1qpJzxs9gKsv2kfHQAehSCi1DA2E6Ih00NzdzJvtb6b+LabjdXnHvHxuH16XF4/l4Wz3WQ63\nH57wWit8K1LJOZX8/SPb5Tnl89JNoslYzYmavBr21O8B7NHY7eF2mrubOdt9NrU81HYo9QbqdXmp\nyq2iJtdO0Od6zvHiuRepK6jjsa2PUZJVks4/Ry0QWRlZbCrYxKaCTWP2DyWGaO1tHUnUPefpjHTi\nslx4LA8+y4clFm6xm81d4hpZit28PnpfWXbZokq8U3FZLnZU7uDOijt59eKr7Du5jz2H9/DDEz9k\nIDZA12AXllhsLtjMQ597iIbSBmrzauc8AYkIQW+QoDfIuvx1E54znLBDkRD90f6RROvy4XWPTb7T\nldcYQzgWJjQQspP+8MvZ/ij8Eb/v/P2YAXQBT4C3/+LtWf27J6PJWM05SyzKsssoyy7ji2u+mNo/\nGB+kpbeF5u7mVIJ+s/1NXm55GUH45qZv8q26b+koYjUtr8vLuvx1k76pKzsp37n2TrZXbOc3F3/D\nc03PUZBZwNbVW/n8qs8vyMlsRifs2bhWdkY22RnZVOdVT3relfgVOiOddEY66Y/2f+bfO1OajFXa\n+Nw+Nq7YyMYVY+fp/vTKpwwlhqZs6lJKXR9LLLZXbB9zS54akenOTM2COJ80GasFZ7LJR5RSaqla\nmo/vUUoppRYRTcZKKaVUmmkyVkoppdJsRslYRO4UkSYROScifz3Bca+I/Kdz/IiIVMx2QZVSSqml\natpkLCIu4F+BPwE2APeJyIZxp/0V0G2MqQYeB/5xtguqlFJKLVUz+WZcD5wzxpw3xkSB54CvjDvn\nK8BPnPXngdtlIc7srpRSSi1AM7m1qRT4cNR2G7BlsnOMMXER6QVWAJ/MRiGnc/jAWS6cStJ97Ph8\n/LpFq6dHYzQVjc/0NEZT0/hMbzHFaGVZFg275u5Z6aPN633GInI/cL+zGRaRplm8/ErmKfkvYhqj\nqWl8pqcxmprGZ3qLK0Z/NqtXm3QmkZkk43agbNT2amffROe0iYgbCAKfjr+QMWY/sH8Gv/OaicjR\nyZ6GoWwao6lpfKanMZqaxmd6GqOJzaTP+HdAjYisFZEM4M+Bg+POOQh8w1m/B/hfk65nMyqllFKL\nzLTfjJ0+4G8D/w24gGeMMe+JyKPAUWPMQeBp4N9E5BzQhZ2wlVJKKTUDM+ozNsa8Arwybt/fjlof\nBO6d3aJdszlp/l5iNEZT0/hMT2M0NY3P9DRGExBtTVZKKaXSS6fDVEoppdJsSSTj6abrXO5EpFVE\nTonICRE5mu7yLAQi8oyIdIrI6VH78kXkVRFpdpZ56Sxjuk0So++LSLtTl06IyF3pLGM6iUiZiLwu\nIu+LyHsi8pCzX+sRU8ZH69AEFn0ztTNd51ngDuwJSX4H3GeMeT+tBVtARKQVuNkYs3ju7ZtjIrIV\nCAM/Ncb8gbPvMaDLGPMPzoe6PGPMnnSWM50midH3gbAx5p/SWbaFQERKgBJjzHERyQaOATuBv0Tr\n0VTx2YXWoasshW/GM5muU6kxjDGN2CP/Rxs9retPsN84lq1JYqQcxpjLxpjjzno/cAZ7NkKtR0wZ\nHzWBpZCMJ5quU//BxzLA/4jIMWcWNDWxImPMZWe9AyhKZ2EWsG+LyEmnGXtZNsGO5zyp7g+BI2g9\nusq4+IDWoasshWSspvcFY8znsJ+89aDT/Kim4Exas7j7cObGk0AVUAdcBv45vcVJPxHJAv4LeNgY\n0zf6mNajCeOjdWgCSyEZz2S6zmXNGNPuLDuBF7Gb9tXVQk4/13B/V2eay7PgGGNCxpiEMSYJPMUy\nr0si4sFONP9ujHnB2a31yDFRfLQOTWwpJOOZTNe5bIlIwBk8gYgEgO3A6al/atkaPa3rN4CX01iW\nBWk4yTj+lGVcl5zHxD4NnDHG/MuoQ1qPmDw+WocmtuhHUwM4Q+OfYGS6zr9Pc5EWDBGpxP42DPaM\na89qfEBE/gPYhv0EmRDwd8BLwAFgDXAR2GWMWbYDmCaJ0Tbs5kUDtAIPjOofXVZE5AvAYeAUkHR2\n/w12v+iyr0dTxOc+tA5dZUkkY6WUUmoxWwrN1EoppdSipslYKaWUSjNNxkoppVSaaTJWSiml0kyT\nsVJKKZVmmoyVUkqpNNNkrJRSSqWZJmOllFIqzf4fK1L7BGRsK8YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the vertical range to [0-2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OE8dO3tnRSLl",
    "outputId": "c282feb0-12e0-476d-8537-f160e14062ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_cnn = model_cnn.predict_classes(X_train_cnn)\n",
    "model_pred_cnn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1UKq5p5vRSF5",
    "outputId": "3c3885b0-446e-40f9-b053-72a8cac2eb55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_cnn_cv = model_cnn.predict_classes(X_valid_cnn)\n",
    "model_pred_cnn_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6ueed-qdRSAh",
    "outputId": "61cdeff4-57a2-4437-e34d-551ca5383fed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert the training labels back to single digits rather than one hot encoding\n",
    "\n",
    "rounded_labels_cnn=np.argmax(y_train_cnn, axis=1)\n",
    "rounded_labels_cnn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d6yuWTrkRR6E",
    "outputId": "0d3ce784-cbb6-43dd-8b11-20f55f74e306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert the cross-val labels back to single digits rather than one hot encoding\n",
    "\n",
    "rounded_labels_cnn_cv=np.argmax(y_valid_cnn, axis=1)\n",
    "rounded_labels_cnn_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PlQDmDhsRqtY",
    "outputId": "113c240a-d4c0-4fef-9fb8-68f0fe1acc57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.994462962962963\n",
      "Cross-Val Accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "## Comparing accuracy scores from training data and cross-val data\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_acc_cnn = accuracy_score(rounded_labels_cnn, model_pred_cnn)\n",
    "model_acc_cnn_cv = accuracy_score(rounded_labels_cnn_cv, model_pred_cnn_cv)\n",
    "\n",
    "print(\"Training Accuracy:\", model_acc_cnn)\n",
    "print(\"Cross-Val Accuracy:\", model_acc_cnn_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoZw4IW1nDhX"
   },
   "source": [
    "Here we evaluate our model and obtain the accuracy score between our train and validation split of our training data. The accuracy of 0.9945 was obtained, indicating that it should do fairly well on the subset of test data we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ME0dpMsSRqq6",
    "outputId": "1dc179f9-dc46-478f-fea6-dc00ad9d29fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5375,   19,    1,    0,    0,    0,    0,    2,    3,    0],\n",
       "       [  51, 5340,    0,    2,    0,    2,    0,    3,    0,    2],\n",
       "       [   1,    0, 5393,    4,    0,    1,    0,    0,    0,    1],\n",
       "       [   2,    0,    2, 5345,    0,   10,    0,   40,    1,    0],\n",
       "       [   0,    0,    0,    0, 5383,   14,    0,    1,    1,    1],\n",
       "       [   0,    0,    0,    0,    0, 5400,    0,    0,    0,    0],\n",
       "       [   0,    0,    1,    0,    0,    0, 5292,   59,    0,   48],\n",
       "       [   0,    0,    3,    3,    0,    0,    5, 5389,    0,    0],\n",
       "       [   1,    0,    0,    0,    1,    0,    0,    0, 5395,    3],\n",
       "       [   1,    0,    0,    0,    0,    0,    9,    1,    0, 5389]])"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Implementing confusion matrix to evaluate the classified digits in the training data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_cnn_cm = confusion_matrix(rounded_labels_cnn, model_pred_cnn)\n",
    "model_cnn_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "MzWdkoeXRqoa",
    "outputId": "e403569d-03c4-4a03-f184-0f5d2a505c25"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEcCAYAAAAPyOtuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZ7klEQVR4nO3debRdZX3G8e+TAUIYAiGAJAFCq4CU\ngsEoyFQEtEwOtVRAaAGrEUVApbVoaVEElwO2shxQwCrKJAJOgAwiCChDQkCmgCAgSEgJ82hJyK9/\nvO8N+x7ucM6bu89w83zWyso9e3j375yz93P2vBURmJmVGNPpAsysdzlAzKyYA8TMijlAzKyYA8TM\nijlAzKzYqAoQSatI+rmkpyX9aDnaOUDSZSNZWydI+oWkgzpdh3WOpE9LOq2u9jsSIJLeJ2mupOck\nPZJn9B1GoOl9gPWAtSPiH0obiYgzI+LtI1BPP5J2lhSSftzQfavc/aom2/mMpDOGGy4i9oiI0wvq\nPFjSta2O126SrpL05zwfPSbpAknrd7qukdLs91wZfmdJf6p2i4jPR8QHRr66pO0BIukTwFeBz5MW\n9g2BbwLvGoHmNwJ+HxFLRqCtuiwC3iJp7Uq3g4Dfj9QElIyqtcshfDQiVgNeC6wGnDjSE5A0bqTb\nHDUiom3/gEnAc8A/DDHMyqSAWZD/fRVYOffbGfgTcBTwKPAIcEju91ngJWBxnsY/A58Bzqi0PQMI\nYFx+fTBwH/AscD9wQKX7tZXxtgPmAE/n/7er9LsK+Bzwm9zOZcCUQd5bX/3fAg7L3cYCDwP/CVxV\nGfYk4CHgGeAmYMfcffeG9/m7Sh0n5DpeJC1QVwEfyP1PBs6vtP9F4ApAA9TZ+P4fAP4VuBV4HvgO\nKfx/kd/zL4G1KsP/CFiYP6+rgb+q9Fsb+Hl+X3OA4xumtRlwOfAEcDfw3iHmlWXvL7/+CHBHM20B\n38vfw+X5Pfwa2KjSP4DDgHuA+3O3vYFbgKeA3wJbVob/t/w9PpuntWvuPgY4GvgD8DhwLjC5YX48\nCHgQeAz492G+50OA+Xk69wEfyt1Xzd/70jz8c8BUXr0MvBO4I7+Hq4DXN3zP/5K/56eBHwIThlym\n2xwguwNLyAvwIMMcB1wPrAusk7+oz1UWwCV5mPHAnsAL5Jl3gA+r8XXfFzYuf+DPAJvmfuuTZ3Qq\nCxAwGXgS+Mc83v759dqVmfgPwCbAKvn1F4YJkO2AG3K3PYFLgQ/QP0AOJC1s40iBubDvy2x8X5U6\nHgT+Ko8znv4BMpG0lnMwsCNpZp0+SJ3L3n9lxrqeFBrTSOE9D5gJTAB+BRxbGf79wOq88mNwS6Xf\nOfnfRGBzUkj2fdar5teH5PcwM9e5+XABkj+rXwI/baYtUoA8C+yU6zyp4T0HKVwm5+91Zn7f25BC\n/6D8uawMbJqnNbUyn/1l/vvI/NlNz8N+Gzi7YX48NU9jK+D/yAv1IN/zXsBfAgL+hjT/b12dvxqG\nX9YGaR59Hngbaf74JHAvsFLle76RFDyTSUF1aDcFyAHAwmGG+QOwZ+X13wIPVD6gF6kEUP5Sty0M\nkKeAvwdWGWwBIgXHjQ39rwMOrszEx1T6fQS4ZKgAyX/fk2e8c/Ln0i9ABhj3SWCrYQLkuMEWsPx6\nG9Kv8R+B/YeY1rL3X5mxDqi8Ph84ufL6cOAng7S1Zv7MJ5EWvMXk0M79l62BAPsC1zSM/20q4TTA\n+3uB9GsZpLWDDZtpixQg51T6rQa8DGyQXwewS6X/yeQfskq3u0kL8WtJ8+FuwPiGYeaT10by6/Xz\nZzCuMj9Or/S/EdhvsO95gM/gJ8CRjfPXQMsA8B/AuZV+Y0hrTTtXvucDK/2/BHxrqOm3ezv5cWDK\nMNuUU0kzeJ8/5m7L2oj++zheIH35LYmI50kz2aHAI5IukrRZE/X01TSt8nphQT0/AD4KvBX4cWNP\nSf8iaX4+ovQUaQGcMkybDw3VMyJuIK32irQq3Yr/rfz94gCvV8t1j5X0BUl/kPQMaaaEVPs6pAWn\nWmf1742AbSQ91fePFK6vGaKuIyJiErAlsBbpl77ZtpZNOyKeI4Xr1IH65/aOamhvA9Jax73Ax0gL\n66OSzpE0tTLejyvjzCcF1XqVtpuefyTtIel6SU/k9vZk+PmiT795OSKW5vdYPC+3O0CuI62ivXuI\nYRaQPvQ+G+ZuJZ4nrSr36TcjRsSlEfE20q/CXaRVyeHq6avp4cKa+vyAtLZycUS8UO0haUfS6uV7\nSZtna5J+ZdVX+iBtDta9r93DSKvRC3L7dXgfaYf4bqTQm9E3edIO5CW8spBDWgj7PAT8OiLWrPxb\nLSI+PNxEI+I20trMNySpybaWTVvSaqTV9uq8Vv08HwJOaGhvYkScnad/VkTsQJpXgrSPqW+8PRrG\nmxARzcw//b5PSSuT1v5OBNbL88XFDD9f9Ok3L+fPaQOWY15ua4BExNOknYXfkPRuSRMljc+p+qU8\n2NnAMZLWkTQlD9/0oawGtwA7SdpQ0iTgU309JK0n6V2SViWF2nOkHVCNLgY2yYeex0nal7TtfmFh\nTQBExP2k1d9/H6D36qQFbREwTtJ/AmtU+v8vMKOVIy2SNiEtYAeSNss+KekNheUPZXXS5/k4Kbw/\n39cjIl4GLgA+k7/7zYB/qox7Iemz/sc8X4yX9CZJr29y2qeTftnf2WRbe0raQdJKpB3h10fEYGtx\npwKHStomH+VaVdJeklaXtKmkXfIC/mde2ZkJaUftCZI2AsjzdbNHHBu/55VIPwCLgCWS9gDe3jD8\n2nleH8i5wF6SdpU0nrRv7f9I+xmLtP1QX0R8BfgEcAzpg3iItCr/kzzI8cBc0p7g20g7644vnNbl\npD3Jt5KOZFQX+jG5jgWkVde/AV71SxcRj5P2vh9FWig+CewdEY+V1NTQ9rURMdDa1aXAJaSdnn8k\nzZTVGbvvJLnHJc0bbjp5k/EM4IsR8buIuAf4NPCDPNOPpO/nmh8G7iTtQKz6KGnNZCFpLexs0kxM\nRDxLWiD2I30vC0m/5E3VGBEvkXaG/keTbZ0FHEv6/t9ICtfB2p4LfBD4Oml/1L2kfUXkNr9A2km7\nkHQAoO/H6iTgZ8Blkp7Nn8c2zbwfGr7n/J6OIAXBk6S1vZ9VaryL9HnelzeZqptjRMTd+T1+Ldf6\nDuAd+XMroryzxKwjJH0ReE1EHNTm6X6PtMPxmHZOd7RZUU42si4haTNJW+bNgDeTztd51U5k6w0+\nw87abXXSavZU0jb7V4CfdrQiK+ZNGDMr5k0YMyvmADGzYj0XIJJ2l3S3pHslHd3peoYjaQNJV0q6\nU9Idko7sdE3NyGeU3ixpuc53aRdJa0o6T9Jd+Qzet3S6puFI+nieJ26XdLakCZ2uqVU9FSCSxgLf\nAPYgncy1v6TNO1vVsJYAR0XE5sC2wGE9UDOki8Dmd7qIFpxEugZpM9JFaV1du6RppHM6ZkXEFqTr\nhPbrbFWt66kAAd4M3BsR9+WTX85hZO4jUpuIeCQi5uW/nyXN2NOGHquzJE0nXfVZ252sRlI+83In\n0m0GiIiXIuKpzlbVlHHAKvlEv4mUX7LRMb0WINPof0bmn+jyhbFK0gzSZeE3dLaSYX2VdMbtQKf2\nd6ONSWc1fzdvdp2WL1HoWvlamBNJt2B4BHg6InruNpq9FiA9K1+sdT7wsYh4ptP1DEbS3sCjEXFT\np2tpwThga9ItBmaSLqLs6v1jktYirT1vTDonZlVJg55K3616LUAepv/Vm9NZ/qtia5cvXDofODMi\nLuh0PcPYHninpAdIm4i7qIX7cnbIn0inpfet2Z1HCpRuthvpTmeLImIx6SLD7TpcU8t6LUDmAK+T\ntHG+gnI/KhcTdaN8yfR3gPkR8V+drmc4EfGpiJgeETNIn++vIqKrfxkjYiHwkKRNc6ddSRfydbMH\ngW3zVcki1dzVO34H0lOnskfEEkkfJV2tOhb4n4i4o8NlDWd70uXzt0m6JXf7dERc3MGaRqPDgTPz\nD8t9pFsZdq2IuEHSeaSrzZcANwOndLaq1vlUdjMr1mubMGbWRRwgZlbMAWJmxRwgZlbMAWJmxXo2\nQCTN7nQNrei1esE1t0Ov1duoZwME6LUPvtfqBdfcDr1Wbz+9HCBm1mFddSLZlClTYsaMGU0Nu2jR\nItZZZ52mhr3ppl66LsysMyJCww/VX1edyj5jxgzmzJkz4u2OGeMVLbM6eMkys2IOEDMr5gAxs2IO\nEDMr5gAxs2K1BkivPcPFzFpTW4D06DNczKwFda6B9NwzXMysNXUGSE8/w8XMhtfxnaiSZkuaK2nu\nokWLOl2OmbWgzgBp6hkuEXFKRMyKiFnNXttiZt2hzgDpuWe4mFlraruYrkef4WJmLaj1atz88CQ/\nQMlslOr4TlQz610OEDMr5gAxs2IOEDMr5gAxs2JddVNlSVHH/UsXL1484m32GTt2bG1tm7VTyU2V\nvQZiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFi\nZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWrOse69DpGlpV1+cntXyH\nfbPl4sc6mFlbOUDMrJgDxMyKOUDMrJgDxMyKOUDMrJgDxMyK1RYgkjaQdKWkOyXdIenIuqZlZp1R\n24lkktYH1o+IeZJWB24C3h0Rdw4xjk8ky3wimbVbV51IFhGPRMS8/PezwHxgWl3TM7P2G9eOiUia\nAcwEbhig32xgdjvqMLORVfu1MJJWA34NnBARFwwzrDdhMm/CWLt11SYMgKTxwPnAmcOFh5n1njp3\nogo4HXgiIj7W5DheA8m8BmLtVrIGUmeA7ABcA9wGLM2dPx0RFw8xjgMkc4BYu3VVgJRwgLzCAWLt\n1nX7QMxsdHOAmFkxB4iZFXOAmFkxB4iZFWvLqeyjWV1HS15++eVa2gUYO3ZsbW33mrq+v246ulkn\nr4GYWTEHiJkVc4CYWTEHiJkVc4CYWTEHiJkVc4CYWTEHiJkVc4CYWTEHiJkVc4CYWTEHiJkVaylA\nJK0lacu6ijGz3jJsgEi6StIakiYD84BTJf1X/aWZWbdrZg1kUkQ8A7wH+H5EbAPsVm9ZZtYLmgmQ\ncflB2e8FLqy5HjPrIc0EyHHApcC9ETFH0l8A99Rblpn1Aj8Xpkv5jmTt4TuSvaLkuTCD3tJQ0teA\nQT+FiDii1YmZ2egy1D1R57atCjPrSU1vwkiaGBEv1FqMN2GW8SZMe3gT5hW1PNpS0lsk3QnclV9v\nJembBfWZ2Sgz7BqIpBuAfYCfRcTM3O32iNhixIvxGkhb+IHgNpDaHq4dEQ81dKpv/drMekYzD5Z6\nSNJ2QEgaDxwJzK+3LDPrBc2sgRwKHAZMAxYAb8ivzWwF5xPJVkDeB2IDqesozF9I+rmkRZIelfTT\nfDq7ma3gmtmEOQs4F1gfmAr8CDi7zqLMrDc0cxj31ojYsqHb7yJiqxEvxpswbeFNGBvISF8LMzn/\n+QtJRwPnkK6N2Re4uNkJSBpLOi3+4YjYu9UCzax7DboGIul+UmAMlEoREU3tB5H0CWAWsMZwAeI1\nkPbwGogNZETXQCJi4+UrByRNB/YCTgA+sbztmVl3aeZEMiRtAWwOTOjrFhHfb2LUrwKfBFYfou3Z\nwOxm6jCz7jJsgEg6FtiZFCAXA3sA1wJDBoikvYFHI+ImSTsPNlxEnAKcksfxJoxZD2nmMO4+wK7A\nwog4BNgKmNTEeNsD75T0AGkH7C6Szigt1My6TzMB8mJELAWWSFoDeBTYYLiRIuJTETE9ImYA+wG/\niogDl6taM+sqzewDmStpTeBU4CbgOeC6Wqsys57Q0rUwkmYAawCPRcSCES/G+0DawodxbSAlh3GL\nLqaT9GBEbNjyiMO36wBpAweIDaS2GwoNwHOKmRUHiNcUzKzouTAC1qytIjPrGaXPhfEzY8zMdySz\nkeOds72tnTtRzcwcIGZWzgFiZsVKjsIAEBFH1FKRmfWM0qMwZmY+CmMjx0dhetuI3tKwj6R1gH/j\n1Xck26XViZnZ6NLMTtQzSc/C3Rj4LPAAMKfGmsysRzTzXJibIuKN1efDSJoTEW8a8WK8CdPTvAnT\n22rZhAEW5/8fkbQX6QHbk4cY3sxWEM0EyPGSJgFHAV8j3VDo47VWZWY9wUdhbMR4E6a31XUU5rsM\ncEJZRLy/1YmZ2ejSzCbMhZW/JwB/R9oPYmYruJY3YSSNAa6NiO1GvBhvwvQ0b8L0tnZdzv86YN2C\n8cxslGlmH8iz9N8HspB0ZqqZreCGDZCIGPTB2Ga2Yht2E0bSFc10M7MVz1D3A5kATASmSFqLV54F\nswYwrQ21mVmXG2oT5kPAx4CppGfi9gXIM8DXa67LzHpAMxfTHR4RX2tLMT6MawN46aWXamt7woQJ\nww9UYOnSpbW0CzBmzMjfiXTp0qW1HcZdKmnZg6QkrSXpI61OyMxGn2YC5IMR8VTfi4h4EvhgfSWZ\nWa9oJkDGqnIqoKSxwEr1lWRmvaKZa2EuAX4o6dv59YdyNzNbwTWzE3UMMBvYLXe6HDg1IkZ8L5F3\notpAvBO1v27aiVpyMd2OwH4RcVirE2uibQeIvYoDpL9uCpBmNmGQNBPYH3gvcD9wQasTMrPRZ6gz\nUTchhcb+wGPAD0lrLG9ttvF8+Pc0YAvSBXnvj4jrlqtiM+saQ62B3AVcA+wdEfcCSGr1XqgnAZdE\nxD6SViKdGm9mo8RQG1PvAR4BrpR0qqRdeeV09mHlGzHvBHwHICJeqp5PYma9b9AAiYifRMR+wGbA\nlaTrYtaVdLKktzfR9sbAIuC7km6WdJqkVUekajPrCsPuzo2I5yPirIh4BzAduJnmbig0DtgaODki\nZgLPA0c3DiRptqS5kvwwb7MeU9tjHSS9Brg+Imbk1zsCR0fEXkOM48O49io+jNtfNx3GHflKsohY\nCDwkadPcaVfgzrqmZ2bt19R5IMvhcODMfATmPuCQmqdnZm3kJ9NZ1/MmTH8rxCaMmY1+DhAzK+YA\nMbNiDhAzK+YAMbNiDhAzK+bDuLZCq/FM7FrarZMP45pZWzlAzKyYA8TMijlAzKyYA8TMijlAzKyY\nA8TMijlAzKyYA8TMijlAzKyYA8TMijlAzKyYA8TMijlAzKyYA8TMijlAzKyYA8TMijlAzKyYA8TM\nijlAzKyYA8TMio3rdAFmnVTX3dPrfNpBN93x3WsgZlbMAWJmxRwgZlbMAWJmxRwgZlbMAWJmxRwg\nZlas1gCR9HFJd0i6XdLZkibUOT0za6/aAkTSNOAIYFZEbAGMBfara3pm1n51b8KMA1aRNA6YCCyo\neXpm1ka1BUhEPAycCDwIPAI8HRGXNQ4nabakuZLm1lWLmdWjzk2YtYB3ARsDU4FVJR3YOFxEnBIR\nsyJiVl21mFk96tyE2Q24PyIWRcRi4AJguxqnZ2ZtVmeAPAhsK2mi0uWDuwLza5yembVZnftAbgDO\nA+YBt+VpnVLX9Mys/VTnfQtaJal7ijFbDr14P5CIaLlhn4lqZsUcIGZWzAFiZsUcIGZWzAFiZsUc\nIGZWzI91MKtBnY9eqOMQ8axZZVeSeA3EzIo5QMysmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMys\nmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMysmAPE\nzIp1213ZHwP+2OSwU/LwvaLX6gXX3A4t11vTHd83KhlJdT5FvE6S5kZE2b3oO6DX6gXX3A69Vm8j\nb8KYWTEHiJkV6+UAOaXTBbRoueqV9LKkWyTdLulHkiYuR1vfk7RP/vs0SZsPMugpknaWtF3BNB6Q\nNKXZ7oO0cbCkr7c46RnNtt8lem0+7qdnAyQieuqDH4F6X4yIN0TEFsBLwKHVnpKKdohHxAci4s5B\n+p0C7Ay0HCAd9FynC2hFr83HjXo2QFZw1wCvzWsH10j6GXCnpLGSvixpjqRbJX0IQMnXJd0t6ZfA\nun0NSbpK0qz89+6S5kn6naQrJM0gBdXH89rPjpLWkXR+nsYcSdvncdeWdJmkOySdBjR9qEDSmyVd\nJ+lmSb+VtGml9wa5xnskHVsZ50BJN+a6vi1pbEObq0q6KL+X2yXt2+JnbE3otsO4Noy8prEHcEnu\ntDWwRUTcL2k28HREvEnSysBvJF0GzAQ2BTYH1gPuBP6nod11gFOBnXJbkyPiCUnfAp6LiBPzcGcB\n/x0R10raELgUeD1wLHBtRBwnaS/gn1t4W3cBO0bEEkm7AZ8H/j73ezOwBfACMEfSRcDzwL7A9hGx\nWNI3gQOA71fa3B1YEBF75bontVCPNckB0jtWkXRL/vsa4DukTYsbI+L+3P3twJZ9+zeAScDrgJ2A\nsyPiZWCBpF8N0P62wNV9bUXEE4PUsRuweeVchDUkrZan8Z487kWSnmzhvU0CTpf0OiCA8ZV+l0fE\n4wCSLgB2AJYAbyQFCsAqwKMNbd4GfEXSF4ELI+KaFuqxJjlAeseLEfGGaoe88Dxf7QQcHhGXNgy3\n5wjWMQbYNiL+PEAtpT4HXBkRf5c3m66q9Gs8USlI7/P0iPjUYA1GxO8lbQ3sCRwv6YqIOG55irRX\n8z6Q0eVS4MOSxgNI2kTSqsDVwL55H8n6wFsHGPd6YCdJG+dxJ+fuzwKrV4a7DDi874WkvlC7Gnhf\n7rYHsFYLdU8CHs5/H9zQ722SJktaBXg38BvgCmAfSev21Sqp35mUkqYCL0TEGcCXSZt6NsK8BjK6\nnAbMAOYprRIsIi10PwZ2Ie37eBC4rnHEiFiU96FcIGkMaZPgbcDPgfMkvYsUHEcA35B0K2n+uZq0\no/WzwNmS7gB+m6czmFslLc1/nwt8ibQJcwxwUcOwNwLnA9OBMyJiLkAe9rJc62LgMPpfBvHXwJfz\ndBYDHx6iHivUs6eym1nneRPGzIo5QMysmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMys2P8Dk3b5\n5KGUPf4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(model_cnn_cm, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix Image Representation\", x=0.5, y=1)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "7ZTKOgmZR5aR",
    "outputId": "32638f5e-a63a-45a8-f5d6-ad0355596dd7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAEcCAYAAACrolO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCA4zMyuCw8zMiuAwM7Mi/H8IAU7CJEFrsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Now lets check where the errors are occuring most\n",
    "\n",
    "row_sums = model_cnn_cm.sum(axis=1, keepdims=True)\n",
    "norm_model_cnn_cm = model_cnn_cm / row_sums\n",
    "\n",
    "## Filling the leading diagonal with zeros to only keep the errors and plot results\n",
    "\n",
    "np.fill_diagonal(norm_model_cnn_cm, 0)\n",
    "plt.matshow(norm_model_cnn_cm, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix Image Representation of Errors\", x=0.5, y=1)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cwTcxOyoR5g2",
    "outputId": "49c79d37-060d-4d54-9606-6b6276e9f784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision: 0.9945047665704208\n",
      "Training Recall: 0.994462962962963\n"
     ]
    }
   ],
   "source": [
    "## Comparing precision and recall scores from training data\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Training Precision:\", precision_score(rounded_labels_cnn, model_pred_cnn, average='weighted'))\n",
    "print(\"Training Recall:\", recall_score(rounded_labels_cnn, model_pred_cnn, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxvtXa9To3rz"
   },
   "source": [
    "# 8.3 Convolutional Recurrent Neural Networks (CRNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWccWf0GCqc6"
   },
   "source": [
    "**8.3.1 Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "8DBoTvbbCfFW",
    "outputId": "9f565cc5-9e7d-47a5-d7b4-dda424ef8630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional, GRU\n",
    "\n",
    "model_crnn = keras.models.Sequential()\n",
    "model_crnn.add(keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model_crnn.add(keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = 'Same', activation = 'relu'))\n",
    "model_crnn.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model_crnn.add(keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "model_crnn.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model_crnn.add(keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model_crnn.add(keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = 'Same', activation = 'relu'))\n",
    "model_crnn.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_crnn.add(keras.layers.BatchNormalization()) \n",
    "\n",
    "model_crnn.add(keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "model_crnn.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model_crnn.add(keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model_crnn.add(keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model_crnn.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_crnn.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model_crnn.add(keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2)))\n",
    "model_crnn.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "#Start of the RNN part of the network. \n",
    "model_crnn.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "model_crnn.add(keras.layers.Bidirectional(GRU(128, return_sequences = True)))\n",
    "model_crnn.add(keras.layers.Flatten())\n",
    "model_crnn.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model_crnn.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model_crnn.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model_crnn.add(keras.layers.Dropout(0.25))\n",
    "model_crnn.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irRY4bmFnLhJ"
   },
   "source": [
    "CRNN was the final model created for this investigation. This was chosen to see if there could be any benefits drawn from the RNN, despite CNN's being the better performers for image analysis and classification. The CNN part of the model is identical to the original CNN.\n",
    "\n",
    "With reference to the RNN phase of our model, the features from the CNN are fed to a Bidirectional gated current unit (GRU). This means that it is essentially two seprate RNN's, where one is fed with an input sequence in normal time order, while the other is in reverse time order. The idea was that the RNN part of the architecture would be able to add another level of learning to our model as it can learn temporal information, unlike the CNN that only consumes spatial information. This was intially thought to be of benefit as it would allow the model to a predict subsequent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "klhMLyUCCfCP",
    "outputId": "e7e6e71f-f426-4042-dbd2-c8fd1ad8908b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 7, 384)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 7, 256)            393984    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               229504    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 921,354\n",
      "Trainable params: 920,970\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_crnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "tuJ50XzvB1b6",
    "outputId": "222c69b3-9037-463c-9e12-91e1c7f23309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f95869528d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f951a587b00>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f951a587ac8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f951a593400>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f951a54ce10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f951a593278>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f951a4e30f0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f951a4f9860>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f951a55b940>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f951a4f3160>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f951a4f31d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f951a4fd908>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f951a4c8da0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x7f951a4bfc88>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f951a4db908>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f951a4d1940>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f951a487128>,\n",
       " <tensorflow.python.keras.layers.wrappers.TimeDistributed at 0x7f951a42dda0>,\n",
       " <tensorflow.python.keras.layers.wrappers.Bidirectional at 0x7f951a43b748>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7f951a425320>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f951a39e7f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f951a4632b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f951a2ae828>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f951a44c550>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f951a44c588>]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_crnn.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6abfoo_FB1mJ"
   },
   "source": [
    "**8.3.2 Compiling the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTupYVk6B12E"
   },
   "outputs": [],
   "source": [
    "model_crnn.compile(loss = \"categorical_crossentropy\", # as we are using one-hot encode for the label data\n",
    "              optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              #optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUng-OMZBvjY"
   },
   "source": [
    "**8.3.3 Fitting the Model to the Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AS_TiA1dAzii",
    "outputId": "c9ab2a57-53af-489a-9201-01bbf149872e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "105/106 [============================>.] - ETA: 0s - loss: 1.0420 - acc: 0.6380Epoch 1/100\n",
      "106/106 [==============================] - 24s 230ms/step - loss: 1.0361 - acc: 0.6403 - val_loss: 2.3133 - val_acc: 0.1028\n",
      "Epoch 2/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.2820 - acc: 0.9157Epoch 1/100\n",
      "106/106 [==============================] - 17s 163ms/step - loss: 0.2814 - acc: 0.9159 - val_loss: 1.6791 - val_acc: 0.4342\n",
      "Epoch 3/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9411Epoch 1/100\n",
      "106/106 [==============================] - 18s 167ms/step - loss: 0.2039 - acc: 0.9412 - val_loss: 0.3391 - val_acc: 0.8918\n",
      "Epoch 4/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9493Epoch 1/100\n",
      "106/106 [==============================] - 18s 167ms/step - loss: 0.1732 - acc: 0.9494 - val_loss: 0.0722 - val_acc: 0.9767\n",
      "Epoch 5/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9554Epoch 1/100\n",
      "106/106 [==============================] - 18s 168ms/step - loss: 0.1485 - acc: 0.9554 - val_loss: 0.0733 - val_acc: 0.9790\n",
      "Epoch 6/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9602Epoch 1/100\n",
      "106/106 [==============================] - 18s 167ms/step - loss: 0.1328 - acc: 0.9602 - val_loss: 0.0553 - val_acc: 0.9855\n",
      "Epoch 7/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9634Epoch 1/100\n",
      "106/106 [==============================] - 18s 168ms/step - loss: 0.1234 - acc: 0.9633 - val_loss: 0.0644 - val_acc: 0.9852\n",
      "Epoch 8/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9658Epoch 1/100\n",
      "106/106 [==============================] - 17s 163ms/step - loss: 0.1137 - acc: 0.9658 - val_loss: 0.0562 - val_acc: 0.9852\n",
      "Epoch 9/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9671Epoch 1/100\n",
      "106/106 [==============================] - 18s 165ms/step - loss: 0.1078 - acc: 0.9671 - val_loss: 0.0329 - val_acc: 0.9908\n",
      "Epoch 10/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9690Epoch 1/100\n",
      "106/106 [==============================] - 18s 168ms/step - loss: 0.1017 - acc: 0.9690 - val_loss: 0.0430 - val_acc: 0.9902\n",
      "Epoch 11/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9690Epoch 1/100\n",
      "106/106 [==============================] - 18s 170ms/step - loss: 0.1013 - acc: 0.9691 - val_loss: 0.0401 - val_acc: 0.9908\n",
      "Epoch 12/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9710Epoch 1/100\n",
      "106/106 [==============================] - 18s 168ms/step - loss: 0.0948 - acc: 0.9710 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "Epoch 13/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9720Epoch 1/100\n",
      "106/106 [==============================] - 18s 167ms/step - loss: 0.0949 - acc: 0.9720 - val_loss: 0.0539 - val_acc: 0.9885\n",
      "Epoch 14/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9738Epoch 1/100\n",
      "106/106 [==============================] - 18s 169ms/step - loss: 0.0866 - acc: 0.9739 - val_loss: 0.0428 - val_acc: 0.9898\n",
      "Epoch 15/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9744Epoch 1/100\n",
      "106/106 [==============================] - 17s 164ms/step - loss: 0.0866 - acc: 0.9744 - val_loss: 0.0333 - val_acc: 0.9908\n",
      "Epoch 16/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9748Epoch 1/100\n",
      "106/106 [==============================] - 18s 169ms/step - loss: 0.0832 - acc: 0.9748 - val_loss: 0.0446 - val_acc: 0.9898\n",
      "Epoch 17/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9757Epoch 1/100\n",
      "106/106 [==============================] - 18s 166ms/step - loss: 0.0828 - acc: 0.9757 - val_loss: 0.0436 - val_acc: 0.9903\n",
      "Epoch 18/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9760Epoch 1/100\n",
      "106/106 [==============================] - 18s 170ms/step - loss: 0.0832 - acc: 0.9760 - val_loss: 0.0313 - val_acc: 0.9922\n",
      "Epoch 19/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9760Epoch 1/100\n",
      "106/106 [==============================] - 18s 169ms/step - loss: 0.0788 - acc: 0.9760 - val_loss: 0.0716 - val_acc: 0.9838\n",
      "Epoch 20/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9762Epoch 1/100\n",
      "106/106 [==============================] - 17s 164ms/step - loss: 0.0774 - acc: 0.9762 - val_loss: 0.0456 - val_acc: 0.9905\n",
      "Epoch 21/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9776Epoch 1/100\n",
      "106/106 [==============================] - 18s 173ms/step - loss: 0.0720 - acc: 0.9776 - val_loss: 0.0386 - val_acc: 0.9910\n",
      "Epoch 22/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9772Epoch 1/100\n",
      "106/106 [==============================] - 18s 168ms/step - loss: 0.0740 - acc: 0.9773 - val_loss: 0.0448 - val_acc: 0.9913\n",
      "Epoch 23/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9781Epoch 1/100\n",
      "106/106 [==============================] - 18s 166ms/step - loss: 0.0737 - acc: 0.9781 - val_loss: 0.0318 - val_acc: 0.9915\n",
      "Epoch 24/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9796Epoch 1/100\n",
      "106/106 [==============================] - 17s 162ms/step - loss: 0.0690 - acc: 0.9796 - val_loss: 0.0327 - val_acc: 0.9927\n",
      "Epoch 25/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9784Epoch 1/100\n",
      "106/106 [==============================] - 18s 169ms/step - loss: 0.0703 - acc: 0.9783 - val_loss: 0.0524 - val_acc: 0.9855\n",
      "Epoch 26/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9787Epoch 1/100\n",
      "106/106 [==============================] - 18s 166ms/step - loss: 0.0700 - acc: 0.9787 - val_loss: 0.0442 - val_acc: 0.9897\n",
      "Epoch 27/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9789Epoch 1/100\n",
      "106/106 [==============================] - 17s 162ms/step - loss: 0.0683 - acc: 0.9791 - val_loss: 0.0365 - val_acc: 0.9915\n",
      "Epoch 28/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9796Epoch 1/100\n",
      "106/106 [==============================] - 17s 164ms/step - loss: 0.0676 - acc: 0.9796 - val_loss: 0.0360 - val_acc: 0.9922\n",
      "Epoch 29/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9803Epoch 1/100\n",
      "106/106 [==============================] - 17s 165ms/step - loss: 0.0648 - acc: 0.9802 - val_loss: 0.0433 - val_acc: 0.9898\n",
      "Epoch 30/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9792Epoch 1/100\n",
      "106/106 [==============================] - 18s 173ms/step - loss: 0.0672 - acc: 0.9793 - val_loss: 0.0405 - val_acc: 0.9902\n",
      "Epoch 31/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9792Epoch 1/100\n",
      "106/106 [==============================] - 18s 173ms/step - loss: 0.0660 - acc: 0.9792 - val_loss: 0.0477 - val_acc: 0.9862\n",
      "Epoch 32/100\n",
      "105/106 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9803Epoch 1/100\n",
      " 11/106 [==>...........................] - ETA: 4s - loss: 0.0431 - acc: 0.9906\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "106/106 [==============================] - 19s 175ms/step - loss: 0.0644 - acc: 0.9804 - val_loss: 0.0416 - val_acc: 0.9907\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_crnn.fit_generator(train_gen.flow(X_train_crnn, y_train_crnn,batch_size=512), epochs=100, \n",
    "                                        validation_data=valid_datagen.flow(X_valid_crnn, y_valid_crnn,batch_size=512), \n",
    "                                        callbacks=[learning_rate_reduction, early_stopping_lr], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HW2P7U1Bpi3"
   },
   "source": [
    "**8.3.4 Evaluating the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "FLZ7fxEhAzfZ",
    "outputId": "f97d5bde-63ee-4f5e-b9a2-98697d20b238"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZhcVZ3w8e+5Sy29VC/p9JKks0DS\nCVlkiwgiEFyBUXAckUEd0XfEV8ddx5HXfdDRUXz1dRsdxnFBZQBFBhxZfIQ0QQFlEchKJyTpdCed\nrt732m6d949bVV29V3VXpZuq3+dJPXe/depWun73LPccpbVGCCGEEIvHWOwECCGEEMVOgrEQQgix\nyCQYCyGEEItMgrEQQgixyCQYCyGEEItMgrEQQgixyOYMxkqpHymlgkqpPTNsV0qpbyulDimlnlNK\nnZP7ZAohhBCFK5Oc8U+Ay2bZfjmwIfF6D/D9hSdLCCGEKB5zBmOt9S6gd5ZdrgJu0a7HgUqlVEOu\nEiiEEEIUulzUGa8E2tKW2xPrhBBCCJEB61S+mVLqPbhF2fj9/nMbGxtzdu7gaJxoHFaWLfz+oifW\nQ1iHWWGvyEHKTq14PI5hFHe7PLkGLrkOcg2S5DosjWvQ0tLSrbVePt22XATj40B6VF2VWDeF1vpm\n4GaA7du36yeffDIHb+96x3cf4MCAyZ8//eoFn+vzj36eP7T/gQff8mAOUnZqNTc3s2PHjsVORorW\nGqe/n+iJE8SHhlGmAaY1aWqiEi8mT5VCOw44DtqJgxMbn8bj6FgssW18n2effoqXbNmCjkbR0Rg6\nFnPnY1F0NAqxmLs+GnW3xaKgwQyUY1ZUYFRUYE56KZ8PpVRuronjjKcpmZ5YWnqiiTSl0ue418my\nUJaNsi2UbaMsC2VZYNsTlpVtg2nycHMzl1xyiXtd4nGIx91rp+MzrotHIuhQiPhYCB0aIx4KpZbj\nobHxbeHxdVZVFd4NG/Bu2IDn9NMxPJ6cXKfU9dIap7ubWG8fxMfT7X4G7a5LfAbtOO62xOfa89xz\nbNmyGeIatHb3icfdZbS7X9ydouNorcf3xZ1qnTyWxDTZn3/a9rhOfZ8TXpHIjOvQGnvVSjxr1+JZ\nuxbvunXYq1fn/PqB+7twySte4X6fY2nfayhEfGwsNZ/+3etYbMLfnHZiMGHqjP/tJb4D5bExSkox\nSkowShPT9PnSUozStHV+P8qyxq9x8ruD8fm074q4+x0ZPh+G35/1Ncjkt1FrTXxoiFh3N/GhIfxn\nnjmfSz4tpVTrTNtyEYzvAT6glLoNeBkwoLXuyMF5s1JiKQZD0Zycy2t6CTmhnJyr0MUjEWInTxI9\n0UH0xAmiHSeIdnQQO9FBtMN96dCpvZZVTKw3mZNpulPHmXEXZdsYlYngHHCnRlkZODE3gEUi6HBi\nmvaKRyPoSOIHOBx2f4Tj8YV8vIzVAQfydG5l2yi/H8PrJdbfD9HE355p4lmzxg3OTRvGg/Tq1e7N\n1Qy04xDtOEn0WCuRY21Ejh0j2naMSOsxIu3t6NHReaWzkhlyBvmUuCGa9uXxpOaJxxl+eBfOnb8e\nP9YwsFesSAXo8UC9FquhAZXI2WmtiQ8MEOvtxenpIdbTS6y3B6e7x5329I5v6+ujdniYA7P8/86Y\nbaMMY/obZ9N0/8+PjJySv3nl92NVVWFWV2Muq8aqqsasrsaqrsKsXoZZXYVVnVxXDZEIkfbjON1d\nxLq73VdX9/h8dxdOYllHIgAYFRVs/NPjef8skEEwVkr9F7ADqFFKtQOfB2wArfUPgHuBK4BDwCjw\nrnwldjYlNoSiccIxB6818x99Jnymj7ATzlHKck9rTSzYRbS9jcixNqJtbUTa2oi2t1Pd3c2Rb38H\nDAMMw83NKZVYVihlpJaVoSC5nF0CcIaGiHacwOnqnrLZXF6D3bACb1MTZZdcgr2iAauhATNQMZ6L\nme5uOx5HxxJ32clpPI4yLTAN1Aw56gk5a8Pkmd3Pcc5556XlJBO5SSstR2nb7g+LZaEMA601enQU\nZ2Ag8RpMTPtxBgaIDw7i9A+ktkc7OogPD7vHezwor9ed+rwYgXIMjwdle9x1E17JXGxabta2xn/A\nrcQ6T1rO17TcXFsqpz85Rz0pl5/IZR9tbWXtaae5P+CG6V4zZbjXcoZ1yuPF8PtQXp879fknLBs+\nn1tKkBZYdTRKpLWVcEsLoYMHCR88SOjAfoZ+97tULlJ5vXhPPz0RpJtQtpUIuq1Ej7UROX58PKAD\nyuPBbmzE09hI6QXnYzeuxqpZ5n7Xyf/bie9bGWr8s6RvUwZP/eVptp93nvt/XKnUsaASx02zrBSg\n3H/Jv5/0VzKN6esMY/z7nOWmYzrO0BCRo61Ejh4dfx05wsDTTxNPuwlRHg/2ihXER0eJ9fZCLDb1\nZEphVla6wal6Gd4zNlFaVU17Tw9rNjZhJL9Pnx/D50UlcpiGz5e6uUpNEyUsqb+xLIp4teMQHxsj\nPjJCfGTUnY6OEh9NLI8mlkdG3Jtglfh9Sl7/CctG4rsb/72Kh8ZwevtwenuI9fbhdPcQbjmI09uL\nDk//210HvDDd9aqqwqqpwaqpwbt2LWZNDVbNcnfd8pqMP/NCzRmMtdbXzrFdA+/PWYrmqdR2/0gG\nx2IsL19gMLbcYBzXcQx16usYtNboUMjNWbYlAm4i8EbajhFtPz7xztMwsOvrsRsbiVdVYlUvQ+tE\nUdzk4rd4HB13UsWUOj6/u2WzrBTvJZdgNzRgN6zAXtGAvWIFVn19XorZshENjWVdtKSUQpWWYpSW\nYq948bUVmM7e5maWn4IqC2XbeNevx7t+PYG09fHRUcIvHCacCNDhlhZGHnuMgbvvBsAoK8Ne3Yh3\n0ybKX/Ma7NWNeFavwbO6EauuLqsf/5nEerrxbdq04PPMm9YQj0EsBLHwxKkTAcPGtHz4GwP4174U\nrAvB9ILlRSuDWFdXWpBuJXr8OEZ5GVb1Mqxl1ZjVy7BqlrnTZdWYlZXuDdwkByb/X9DjxfZTXiTW\nx8MQcyDq3hijk9N42nIsbT6e2kdpBzPuYCbXexywHChPHqNA+yBuJ24GbTAsd2p6xucN270ZNeyJ\ny8ocv2mC1E2S1qDHQsT6B3D6+oj1DeD0DRDr6+fYkcOcduZWrKoAZmUZVkUJVrkPpeLud+JEwUlO\nIxDrAqMXOD/f/0uAU9yAK59KrEQwDkVZXu5d0Lm8pnt82Anjt7Krl5hMa83wzmYiR46k7gTdO8S0\n+cnT0dEpRabK78fT2IhnzVrKXnGR+8OVyDnYK1agEgHwSHMzZy2hOmOxxMTjEI+6PzjxKDixtOVY\n4gdZT//jnNqmJ62ffkx0A40/AP5z6+DcOuAVADiDw2gnjllRmvgpTaujZRRGD8CR/Wn1tsm0x9wf\ny1h4YkCLhSAWmXZ5c2cHdP00kaNKy3VNnid9PvFe8agbaOKx8euTfDnJbdHx5fRg66SlUc+vWkIp\nE9vyYpseSi0veLyw3jN+/fsc6NXQkgiQOj1Q6vFlHediJwa7SPtOC1MyPE+XHagpBw5neUJvBZzz\njgWnKxOFE4xtdzo4tvB6Y5/lAyAcW3gwHn7wQdo/8MHUsko1aChxGzqUlmBWV2GvWjW+LtG4wa6v\nw17ViGd1I+ayZTlrQCSyoPX4j27yB9mJjN89R8cSr9G06ejEdZGRiful5zDScxmp+WnWTwiG0+Rm\nptn+8tAoPE4i4CaCyxL4IV5YudVsJ/aA5RufWh5KQxE4GZzmxmLyddQT9zGSOTXLnRqJ3Jlhjufi\nDNt9n2QuzvIm3nem6aR1hu1+J6kbibA7P2EaTtxgpM0nbxoMM+2mwpy0zpxww9HWfpw1a9ZOvfGY\ncFMy6ebEMN3PljqvOXE63bqZ9k2uN6yp63R86k1h8m9suhtGJzLpJjAxnWO5peUgTZu3uSUPyRy4\n5XGnk1+p9QvL2GWjcIJxImc8kINgnMwZL7QRVzwSofNrN+HdsJ41t96KUVqak6K3gqG1+yOUDFKR\naQLZTHX3M+TGAGo798BTR6cPhDMFzOhY2h9/ZOIPADO/V0YsH9h+sEvB9o3/wCkzUUdpTPyBUub4\nj/uUH9nJubvpXm7+oKuzi5Wr1iSCh5lW1JdeBJi+nFb8N1fuMVV/qsZzk9OZ9QYy/Rzp0xm2GUYi\n2HoTQS3xMr2Jos2p6XhiiT1dsFiONDezpsivw4mRZprO3rHYyZhRwQTjVJ1xaJpGDVlKL6ZeiL6f\n/4LosWM0/vCHmOXlC07XKeNEITwEkWEIDyemQxPXRUfH79hTRYOT7+LDk+76w1ODYh5sBtiftkIZ\nYJckXv6J05KaxLw/LUB5EnfOaQFr2nnPpPMl5j1p72X5pw0Sp8LB5mZWFvkPsBAvFgUTjEsSnyQX\nxdTJoulQbP4541hvL93/9m+UXnIxZa+4cMFpypjWEBqE0ACE+hPTARhLm5+8PjwEkUSwDQ/PnBud\njmFNzKmYnok5FssL3nKwlrtFP3apG6Q8MwTH9KBm+91zzJi7mn79n554gpe94tLx85ieOXJoQgix\nuAonGKdyxkujmLrrO98hPjZG3Sc/ueD0AG6x6UgQhjpg6OQ0U3f+ktE+eHiOekFvBfgqwF/hzlc2\ngqcMvGWJabn7Sq0rT9uWWLb9iXqvvNUAzttYyQkIFEaLaCFEcSiYYGwb4DGNnNQZpzfgmo9QSwv9\nt99B1Vvfive00+Y+IB6H4U7oPwYDbdDfCv1tiUCbCLbDQabUXSoDyuqgvB4qV8Oql3Ksa5g1m850\ng62vMjGtAH9i3htYkgFUCCGKWcEEY6UUAb/N4Fju6oznkzPWWhP86tcwysupef8/uCudmBtUU8H2\n2PhroA0G2t261nQly9zcXXkDNJzpTsvrJ05Ll08JrEeam1nz8h3z+dhCCCEWScEEY4CA38ppMXXW\nDbjiDiO//SUjf/wjdW95GdaDH4fgfug+6LbMTVdW5+ZmG86CM650i4or10BFY6LYuHTBn0MIIcSL\nQ2EFY599ahpwxeNujja4H7r2u9PgfnSwhc7/KcdTrqjiLmhfA7VnwIbXQvU6N/hWrIaKVe4jLkII\nIQSFFoz9NgOjkbl3nMO0xdTxOOy/Bx7/PpzcDdGR8W3lK6D2DPrCK4kMPsuqL34MdeW1bmMnIYQQ\nYg4FFYwr/DZtvQt/dnVCAy6t4YUH4cEboeNZqGmCs9/u5nhrz4Dlm8BfidPfT/d3L6P05RdQ9uZ3\ny6M0QgghMlZQwTjgs3JSTJ3KGfcchJ/8FbT+0S1ifuMP4CVvmbY1cte//RvO0BC1n7xBuq0UQgiR\nlcIKxn6bwVAUrfWCAqK3qwWA8FM/hqgXrvg6nHOd22nFNMKHj9B3639R+eY349vYNO/3FUIIUZwK\nKxj7bKKOZizqUOKZx0freQF2/gtqz5341jYSXnshXPHDOVs2B2+6CcPrZfmHPzTPlAshhChmBRWM\nK/zu0E2DY7HsgvHAcXj4q/CXn7u9Sl30cbzBBxir3zpnIB559FGGd+6k9h8/jrVs2UKSL4QQokgV\nVDAO+N2PMxiKUl+RwaNDI93wh2/Cn/8D0HDe9XDRx6GsFu8vH57zOWPtOHT+61exV62i6h2nZsxL\nIYQQhaewgrHPzRln1CVmzwtw8w53FKIzr4UdN7iNtBJ8pm/OHrj6f3Un4ZYWVn7rWxie6euThRBC\niLkUVjBOFVNnEIwPPQjhQbj+IVh57pTNXss7a9/UztAQXd/6FiXbt1P+2tfMO81CCCFEQY10n6oz\nzqRLzOBedyCFFedMu9lv+mctpu7593/H6euj9gZ5lEkIIcTCFFQwDvgSdcaZDBYR3A91W2bsnMNr\neRmLjU27LdLWRu9Pb6HijW/Ev3XLvNMrhBBCQIEF4/JM64y1doNx7Rkz7uI1vTPmjIM3fR1sm+Uf\n+ci80yqEEEIkFVQw9lgGftucu854oM2tL67dPOMuPtM3bTAefeIJhn73O5a9+++x62oXmmQhhBCi\nsIIxuPXGc9YZd+5zp3UzFzF7Le+UUZt0PE7nV/4Vq6GBZe9610KTKoQQQgAFGIwDfmvuOuNgIhjP\nUkw9Xc44tGcPoX37WP6B92P4/QtNqhBCCAEUYjD22XPXGQf3QWAV+Cpm3MVn+abkjKMnOtxtm2cu\n3hZCCCGyVXDBOONi6rrZA6rX9E7p9CMW7ATAqqtbUBqFEEKIdAUXjANzBWMnCt0tszbeAreYOhqP\n4sSd1LpoZyfKtjGrqnKVXCGEEKIAg7FvjjrjnkMQj87aeAvcBlzAhHrjWGcQq7ZWOvkQQgiRU4UX\njBM543hcT79D5153OkvjLXBzxsCEoupYZ6cUUQshhMi5ggvGFX4brWE4MkPuOLgPlAk1TbOex2e5\nwTi9f+pYMIglzxYLIYTIsYILxsmRm2bs+CO4H2o2uOMWz8JrutuTOWOtNdFgELtWcsZCCCFyq/CC\nsX+O/qk7985ZRA3jxdTJOuP40BB6bEyKqYUQQuRc4QXj2fqnDg9BfyvUzj24Q7IBV/JZ41hn8rEm\nKaYWQgiRW4UXjGcbRjF4wJ3O8YwxTG3AFe0MAmBLzlgIIUSOFVwwTo1pPF3OONUNZgbBeFIDrvGc\nsQRjIYQQuVVwwXjWYurgPrBLoXLNnOeZ3IAr1ftWrRRTCyGEyK2CC8ZlvkQDrtA0Dbg690LtJjDm\n/tiTG3BFOzsxKysxvLO3whZCCCGyVXDB2DQU5T5rajG11m7OOIMiapiuAVdQiqiFEELkRcEFY3CL\nqqc04BrpgtGeObvBTErWGae3ppaW1EIIIfKhMIOx356aM86wG8ykKcXUwaC0pBZCCJEXhRmMpxss\nItWSOrOcsW3YKBQhJ4SORnF6erCk9y0hhBB5UJDBeNoxjTv3QelyKFue0TmUUvgsH+FYmFhXF2gt\nLamFEELkRUEG42mLqYP7Mi6iTvKaXkJOiKj0viWEECKPCjMY++yJzxnH49B1IOMi6iSf5SMUCxGT\n3reEEELkUWEGY7/FSMQh5sTdFX1HIDqaUTeY6Xymj7ATHu/wQ4KxEEKIPMgoGCulLlNKPa+UOqSU\numGa7auVUjuVUn9RSj2nlLoi90nNXLJLzKFkxx/B/e40y5xxejG1sm3MqqpcJlMIIYQAMgjGSikT\n+B5wObAZuFYpNTmL+RngDq312cDfAv+W64RmIzWmcbIRV7Il9fKNWZ3Ha3ndBlzBLqzaWpRSuUym\nEEIIAWSWMz4POKS1Pqy1jgC3AVdN2kcDgcR8BXAid0nMXnLkplS9cedeqFoL3rKszpMqpu7slCJq\nIYQQeWNlsM9KoC1tuR142aR9vgD8Tin1QaAUePV0J1JKvQd4D0BdXR3Nzc1ZJndmw8PDqfMd7nUA\neOTxp+itMXnp0ScZ869kT5bvNzIwwqAzyODREWKNjRzNYXrzJf06FCu5Bi65DnINkuQ6LP1rkEkw\nzsS1wE+01v9XKXUB8DOl1FatdTx9J631zcDNANu3b9c7duzI0dtDc3MzyfPVnxzkK39+hHUbN7Nj\nUxU83EHp9mvJ9v3uab6Hsb5R7KEhardu5ewcpjdf0q9DsZJr4JLrINcgSa7D0r8GmRRTHwca05ZX\nJdal+3vgDgCt9WOAD6jJRQLnI1VnPBaF7hbQTtbPGINbTK1GQuixMSmmFkIIkTeZBOMngA1KqXVK\nKQ9uA617Ju1zDHgVgFLqDNxg3JXLhGZjQp1xlt1gpvNaXvx9o4B0+CGEECJ/5gzGWusY8AHgAWA/\nbqvpvUqpG5VSVyZ2+zhwvVLqWeC/gHdqrXW+Ej2XUo+JaSi3NXXnXjA9sOz0rM/jM32U9rujNkmH\nH0IIIfIlozpjrfW9wL2T1n0ubX4fcGFukzZ/SqnxwSKG90NNE5h21ufxWT7K+t1Rm6SYWgghRL4U\nZA9c4BZVp4qpa7PreSvJa3qpGHLboMkgEUIIIfKlcIOxzyY20guDx7PuBjPJZ/qoHtIYlRUYXm+O\nUyiEEEK4CjYYV/htqoYPuQvzaLwFbgOu6iEwli9aw3AhhBBFoGCDccBvURs67C7M47EmSOSMhzUs\nX5bDlAkhhBAT5arTjyUn4LNZGTkC3gqoWDWvc/gsH5VDEK+RASKEEELkTwHnjG3WOkfdXPE8B3jw\naovACDjLAnPvLIQQQsxTwQbjCp9FE23Els+viBrA3x/CAGISjIUQQuRRwQbjetVLQI0yVtk073P4\n+kYACFdnN9qTEEIIkY2CDcYrIm7jrYHA/IOxp3cYgFBVSU7SJIQQQkynYINx7egLAPSUZt8NZpLd\nOwTAWKUEYyGEEPlTsMG4cvgFTuoq+uKl8z6H2dNP1ITRMjOHKRNCCCEmKthgXDbwPM/HGxkMxeZ9\nDtXdR18ZhJ1IDlMmhBBCTFSYwdiJ4ek7xAHd6PZPPV9dvfSWQ8gJ5S5tQgghxCSFGYx7X0A5YTdn\nvIBgHA9201uuCMUkGAshhMifwgzGwX0AHDbWuGMaz4PWmlgwSF+5QdgJ5zJ1QgghxASFGYw794Ey\n6PKuccc0nof40BB6bIyhgCXF1EIIIfKqMPumDu6D6tPxRkrnXUwd6+wEYLjSixWTnLEQQoj8KdCc\n8V6o20zAZ8+7mDraGQRgpNInOWMhhBB5VXjBODICfUehdjMVfnvBOeOxKr804BJCCJFXhReMuw4A\nGmo3E/Db837OOBZ0g3G0qkwacAkhhMirwgvGnW5Lauq2EPBZ837OONrZiVlZienzSzG1EEKIvCq8\nYBzcB5Yfqta6OeOxKFrrrE8T6wxi1dXhtbyEpQGXEEKIPCrMYLx8IxgmFX6bWFwzFnWyPk2ssxOr\nrhaf6ZNiaiGEEHlVeMG4cx/UbQEg4LMB5lVUHQ0GsWpr8ZpexmJjOU2iEEIIka6wgvFIN4wEoXYz\nAAG/+xh1th1/6GgUp6cHu7YOnyU5YyGEEPlVWMG4c687rT0DgAq/mzPO9lnjWFcXaI1VVyfF1EII\nIfKusIJxcL87nVRMne2zxrGg2+GHVVeL1/LKc8ZCCCHyqsCC8V7wV0NZHQAB//zqjJO9b9lpOeP5\ntMgWQgghMlFYwTjZeEspAAK+ZJ1xljnjRO9bVl0dXtOLox1i8fl1HiKEEELMpXCCsY67vW8l6oth\nPGecbS9csWAnyrYxq6rwWT4A6fhDCCFE3hRMMPaFuiAynGpJDWCbBiUeM+uccbTTfaxJKYXPdIOx\nNOISQgiRLwUTjEtHjrozicZbSQGfnXWdsdvhh1vv7LW8ANKISwghRN4UUDBudWeWb5qwPuC3sn+0\nKdH7FiA5YyGEEHlXQMH4GFSsBl9gwnp3GMXM64y11kSDQezaRM7YlJyxEEKI/CqYYFw23Ap1m6es\nD/jsrHLG8aEh9NhYqphaGnAJIYTIt8IIxrEI/rHjExpvJQX82dUZjz/WlCimTgRjGblJCCFEvliL\nnYCc6G7B0M70wdhnZdWaOr3DD0grppacsRCiyEWjUdrb2wmFXny/hxUVFezfv/+UvJfP52PVqlXY\ntp3xMYURjFPdYE4NxhV+m6FwjHhcYxhqzlOld/gB4w24pM5YCFHs2tvbKS8vZ+3atSg19+/pUjI0\nNER5eXne30drTU9PD+3t7axbty7j4wqjmHrZ6bStegMs2zBlU8BvozUMRzJrxBULJoJxrVtMnXy0\nSVpTCyGKXSgUYtmyZS+6QHwqKaVYtmxZ1qUHhRGMV57DC+vfDZZnyqbUmMajmRVVRzs7MSsrMbxu\nEE7ljKWYWgghJBBnYD7XqDCC8SxSYxpn2KI61hlMFVGDNOASQoilpKysbLGTkBdFEIyTwyhmWEzd\n2ZkqogZpwCWEECL/Cj8Y+7IbRjEaDKYeawKwDAtLWdKASwghlhCtNZ/4xCfYunUr27Zt4/bbbweg\no6ODiy++mLPOOoutW7fyyCOP4DgO733ve1P7fvOb31zk1E9VGK2pZ1GRGrlp7mCso1Gcnp5U71tJ\nXssrDbiEECLNP/9mL/tODOb0nJtXBPj8G7bMvSPw61//mmeeeYZnn32W7u5uXvrSl3LxxRdz6623\n8rrXvY5Pf/rTOI7D6OgozzzzDB0dHezZsweA/v7+nKY7F4omZ5zJs8ax7m7QekKdMbiNuKSYWggh\nlo4//OEPXHvttZimSV1dHZdccglPPPEEL33pS/nxj3/MF77wBXbv3k15eTmnnXYaR44c4YMf/CD3\n338/gUBg7jc4xTLKGSulLgO+BZjAD7XW/zrNPm8BvgBo4Fmt9VtzmM55K/dZKJXZmMaTe99K8lk+\nacAlhBBpMs3BnmoXX3wxu3bt4re//S3vfOc7+djHPsY73vEOHn30UR599FF+8IMfcMcdd/CjH/1o\nsZM6wZw5Y6WUCXwPuBzYDFyrlNo8aZ8NwP8BLtRabwE+koe0zothKMq8mfXCNbn3rSSv6ZWcsRBC\nLCEXXXQRt99+O47j0NXVxa5duzjvvPNobW2lrq6O66+/nne/+908/fTTdHd3E4/H+Zu/+Ru+9KUv\n8fTTTy928qfIJGd8HnBIa30YQCl1G3AVsC9tn+uB72mt+wC01sFcJ3QhAj47s2LqSb1vJXlNrzTg\nEkKIJeSv//qveeyxxzjzzDNRSvG1r32N+vp6fvrTn3LTTTdh2zZlZWXccsstHD9+nOuuuy517Fe+\n8pVFTPn0MgnGK4G2tOV24GWT9mkCUEr9Ebco+wta6/tzksIcCPgzG7kpFuxE2TZmVdWE9T7LJw24\nhBBiCRgeHgbcjjVuuukmbrrppgnbr7vuugmBN+mRRx45Jd1hzleuWlNbwAZgB7AK2KWU2qa1ntBk\nTSn1HuA9AHV1dTQ3N+fo7d0vaKbz6fAYx07OvD0p8NxuPIEADz/88IT1Y4Nj9MX7cprefJntOhQL\nuQYuuQ5yDZJydR0qKioYGhpaeIIWgeM4pzTtoVAoq2ueSTA+DjSmLa9KrEvXDvxJax0FjiilWnCD\n8xPpO2mtbwZuBti+fbvesWNHxgmdS3NzMzOd79ZjT9LaM8qOHRfPeo7WH/0YvWYNWyed586H7qRj\nuGPG8y8ls12HYiHXwCXXQa5BUq6uw/79+5d07nI2p2qgiCSfz8fZZ5+d8f6ZPNr0BLBBKbVOKeUB\n/ha4Z9I+/42bK0YpVYNbbKT//YcAACAASURBVH0441TkWcbF1J2dU1pSg/tokxRTCyGEyJc5g7HW\nOgZ8AHgA2A/cobXeq5S6USl1ZWK3B4AepdQ+YCfwCa11T74Sna0K/9wNuLTWRIPBKR1+gNuAayw2\nlq/kCSGEKHIZ1Rlrre8F7p207nNp8xr4WOK15AR8NiMRh5gTxzKnv/+IDw2hx8amtKQGacAlhBAi\nvwq+By5IH7lp5o4/ZurwA6SYWgghRH4VRzDOoEvMmTr8ALdv6lAshFsAIIQQQuRWUQTjTAaLmKnD\nD3BzxhpNNJ7ZyE9CCCFENooiGGcypnEsmAjGtVOLqZNjGksjLiGEWHxvfOMbOffcc9myZQs333wz\nAPfffz/nnHMOZ555Jq961asA9/nqd73rXWzbto0LLriAO++8czGTPauCH0IRxuuMZxvTONrZiVlZ\nieH1Ttnms3wAUm8shBBJ990AJ3fn9pz12+DyKeMQTfGjH/2I6upqxsbGeOlLX8pVV13F9ddfz65d\nu1i3bh29vb0AfPGLX6SiooLdu3czNDRELDb3gEGLpTiCsS+TYurgtLliSAvGMnKTEEIsum9/+9vc\nddddALS1tXHzzTdz8cUXs27dOgCqq6sB+P3vf89tt92WOq5qUlfHS0lRBONUnfEsOWO3w4+p9cUw\nXkwtIzcJIURCBjnYfGhubub3v/89jz32GCUlJezYsYOzzjqLAwcOLEp6cqUo6oxLPCamoWYvpu4K\nTvtYE7gNuECKqYUQYrENDAxQVVVFSUkJBw4c4PHHHycUCrFr1y6OHDkCkCqmfs1rXsP3vve91LF9\nfX2LkuZMFEUwVkoR8FkzFlPraBSnu2fa3rfAfbQJpAGXEEIstssuu4xYLMYZZ5zBDTfcwPnnn8/y\n5cu5+eabedOb3sSZZ57JNddcA8BnPvMZ+vr62Lp1Ky9/+cvZuXPnIqd+ZkVRTA2J/qlnaE0d6+4G\nrWcsppacsRBCLA1er5f77rtv2m2XX375hOWysjJ++tOfAqd+oIhsFUXOGBL9U8+QM56t9y2QBlxC\nCCHyq2iCccBnz1hnPFvvWyANuIQQQuRX8QRjvzVja+rZet8CKaYWQgiRX8UTjH32jANFxIKdKNvG\nnOEZNGnAJYQQIp+KJhjPNqZxNNHhh1Jq2u2SMxZCCJFPRROMA36bcCxOKOpM2TZbhx8wXmcsDbiE\nEELkQ/EEY19yTOOpuWM3GE/fkhrANExsw5YGXEIIIfKieILxDCM3aa2JBoMzdviR5DN9hGISjIUQ\n4sWkrKxsxm1Hjx5l69atpzA1Myu+YDwpZxwfGkKPjc1aTA1uIy6pMxZCCJEPxdMDV2LkpsnPGs/V\n4UeS1/RKMbUQQiR89c9f5UBvbgdn2FS9iU+e98lZ97nhhhtobGzk/e9/PwBf+MIXsCyLnTt30tfX\nRzQa5Utf+hJXXXVVVu8dCoV43/vex5NPPollWXzjG9/g0ksvZe/evbzrXe8iEokQj8e58847WbFi\nBW95y1tob2/HcRw++9nPprrgnK+iCcYViTGNJ7eonqvDjyS/5ZcGXEIIsciuueYaPvKRj6SC8R13\n3MEDDzzAhz70IQKBAN3d3Zx//vlceeWVMz4hM53vfe97KKXYvXs3Bw4c4LWvfS0tLS384Ac/4MMf\n/jBve9vbiEQiOI7Dvffey4oVK/jtb38LuINXLFTRBOPxMY0n1hnP1eFHkuSMhRBi3Fw52Hw5++yz\nCQaDnDhxgq6uLqqqqqivr+ejH/0ou3btwjAMjh8/TmdnJ/X19Rmf9w9/+AMf/OAHAdi0aRNr1qyh\npaWFCy64gH/5l3+hvb2dN73pTWzYsIFt27bx8Y9/nE9+8pO8/vWv56KLLlrw5yq+OuPJxdTBRDCu\nzaCYWhpwCSHEorv66qv51a9+xe23384111zDL37xC7q6unjqqad45plnqKurIxTKze/1W9/6Vu65\n5x78fj9XXHEFDz30EE1NTTz99NNs27aNz3zmM9x4440Lfp+iyRn7bBOPZUxTTN2JWVGB4fXOfrzl\nYygylM8kCiGEyMA111zD9ddfT3d3Nw8//DB33HEHtbW12LbNzp07aW1tzfqcF110Eb/4xS945Stf\nSUtLC8eOHWPjxo0cPnyY0047jQ996EMcO3aM5557jk2bNlFdXc3b3/52Kisr+eEPf7jgz1Q0wRiS\nXWJOzhl3zVlEDW7OuMvpylfShBBCZGjLli0MDQ2xcuVKGhoaeNvb3sYb3vAGtm3bxvbt29m0aVPW\n5/yHf/gH3ve+97Ft2zYsy+InP/kJXq+XO+64g5/97GfYtk19fT2f+tSneOKJJ/jEJz6BYRjYts33\nv//9BX+mogrGFX5rynPGc/W+leSzfNKASwghlojdu3en5mtqanjsscem3W94eHjGc6xdu5Y9e/YA\n4PP5+PGPfzxlnxtuuIEbbrhhwrrXve51vO51r5tPsmdUNHXG4NYbT360KRqcvfetJJ/pkwZcQggh\n8qKocsYBn03faCS1rKNRnO6eOXvfAmnAJYQQL1a7d+/mbW97G4Yxnv/0er386U9/WsRUTVRcwdhv\n09ozklqOdXeD1pkXU0sPXEII8aKzbds2/vjHP1JeXr7YSZlRURVTV/itCc8ZZ9r7Frg547ATRmud\nt/QJIYQoTkUVjAM+t844GVAz7X0L3JwxyJjGQgghcq+4grHfxolrRiPumMaZ9r4FbgMukGAshBAi\n94orGPsmjtwUC3aibBuzqmrOY72W2ynIWGwsfwkUQghRlIoqGFdMGtM42hnEqq3NqDNxyRkLIcSL\nz2zjGS8lRRWMA4mRm5LPGmfa4Qe4DbgAebxJCCFEzhXXo02+iYNFxDo78W4+I6NjpQGXEEKMO/nl\nLxPen9vxjL1nbKL+U5+adZ9cjmc8PDzMVVddNe1xt9xyC1//+tdRSvGSl7yEn/3sZ3R2dvLe976X\nw4cPA/D973+fl7/85Qv81K7iCsb+8TpjrTXRYJCyHTsyOlaKqYUQYvHlcjxjn8/HXXfdNeW4ffv2\n8aUvfYlHH32Umpoaent7AfjQhz7EJZdcwl133YXjOLN2tZmtogrGFWnDKMaHhtBjY5kXU0sDLiGE\nSJkrB5svuRzPWGvNpz71qSnHPfTQQ1x99dXU1NQAUF1dDcBDDz3ELbfcAoBpmlRUVOTscxVVMC73\nJeuMY1l1+AGSMxZCiKUiOZ7xyZMnp4xnbNs2a9euzWg84/kelw9F1YDLNg1KPCaDoWhWHX6ANOAS\nQoil4pprruG2227jV7/6FVdffTUDAwPzGs94puNe+cpX8stf/pKenh6AVDH1q171qtRwiY7jMDAw\nkLPPVFTBGBJjGo9FibYdA8BetSqj46QBlxBCLA3TjWf85JNPsm3bNm655ZaMxzOe6bgtW7bw6U9/\nmksuuYQzzzyTj33sYwB861vfYufOnWzbto1zzz2Xffv25ewzFVUxNbj1xoOhKJH2VpTPh1UrxdRC\nCPFik4vxjGc77rrrruO6666bsK6uro677757HqmdW/HljP0WA2NRIq2teFavRhmZXQJpwCWEECJf\nii5nHPDZdAyEiLS24t2wIePjknXGkjMWQogXFxnPeAkK+G0OdvQTaWuj/NWvzvg4Qxl4DA/hmARj\nIYR4MSmY8YyVUpcppZ5XSh1SSt0wy35/o5TSSqntuUtiblX4bbzdQYjF8Kxdk9WxPstHyJHW1EII\nIXJrzmCslDKB7wGXA5uBa5VSm6fZrxz4MLB08v3TCPgsKvpOAuBZk2UwNn3yaJMQQoicyyRnfB5w\nSGt9WGsdAW4Dpuv084vAV4ElHa0CfpsVQ91A9sHYa3klZyyEECLnMgnGK4G2tOX2xLoUpdQ5QKPW\n+rc5TFteBHw2K0a6oaQUM9HVWaa8plfqjIUQYhG9WIZEzNaCG3AppQzgG8A7M9j3PcB7wH1eq7m5\neaFvnzI8PJzR+do6Y6wc7mKkqpqHH344q/eIjEboCHXkNN25lul1KGRyDVxyHeQaJOXqOlRUVDA0\nNLTwBC3Q5DTEYjEsa/Zw5jjOKU17KBTK6ppnEoyPA41py6sS65LKga1Ac2KEjHrgHqXUlVrrJ9NP\npLW+GbgZYPv27XpHhiMmZaK5uZlMzud5oZvQcDf29jMz2j/dT+//KRqd9XGnUqbXoZDJNXDJdZBr\nkJSr67B///4l0SK5vLyc5uZmPvvZz1JVVcWBAwdoaWmZ9ZihoaFTmnafz8fZZ5+d8f6ZBOMngA1K\nqXW4QfhvgbcmN2qtB4BUea9Sqhn4x8mBeKkImBAY7WVo+cq5d57Ea3npD/XnIVVCCPHi8sgdLXS3\n5W4IQYCaxjIuektTxvs//fTT7Nmzh3Xr1uU0HYthzjpjrXUM+ADwALAfuENrvVcpdaNS6sp8JzDX\nyvuCmGiGamYfWms6PtMnnX4IIcQScd555xVEIIYM64y11vcC905a97kZ9t2x8GTljy94glGgtyr7\nYOw1vfJokxBCQFY52HwpLS1d7CTkTNH1TW0edxuGd1Usz/pYnyU5YyGEELlXdME4eqyVYU8JPWZJ\n1sf6TOmBSwghRO4VXd/UkdZWgoHlDI5Fsz7Wa0kxtRBCLKbkkIg7duwoqJbyRZczjrS20ldVz8A8\ngrHP9BGNR3HiTh5SJoQQolgVVTCOh0LEOk4yWNPAYGgeOWMZRlEIIUQeFFUwjhw7BlozVruCwbFY\n1sf7LB8gwVgIIURuFVcwbm0FINqwcl45Y58pwVgIUdy01oudhCVvPteoqIJxNBGM9crGedUZey23\nmHosNpbTdAkhxIuBz+ejp6dHAvIstNb09PTg8/myOq6oWlNHWlsxly2jpKqS0UiQqBPHNjO/H5Gc\nsRCimK1atYr29na6uroWOylZC4VCWQfI+fL5fKxatSqrY4orGB9txbNmDQG/+7GHQjGqSz0ZH59s\nwCWPNwkhipFt2y/a7iebm5uzGrjhVCuqYurI0aN41qyhwm8DZP2ssTTgEkIIkQ9FE4zjIyPEurrc\nnLHPDcbZ1hv7LT8AI9GRnKdPCCFE8SqaYBw5dgwAz9o1BJI54yxbVK8OrAbgyMCR3CZOCCFEUSue\nYJxoSe1ZuzZVZ5zts8YBT4CG0gae73s+5+kTQghRvIqmAVfk6FEAPKtXUxFVQPbF1ABNVU0c7DuY\ny6QJIYQocsWTMz7ailVbi1FSkqoznk/HH01VTRwZOELEieQ6iUIIIYpU8QTjVvexJoASj4lpqHmN\n3NRU1YSjHQ4PHM51EoUQQhSp4grGa91grJQi4LPmlzOubgKgpa8lp+kTQghRvIoiGDuDgzi9vXjW\nrk2tq/DbDMxjsIjV5avxml6e75VGXEIIIXKjKIJxqiV1opgaIOC351VMbRkWp1eeLjljIYQQOVMc\nwfjoNMHYZ8+rmBrcemMJxkIIIXKlOIJxaysohb16dWpdwG/NK2cMbjDuDfXSPdadqyQKIYQoYkUT\njK2GegyvN7VuvnXGABurNgLSiEsIIURuFE0w9qY13oKFFVNvqNoAQEuvBGMhhBALV/DBWGtN5OhR\n7LT6YnAbcEVicUJRJ+tzVvmqqPXXSs5YCCFEThR8MHb6+4kPDk5ovAXMe7CIpA3VGyQYCyGEyImC\nD8apPqknB2NfcrCI+TfiemHgBaLx+R0vhBBCJBV+ME49Y7x2wvo1y0oBeGBv57zOu7FqI7F4jKMD\nRxeSPCGEEKJIgrFp4lm1csL6sxoruWxLPd9+8CDHekazPm9TldstpgynKIQQYqEKPxgfPYq9ciXK\n45my7fNXbsYyFJ+7Zw9a66zOu7ZiLZZhSb2xEEKIBSv8YJw2WtNkDRV+PvbajTQ/38V9e05mdV7b\nsDm9QrrFFEIIsXAFHYy11kSPzhyMAa67YA2bGwL882/2MpRly+qmqiYO9h5caDKFEEIUuYIOxk53\nN/HR0QmjNU1mmQZfftM2gkNh/u/vssvlbqzeSHAsSF+ob4EpFUIIUcwKOhjP9FjTZGc1VvL2l63h\nlseOsrt9IOPzJ3viOtgnuWMhhBDzV9jBOPlY09rZgzHAP75uI8vKvHz6v3fjxDNrzCUtqoUQQuRC\n4Qdj28ZuaJhz3wq/zWdfv5nn2gf4+eOtGZ2/xl9Dta9aGnEJIYRYkMIOxkdb8axahbKsjPZ/w0sa\nuGhDDTc98Dydg6GMjtlYtVGCsRBCiAUp7GDc2jpr463JlFJ88aqtRJw4N/7PvoyOaapq4oX+F4jF\n5zccoxBCCFGwwVjH47M+YzyTtTWlfODS9fz2uQ6anw/OuX9TdRNhJ8yxoWPzTaoQQogiV7DBONbZ\niQ6HM2q8Ndn/vuQ0Tlteyufu3jvnEIvJRlwytrEQQoj5KthgPD5ARPbB2GuZfOmNWznWO8p3Hzo0\n676nVZyGpaRbTCGEEPNXuMH46PyDMcDLT6/hTees5N93vcCh4NCM+3lMD2sr1kowFkIIMW+FG4xb\nW1FeL1Z9/bzP8akrzqDEY/Hpu2YfSKKpqkmCsRBCiHkr3GB89Cie1atRxvw/Yk2Zlxsu38SfjvRy\n59PHZ9yvqaqJjpEOBiOD834vIYQQxatwg3Fr67wab012zfZGzl1TxZfv3U/fSGTafaQRlxBCiIUo\nyGCsHYdoW9u864vTGYbiX/56K4NjUf71vgPT7pMKxlJULYQQYh4yCsZKqcuUUs8rpQ4ppW6YZvvH\nlFL7lFLPKaUeVEotPAouQLSjAx2NYucgGANsqg/w9xet4/Yn23jiaO+U7bUltVR6KyUYCyGEmJc5\ng7FSygS+B1wObAauVUptnrTbX4DtWuuXAL8CvpbrhGYj2ZLam0XvW3P58Ks2sLLSz6fv2k04NvHZ\nY6WUO7axjN4khBBiHjLJGZ8HHNJaH9ZaR4DbgKvSd9Ba79RajyYWHwdW5TaZ2UkOnZirnDFAicfi\nxqu20NI5zJXf+SNPtU4cw7ipqomD/QeJ63jO3lMIIURxULM9sgOglHozcJnW+t2J5b8DXqa1/sAM\n+38XOKm1/tI0294DvAegrq7u3Ntuu22ByR83PDxMWVkZAOW334Hv0Ufp+n/fBKVy9h4AzwRj3LIv\nQl9I88rVFm9u8uC3FI8NP8atPbfy2RWfpdauzel7ZiP9OhQruQYuuQ5yDZLkOiyNa3DppZc+pbXe\nPt22zIYzypBS6u3AduCS6bZrrW8GbgbYvn273rFjR87eu7m5meT5jt16K7HTTmPHpZfm7PxJO4B3\nh2N8/YHn+eljR9nbb/HPV23hyq3LufW3t1LVVMWONTty/r6ZSr8OxUqugUuug1yDJLkOS/8aZFJM\nfRxoTFtelVg3gVLq1cCngSu11uHcJG9+5jNARDbKvBZfuHILd/3DhVSW2Pzvnz3FN+8dwMCQRlxC\nCCGylkkwfgLYoJRap5TyAH8L3JO+g1LqbODfcQPx3EMd5ZGORom2H8/JM8ZzOauxkt988BV88rJN\nPNIyQDxSw4MvPEM8PnvRvxBCCJFuzmCstY4BHwAeAPYDd2it9yqlblRKXZnY7SagDPilUuoZpdQ9\nM5wu7yLt7eA4eNasPSXvZ5sG79txOg985GIqrNU839vC1f/+GC2dM/dnLYQQQqTLqM5Ya30vcO+k\ndZ9Lm391jtM1bwsZrWkh1taU8nfnnM93n3mSF05281fffoT3XnI67790PT7bPKVpEUII8eJScD1w\nRZPB+BQUU0+2qXoTAN96Rz1veMkKvvPQIa741iM8frjnlKdFCCHEi0fBBeNIaytGIIBZVXXK3zvZ\nLWZn6CjfuOYsfvb35xGLa/725sd538+f4vmTUnQthBBiqsILxkeP4lmzBpXj54szUV9aT7ldnmpR\nfdGG5TzwkYv58Ks28MjBbi771i4++F9/4VBw+JSnTQghxNJVgME4v481zUYpxYaqDRMeb/J7TD76\nmiYe+adLed8lp/Pg/k5e+82H+djtz3C0e2RR0imEEGJpKahgHA+HiXZ0LFowBreouqWvhck9m1WV\nevinyzbxyD9dyrsvOo1793Twqm88zD/96lnaekdnOJsQQohiUFDBONrWBlovSuOtpI3VGxmJjnB8\neEq/KAAsK/PyqSvOYNc/Xco7LljDfz9zgku/3sz/+fVuTvSPneLUCiGEWAoKKhinHmvK4WhN2cp0\nbOPach+ff8MWdn3iUt76stX86qk2dtzUzOfu3kPnYOhUJFUIIcQSUVjBODFa02IWU6+vXI9CZdwt\nZn2Fjxuv2krzJy7lb85dxa1/OsZFX9vJjb/ZR2uP1CkLIUQxyOlAEYstcrQVs6oKMxBYtDSU2CU0\nljdm3Uf1yko/X3nTNt53yel856GD/PSxo/zoj0fY3BDgim31XL6tgdOXF/eoK0IIUagKKxjneYCI\nTDVVNXGw7+C8jl29rISbrj6Tj76miXt3d3DfnpN8/XctfP13LWysK+fybfVcsa2BDbVli/L4lhBC\niNwruGBcev75i50MmqqbePDYg4xGRymxS+Z1jhWVft590Wm8+6LTODkQ4v49Hdy75yTfevAg/+/3\nBzl9eSlXbGvg8q0NnNFQLoFZCCFexAonGIfDxDo78axbu9gpoamqCY3mhf4X2LZ824LPV1/h450X\nruOdF64jOBTigb2d3Le7g+/tPMR3HjrEmmUlXL61gSu21U95pEoIIcTSVzDB2OrqAha38VZSeovq\nXATjdLXlPv7u/DX83flr6BkO87t9ndy7u4P/eOQwP3j4BUptOPfInzlrVQVnNlZyZmMlNWXenKZB\nCCFEbhVMMDY73WGUl0IwXlm2khKrJOtGXNlaVubl2vNWc+15q+kfjfD7/UF+89hegkNhvrvzEMlh\nlVdW+jlrdSVnrXKD89aVAUo8BfPVCyHEi17B/CKbXW4wtlcvfjA2lDGlW8x8qyzx8OZzV1EzdIgd\nOy5iNBJjz/FBnm3r55n2fp5t6+e3z3Uk0gdNdeWclcg5b1tZwYa6MryWDPUohBCLoWCCsRUMYi6v\nwSwrXeykALCxaiP3Hb0PrfWiNK4q8Vict66a89ZVp9Z1D4d5tq0/EaAHuG/PSW57og0Ay1CcvryM\nMxrK2bwiwBkN7kuKuIUQIv8KJhibwSDeNWsXOxkpTVVN3NFyB52jndSX1i92cgCoKfPyqjPqeNUZ\ndQBorTnaM8reEwPs7xhkf8cQjx/u5b+fOZE6prbcyxkNgVSA3twQYF1NKaYhrbeFECJXCicYdwax\nzzprsZOR0lQ93ohrqQTjyZRSrKspZV1NKa9/yYrU+t6RSCI4D7KvY5B9Jwb546FuYolKaJ9tsK6m\njJWVPhoq/Kyo9LOi0sfKSne+ttyLZRZU525CCJFXBRGMneFhzKGhJdF4K2lD5QbADcYXr7p4kVOT\nnepSDxeur+HC9TWpdeGYw6HgMPs7hth3YpDWnhHa+8Z44mgfA2PRCccbCuoDvkSQ9tOQCNQrK/2s\nqiqhsdovDciEECJNQfwiRo4mBohYQsG4zFPGyrKVtPSeukZc+eS1TLasqGDLigo4d+K24XCMjv4x\njveP0TEQ4kRyvj/Es+393L8nRMSJTzhmWamHVdUlNFb5aawuoTERpBurSlhR6cdjSc5aCFE8CiMY\ntx4FwLOE6ozBrTd+vu/5xU5G3pV5LTbUlbOhrnza7fG4pnskzPG+Mdr6xmjrHaW9b5S23jF2Hx/g\n/j0nU0XgMJ6zXlVdQm25F49pYJkKyzTceSM5704tU2EbBnZi+diJGCVHellV5acu4JP6bSHEklcQ\nwdiur2fs/PPxrG5c7KRM0FTVxMPtDxN2wnjN4m2VbBiK2nIfteU+zl5dNWW7E9ecHAzR1jvqvvrG\naO8dpa1vlL0nBok6cWKOJhaPE4nFicU1MUdPyW2nu/m5xwC3lfiKSj+rqpKvkkRxuZ9V1SXUS7AW\nQiwBBRGMS849l8F3Xofh9y92UiZoqmoiruO80P8Cm5dtXuzkLFmmoVJ1yueftizj47TWOHFNLK6J\nOnGijibmxHlw16Os2riN9r4x2vtGE9MxHm7ponMwPOEclqFoqPSlgrJCYRhgJB5HM5RCqcQUt9Gb\nuwy2abCuppSmunI21pezdlmpFK8LIealIILxUpXeLaYE49xTSiWKr8Fnj3dY0lBmcNGG5dMeE4o6\ndAyE0oK0O+0cDBHXoHWcuOMG+rgGjTuvNcTTpgBjUYd7d3ekejqzDMVpy0vZUFfOxrpymurKaaor\nY80yeRRMCDE7CcZ51FjeiN/yn9KeuMTsfLaZepwrF0JRhxe6hjnYOczznUMc7Bziufbx3s4AvJbB\n6cvL2FhfzunL3dyzTgT6ZICHtBsADRqd2geg3GtRUWJT6bepKvVQ6bcTyx7JjQtRACQY55FpmKyv\nXF8wLarFVD47rZV5mpFwjEPBYVo6hxKvYR4/3MNdfzme8zSUekwqSzxUltjuy++hosQm2BGmeXDv\npGL28aJ2RXJKap/kjUDqpkBr96YhrifcPIyXHGhKPRbLy72pV225j+XlXgI+S4b2FCJDEozzrKnK\nHdt4sbrFFIuj1GulRs1KNxZxcLRGMV4fDUytl2Y8cGqtGQ7H6B+NMjAWpW80Qv9olP6xKAOjEfpG\no4lt7voDA4MMjEUZC8cwg+2Jova0wKrHc906bT4+KV3JdEyoN08Eb8MYT+twKDZtYzqvZaQF6MmB\n2sZjuS3gPZaB1zKwTQOP5baYt013nSdtvWUo+RsSBUuCcZ5tqNrAnQfvpHusm+Ul09djiuLh92Q/\nGIdSinKfTbnPJpvnBZqbm9mxY0fW75ctrTWDYzGCQyG6hsJ0DYcJDianIbqGwxzpHuFPR3rpH43O\nfcIZ+GyDhgo/9QEfDRU+t+FdhZ+GgDvfUOGnqsSed8B24pqxqEMkFh+/GUKhDFI3HkZaiQKM36CY\nSmFIuwCxABKM8yzZiOvGx24k4A0QjUeJxWNE49HxeSdKTE+cOtrhrOVnceX6Kzmv/jwMJfWCYmlS\nSlFR4tZhz/SseVI4mM1nYwAAFVJJREFU5vBo2zMMhMY4vXwbEcchEnMfU4vE4kQT00gsnloXceJE\nY3EGxqJ0DIY4ORDiT0d6OTkYwkl7Ph3c3HhDhY/6Cjc4D/aEua/7OcaijvuKjE9DUYfR5HIiCM//\nGsCy0vFSgNpyL7UBb+KRvvH55eXeCY0N56K1+7RAJBYnHIsTc+KQKKUwEjcHhpE2rybNyw3Ci4YE\n4zzbsmwL6yvXs7dnL7ZhYxnW1Klp41VebK+dWhfXcXa27eQ3h39DQ2kDrz/t9Vy1/irWBJZOL2NC\nZOuew7/my49/mZiOceHKC/noOR9lY/XGeZ3LiWu6h8N0DIQ4OTDGif4QJwdDqeU/H+mlbzhGoL8L\nv8fEZ5v4bYMSj0VViQe/Z3zZ3Wbi97jF5MCU1vTJRnXxtHlw69MjTpzuRIlAcCjMgZODdA9Hptws\nAAR8FrUBH9UlHhytUzcf4ZiTuvkIp92Q6KmnyIqhwFJQsut3+CwTr23gs0x8toE3uWybeK2JUzvR\nwY5pKHdqJqbGpPWG+1SDaRiU2CalXotyn0WZ16IsMfVaxoKqGCKxeOomajQSI65xqzMshWUYqflk\nml+M1RkSjPOsxC7hrqvumtexoViInW07ufvQ3fznnv/kP3b/Ryq3/Lq1ryPgCcw7XREnwqH+Q7T0\ntWAqkw1VG1hXsa6oOycR+ePEHb7+5Nf5+f6fc+HKC3lZ/cv44e4fcvVvrub1p72eD5z9AVaUrZj7\nRGlMQ1EX8FEX8MGkuvmkU1VUPx0nrukdiRAcChEcCtM1GE7NBwfD9I5G8JoG5T4rUT9u4knUjyfr\ny5PL6fXqyRuEeNxtRBfXOvEabw/gxNPWxTWHjrRS27CCUNQhHIsTijqEou4NwFAoRvdwhHDUmbA9\nGnef45/uhiJbtqnSgrNNeWK+1OuGILfEIuaWVKSVXiTnY1mmwTbHA3Oy3UEsEqbi6YfxmAZe25hy\nrb1p1z+5vtRr8f5L1y/482dCgvES5rN8XL7uci5fdznB0SD/c/h/uPvQ3dz42I189c9f5ZWNr+TK\n9VdyQcMFmMbMRV/9oX6e73ueA70HeL73eQ70HeBI/xFiOjZhP0MZNJY3sr5yPadXns76yvWsr1zP\n2sBabNPO98cVBWo4Mswndn2CPxz/A28/4+18fPvHsQyLN214E/+55z/5xb5fcP/R+7l207Vcv+16\nKn3TB9YXG9NQqQZsWxY5Lc3NHezYsXVex6Z3rjNxGnenzvjyWCTOUDjKcCjGcNh9DSXnQ+nLUbqG\nwhzuGkYplSiVMCnzWtSUeSnxmKl14/MWfttdVgpiTqKzn7gmmqjiSBbpT5l3NMdOnKB6WTnhmJMq\neRgOx+gZHq8SSZVOJKoFJBiLKWpLavlfW/8X79ryLvb27OXuQ3dz75F7ue/ofdT6a/mr0/+KK/9/\ne+ceHNdd3fHP2Yce1mP1WMl6WdJKtmXJkkdSHRknIbgkboAQAkwwDe6EgJPwRxPCMBPadAaawnSm\npaVAJkwYOibEcagRxBBPYEgTbKcwCZbjR1BkRbKe1sOSrPeutJL28esfd/dasiVbdmStrP19Znbu\nc3fPnj33fu/v9zv33KJPMegb5I3ON+YIb99E38XPic+kJK2EHXk7KEkroSS1hIAK0DLaQstoC62j\nrbSMtnC06ygBFQDAJjbyk/MpTilmQ8oGilOKqV5bjTPeuZC5Gg0A3e5uHj/8OO1j7XzzQ99kV8ku\nc5sj1sHX/+rrfGHTF/jR6R/x4pkX+fXZX7OnYg+7S3cTZ4uLoOWaMLOL69zMHD06zI4d1df0nuAS\n9AosFi3GNxkiQrmznHJnOU/e8iRvdr/JKy2vsK9hH8+/97yxU6/RynUlu6jOrGZT2iZTeNPj5y83\nWZxSzN3cbS7PBGZoH2s3xblltIWm4Sbe6HwDhcJusfPZDZ/ly+VfvubuxZsdpRQn+k9wpOsIRY4i\nqjKrcDlcN+U41Y3kZP9Jvnbka/iVnx/v/DEfyv7QvPtlJWTxndu+w4NlD/LDkz/kByd/wM/f/zmP\nVT7Gp4o/dcVen2hCKUXvRC9pcWnE21ZW6d/VynImwGkxvomJscaws2AnOwt2Mugd5PXO12k728Z9\n2+9jfcr6D9SyiLHGGAJ+SXKN1++ldbSVg2cPcvDsQV5ufplPFn+ShyseXvXJZUop3ux+k731ezl9\n4TRWsZq9B45YB5UZlVRmVlKVWUW5szyqx98PtR7i6beeJicxh2c/+iyFjsKrvmdD6gaevfNZjvcd\n5/snvs+33voW+87s44nqJ/hI3kei9mJnwjfBq62vUttcS/NIM4KQl5Q3Zyhpfcp6XA4XMdaYSJur\nuU60GK8SnPFOHtj0AEf7jlLuvL6xocUQb4s3W+aPbnmUFxpe4JfNv+RQ6yHuLrybRyoeYUPqhhv2\n/ZHAH/Tz+47fs7d+Ly2jLWQnZPNUzVN8ZsNn6Jvo4/TAaU4NnOLUwCne7H4TALvFTll6GVWZVaZA\np8WlLZvNU/4pvEEvXr8Xm8WGTZanGlZQBXnm5DPsfW8v27K28b0d38MR67j6G2dxS9YtvPSJl3i9\n83WeOfUMjx9+nOrMah7a/BDFKcXkJOZgs9yYU9d0YJrpwPQHSo5cKt4ffp/aplp+2/ZbJv2TlKaV\n8o1bvsGEb8IcUvpT95/M3A+rWM2cj/Wp681hpfzk/Aj/kuVDKcXI9Aid4510jHXQMd5B53gnneOd\njHpG2f/afnISc8hJzCE3MdecZsRnRLwHRtQHzZu/TrZu3areeeedJfu8SGZNriQi4YdB7yAvnnmR\nA+8fYNI/yZ35d/LIlkfYnH59aSsDkwPUD9bz3uB7DEwOkGBPICkmieSYZBLtiSTFJF3+sieZSWZL\n5YPpwDS/Ofsbnm94nh5PD8WOYvZU7OFjro9ht8yf0DYyNTJHnBuGGvAFjUIXBckFVGZUstm5mbL0\nMjamblyy7sb+iX5ODZzi5MBJTg+cpmmkiaCae9+sTWyGMF/6Cq23W+24kl1sy97GLVm3UJhceE0C\nPumb5Kk/PsXhrsN8buPneGrbUwv6abH4gj4ONh/kuXefY2hqyPwduUm55CflU5BcQH5yPgVJxjQ7\nIXvOSfXSWPAFffRN9NHr6aXH00O3u5seT4+5fMF7ATDqA2zP3s72nO1Ur61etm7hKf8Ur3W8Rm1T\nLX8Z/Aux1lg+7vo4uzbuotxZftn/4Qv46BzvNIeSwiJ9zn3O/P9tFhtOq5Py7HJcDhdFKUW4HC5c\nyS7W2Ncsy+8KMzY9Rsd4xxyhnAnMkBiTSJLdOJYTYxLN43z28R6ej7fF4/V7Oec+Z3zGWKf5WR3j\nHbhn3Ob32Sw21iWtoyC5gPGhcQIJAXo9veb/bO4nNrISsuYIdHhalVm1ZBeyInJCKbV13m1ajFcX\nkfTD2PQY+xv381LjS7hn3Nyeeztf2fIVKjMrF3yPZ8ZDw1CDKb71g/UMTA4AxgGSsSaDCd8EHp/n\nMnG5lDhrHIkxicT4Y6heV01Jagkb0zZecax8Ptwzbn7R9Av2n9nP0NQQW5xb2FOxhx3rdlxz8ZXp\nwDRnhs6Y4vzuwLuMTI8Axrh+kaOIsvQyStNKKU0vZVPaJhLsV36IRfixnLPFt8dj1LyOt8WzJWML\nlRmVDHQNUFhUaBaT8QcvvsIFZ/xBv7ltOjBN41Aj/ZP9gJHsV5NdQ01WDTXZNeQm5i5oU99EH48f\nfpzmkWae3Poku0t3L2lL3Ov30jjUSOd4J+fc54zp+DnOuc/h9XvN/ewWO3lJeaY4X+i5QIwzht6J\nXnrcPfRP9ptDC2D8B1lrsshNyjVPwBYs1PXVcWrgFL6gD7vFTlVmFdtztrM9ezub0jYteSuqfayd\n2qZaDrUeYnxmHJfDxa6Nu7i3+N5r7lkAI+7ax9o5O3KW1tFW6lrrcNvddLm75vz+7IRsihwhcXa4\nKHIUUZRSRGps6nX/f/6gnx5Pjym47WPttI+10zHewfDUsLmfTWzkJeURb4tnfGYcj8+DZ8Yzx775\nmD08FCYrIYuC5AIKkwspTC4057MTs81elNnnxunANOc95+nx9JgXY72eXnomjPlB7yAASfYk3vrC\nW9flh/nQYhxFrAQ/hMVsX8M+RqZHqMmq4dEtj1KdWU3zSDP1g/Wm+LaPtaNCzybKT8qn3FnOlowt\nlDvL2ZS2yRx3Daogk75JPD6PceDOeHDPuM2D2D3jxjNjbGvsbmRIhkxRAaMbP5zEVpJqjIUXJBfM\n6e4c8g6xv3E/B94/gMfn4dacW3m44mG2rt26ZMKilKJvoo8zw2doHGqkcbiRM0NnzINfEAqSCyhN\nL2Vz+mZK00opSimic7zTFPRTA6fMq39nvJOqzCqqM6upWltFSWrJvCefa7Gvy93Fsb5j1J2vo66v\nzjyB5ibmmq3mmqwaMtdkAlB/oZ6vHvkqXr+X/7jjP/hw3oeXxFeLtfeC94Ipzp3u0HS8ky53F9OB\naTLiM8hNzCU3KZechBzykvKM5cRc1iasXbD17vV7Odl/krd73+bt82+bT19zxDqoyaoxxTkvKe+6\nbPcFfBzuOkxtUy11fXXYLDbuyr+LXSW7ljTm4GIs+AI+zrnP0TbWRttoG21jbaZQzr6occQ6SLQn\nYhELVrFiEcuceatYsVjmLosIA5MDdLm78Acv3jaZFpdmiKSjEFeyi0KHIZi5SbmX+V4phdfvNY9p\n94zbFOnZgh1nizMFNz85f1E9F9dyPEz5pzg/cZ7R6VGqMqsW5+RFoMU4ilhJfpj0TfKr5l/xs4af\nccF7AZvYzPGttLg0KpwVlDvLzen1tADmI+yD8P3VTcNN5rR1rNU8UcRaY1mfsp6StBIE4dW2V5kJ\nzHBXwV3sqdhz3d3s18OFyQs0DjfSMNRgivTsW9LChLO3wwKcl5S34El7KWJBKUXraKspzsf7j5sX\nAi6HiwpnBa91vIYz3smzH32W9anLc0/mYgiqIH84+gd2/vXOJfm8Qe8gx84fM8U53IOTl5hHZWYl\nFrGYvQ0BFbi8J0L5CQQvrh+cGmRseozcxFzu33g/n17/6Rt2u+DVYiGogvRN9Jki3TneidfvJaAC\nBFVw/mkweNm69Lh0XI6LgutyuJbsuP6grIRz45XEWCdwaW4Ya+xreHDzg3x+0+d5peUVuj3dbE7f\nTIWzguyE7BueUJQSl8K27G1sy95mrvMFfLSNtc0R6SPnjuD2ubm36F6+VP4lXA7XDbVrPjLWZJCx\nJoM78u4w1w1PDdM41EjLaAv5SflUZlaSGpe6rHaJCOtTjYSg3aW7CQQDNI00UXe+jmN9x3ij8w0q\nMyr57ke+u6wJaovBIhbssnTFapzxTu4puod7iu5BKUX7eDtv977Nn3v/zPG+41jEctlYvN1ix2qx\nYrPYiJXYOdvLbeXcXXg3t+bcGvHkIYtYzMSm23Nvj6gt0YoWY80NJ9YaO6fYQySxW+0Xb9kqNtYp\npfAr/wdONlpq0uLSuC33Nm7LvS3SpphYLVbK0ssoSy/jofKHovbRoCJijK86ithdujvS5mhWAVqM\nNVGPiCxpCyqaiEYh1mhuBPq5fBqNRqPRRBgtxhqNRqPRRJhFibGIfExEmkSkRUT+cZ7tsSLyi9D2\nYyJSuNSGajQajUazWrmqGIuIFfgR8HGgDHhARMou2W0PMKKUWg98H/j3pTZUo9FoNJrVymJaxjVA\ni1KqTSk1AxwA7rtkn/uAF0LzvwLuFJ3ZodFoNBrNolhMNnUu0DVruRvYttA+Sim/iIwB6cDgUhh5\nNf5Y20x7fZCREyeX4+tWNKOj2g/aBwbaD9oHYbQfrs8HznWJfHjXxhtk0VyW9dYmEXkUeDS06BGR\npiX8eCfLJP4rHO0H7YMw2g/aB2G0H67XB59fUhsWfM7sYsS4B1g3azkvtG6+fbpFxAY4gKFLP0gp\n9RPgJ4v4zmtGRN5ZqMxYNKH9oH0QRvtB+yCM9sPK98FixoyPAxtExCUiMcDfAocu2ecQ8MXQ/P3A\nYRWpotcajUaj0dxkXLVlHBoDfgx4DbACP1VKNYjIt4F3lFKHgL3AiyLSAgxjCLZGo9FoNJpFsKgx\nY6XU74DfXbLuW7Pmp4DPLa1p18wN6f6+CdF+0D4Io/2gfRBG+2GF+yBij1DUaDQajUZjoMthajQa\njUYTYVaFGF+tXGc0ICIdIlIvIqdF5J1I27NciMhPRWRARN6btS5NRF4XkbOh6fI+BHiZWcAHT4tI\nTygeTovIJyJp43IgIutE5IiInBGRBhF5IrQ+auLhCj6IqngQkTgRqRORd0N++JfQeleoZHNLqIRz\nTKRtDXPTd1OHynU2AzsxCpIcBx5QSp2JqGHLjIh0AFuVUlF1L6GI3AF4gH1KqfLQuu8Cw0qpfwtd\nnKUqpf4hknbeSBbwwdOARyn1n5G0bTkRkWwgWyl1UkSSgBPAp4GHiJJ4uIIPdhFF8RCqAJmglPKI\niB34E/AE8HXgoFLqgIj8GHhXKfVcJG0Nsxpaxosp16lZpSil/g8jg382s8uzvoBxMlq1LOCDqEMp\ndV4pdTI07wYaMaoDRk08XMEHUYUy8IQW7aGXAj6KUbIZVlgsrAYxnq9cZ9QFH0ag/a+InAhVOotm\n1iqlzofm+4C1kTQmgjwmIn8JdWOv2q7Z+Qg9Oa4KOEaUxsMlPoAoiwcRsYrIaWAAeB1oBUaVUv7Q\nLitKK1aDGGsMbldKVWM8XevvQ12XUU+o+MzNPRZzfTwHFAOVwHnge5E1Z/kQkUTgZeBrSqnx2dui\nJR7m8UHUxYNSKqCUqsSoGlkDbIqwSVdkNYjxYsp1rnqUUj2h6QDwa4zgi1b6Q2Nn4TG0gQjbs+wo\npfpDJ6Mg8N9ESTyExgdfBl5SSh0MrY6qeJjPB9EaDwBKqVHgCLAdSAmVbIYVphWrQYwXU65zVSMi\nCaFkDUQkAfgb4L0rv2tVM7s86xeBVyJoS0QIi0+IzxAF8RBK2tkLNCql/mvWpqiJh4V8EG3xICIZ\nIpISmo/HSPBtxBDl+0O7rahYuOmzqQFCafo/4GK5zn+NsEnLiogUYbSGwaiq9vNo8YGI/A+wA+OJ\nLP3APwO/AWqBfKAT2KWUWrUJTgv4YAdGl6QCOoCvzBo3XZWIyO3AH4F6IBha/U8YY6ZREQ9X8MED\nRFE8iMgWjAQtK0ajs1Yp9e3QufIAkAacAv5OKTUdOUsvsirEWKPRaDSam5nV0E2t0Wg0Gs1NjRZj\njUaj0WgijBZjjUaj0WgijBZjjUaj0WgijBZjjUaj0WgijBZjjUaj0WgijBZjjUaj0WgijBZjjUaj\n0WgizP8DqtNtdQTkdkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the vertical range to [0-2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EgEfynQhAzcT",
    "outputId": "b70f38bc-69e2-49b5-c445-ee0e6aaf67f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_crnn = model_crnn.predict_classes(X_train_crnn)\n",
    "model_pred_crnn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uG_YRwVmAWQo",
    "outputId": "7d2845bb-d2b1-4d7b-f63f-824553229630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_crnn_cv = model_crnn.predict_classes(X_valid_crnn)\n",
    "model_pred_crnn_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CV5MTwGOAWNt",
    "outputId": "3b215acc-ab6a-4d3a-9879-deabda9fbd0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert the training labels back to single digits rather than one hot encoding\n",
    "\n",
    "rounded_labels_crnn=np.argmax(y_train_crnn, axis=1)\n",
    "rounded_labels_crnn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EyyqiqBcAWLI",
    "outputId": "5d86a315-5fd1-4def-bbf0-fc6fa07983cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert the cross-val labels back to single digits rather than one hot encoding\n",
    "\n",
    "rounded_labels_crnn_cv=np.argmax(y_valid_crnn, axis=1)\n",
    "rounded_labels_crnn_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MuoMbut8AWH5",
    "outputId": "0426e8e2-f7d9-4d52-d37e-b94b8619f4ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9962222222222222\n",
      "Cross-Val Accuracy: 0.9906666666666667\n"
     ]
    }
   ],
   "source": [
    "## Comparing accuracy scores from training data and cross-val data\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_acc_crnn = accuracy_score(rounded_labels_crnn, model_pred_crnn)\n",
    "model_acc_crnn_cv = accuracy_score(rounded_labels_crnn_cv, model_pred_crnn_cv)\n",
    "\n",
    "print(\"Training Accuracy:\", model_acc_crnn)\n",
    "print(\"Cross-Val Accuracy:\", model_acc_crnn_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbxSoXZSncxe"
   },
   "source": [
    "The results from the training data would suggest that the CRNN model would perform slightly better on the test dataset than the CNN model. However, due to the larger difference between the normal model accuracy (0.9962) and the cross-validation model accuracy (0.9907), the CNN actually performs slightly better. This score was achieved over 32 epochs and a higher batch size of 512. This increased batch size may be the reason why this model has not performed as well, however, due to time and power constraints it would have taken too long to train such a model with a smaller batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FopPiiBUAWE-",
    "outputId": "b6ba063b-cdd1-4d28-ab16-819a0584ad02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5373,   18,    3,    0,    0,    0,    0,    0,    6,    0],\n",
       "       [  30, 5360,    3,    2,    0,    0,    0,    1,    1,    3],\n",
       "       [   0,    0, 5399,    1,    0,    0,    0,    0,    0,    0],\n",
       "       [   3,    0,    5, 5379,    1,    0,    1,   11,    0,    0],\n",
       "       [   0,    0,    1,    0, 5393,    3,    0,    0,    3,    0],\n",
       "       [   0,    0,    0,    1,    0, 5399,    0,    0,    0,    0],\n",
       "       [   0,    0,    2,    0,    0,    0, 5355,   34,    1,    8],\n",
       "       [   1,    1,    1,    7,    0,    0,    9, 5381,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0, 5398,    2],\n",
       "       [   0,    0,    1,    0,    0,    0,   39,    1,    0, 5359]])"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Implementing confusion matrix to evaluate the classified digits in the training data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_crnn_cm = confusion_matrix(rounded_labels_crnn, model_pred_crnn)\n",
    "model_crnn_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "RaM_RQFtAWBJ",
    "outputId": "02119d8b-c7ff-4a33-9dfd-07a835c12332"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEcCAYAAAAPyOtuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZ/UlEQVR4nO3debRcZZ3u8e+TgSEMgRBAkgDBVkCa\nCwSDIFMjoJfJoW1aQOgLqDeiCKj0tdGmG0VwOWC3LgcUsBUFggg4AQqIIKAMCYNMAUFAEJImgMzY\nkOR3/3jfE3aKM1S9qV3DyfNZKyun9virqr2fevesiMDMrMSYbhdgZv3LAWJmxRwgZlbMAWJmxRwg\nZlbMAWJmxUZVgEhaVdLPJT0t6UfLMZ2DJV3Wztq6QdIvJB3a7TqseyR9StIZdU2/KwEi6b2S5kp6\nTtL8vKDv3IZJ7w+sD6wTEf9YOpGIODsi3taGepYhaTdJIenHDd23zt2vanI6n5Z01kjDRcTeEXFm\nQZ2HSbq21fE6TdJVkv6al6PHJV0oaYNu19UuzX7PleF3k/TnareI+FxEfKD91SUdDxBJHwe+AnyO\ntLJvBHwTeGcbJr8x8IeIWNSGadVlIfBmSetUuh0K/KFdM1AyqlqXw/hIRKwOvA5YHTil3TOQNK7d\n0xw1IqJj/4CJwHPAPw4zzMqkgHk0//sKsHLutxvwZ+BY4DFgPnB47vcZ4CXg5TyP9wOfBs6qTHs6\nEMC4/Pow4H7gWeAB4OBK92sr4+0IzAGezv/vWOl3FfBZ4Ld5OpcBk4d4bwP1fws4MncbCzwC/Dtw\nVWXYrwIPA88ANwG75O57NbzP31fqODnX8SJphboK+EDufypwQWX6XwCuADRInY3v/0Hg/wG3Ac8D\n3yGF/y/ye/4VsHZl+B8BC/LndTXwt5V+6wA/z+9rDnBSw7w2By4HngTuAd4zzLKy9P3l1x8G7mxm\nWsD38vdweX4PvwE2rvQP4EjgXuCB3G0/4FbgKeB3wFaV4f8lf4/P5nntkbuPAY4D/gg8AZwHTGpY\nHg8FHgIeB/51hO/5cGBens/9wAdz99Xy974kD/8cMIVXrwPvAO7M7+Eq4A0N3/M/5+/5aeCHwCrD\nrtMdDpC9gEXkFXiIYU4ErgfWA9bNX9RnKyvgojzMeGAf4AXywjvIh9X4euALG5c/8GeAzXK/DcgL\nOpUVCJgE/AX4pzzeQfn1OpWF+I/ApsCq+fXnRwiQHYEbcrd9gEuBD7BsgBxCWtnGkQJzwcCX2fi+\nKnU8BPxtHmc8ywbIBFIr5zBgF9LCOm2IOpe+/8qCdT0pNKaSwvtmYAawCvBr4ITK8O8D1uCVH4Nb\nK/3Ozf8mAFuQQnLgs14tvz48v4cZuc4tRgqQ/Fn9CvhpM9MiBcizwK65zq82vOcghcuk/L3OyO97\ne1LoH5o/l5WBzfK8plSWs7/Jfx+TP7tpedhvA7MblsfT8zy2Bv6HvFIP8T3vC/wNIODvSMv/ttXl\nq2H4pdMgLaPPA28lLR+fAO4DVqp8zzeSgmcSKaiO6KUAORhYMMIwfwT2qbz+38CDlQ/oRSoBlL/U\nHQoD5CngH4BVh1qBSMFxY0P/64DDKgvx8ZV+HwZ+OVyA5L/vzQveuflzWSZABhn3L8DWIwTIiUOt\nYPn19qRf4z8BBw0zr6Xvv7JgHVx5fQFwauX1UcBPhpjWWvkzn0ha8V4mh3buv7QFAhwAXNMw/rep\nhNMg7+8F0q9lkFoHGzUzLVKAnFvptzqwGNgwvw5g90r/U8k/ZJVu95BW4teRlsM9gfENw8wjt0by\n6w3yZzCusjxOq/S/EThwqO95kM/gJ8AxjcvXYOsA8G/AeZV+Y0itpt0q3/Mhlf5fBL413Pw7vZ38\nBDB5hG3KKaQFfMCfcrel04hl93G8QPryWxIRz5MWsiOA+ZIulrR5E/UM1DS18npBQT0/AD4CvAX4\ncWNPSf8saV4+ovQUaQWcPMI0Hx6uZ0TcQGr2itSUbsV/V/5+cZDXq+e6x0r6vKQ/SnqGtFBCqn1d\n0opTrbP698bA9pKeGvhHCtfXDFPX0RExEdgKWJv0S9/stJbOOyKeI4XrlMH65+kd2zC9DUmtjvuA\nj5JW1scknStpSmW8H1fGmUcKqvUr0256+ZG0t6TrJT2Zp7cPIy8XA5ZZliNiSX6PxctypwPkOlIT\n7V3DDPMo6UMfsFHuVuJ5UlN5wDILYkRcGhFvJf0q3E1qSo5Uz0BNjxTWNOAHpNbKJRHxQrWHpF1I\nzcv3kDbP1iL9ymqg9CGmOVT3gekeSWpGP5qnX4f3knaI70kKvekDsyftQF7EKys5pJVwwMPAbyJi\nrcq/1SPiQyPNNCJuJ7VmviFJTU5r6bwlrU5qtleXtern+TBwcsP0JkTE7Dz/cyJiZ9KyEqR9TAPj\n7d0w3ioR0czys8z3KWllUuvvFGD9vFxcwsjLxYBlluX8OW3IcizLHQ2QiHiatLPwG5LeJWmCpPE5\nVb+YB5sNHC9pXUmT8/BNH8pqcCuwq6SNJE0EPjnQQ9L6kt4paTVSqD1H2gHV6BJg03zoeZykA0jb\n7hcV1gRARDxAav7+6yC91yCtaAuBcZL+HViz0v+/gemtHGmRtClpBTuEtFn2CUnbFJY/nDVIn+cT\npPD+3ECPiFgMXAh8On/3mwP/pzLuRaTP+p/ycjFe0naS3tDkvM8k/bK/o8lp7SNpZ0krkXaEXx8R\nQ7XiTgeOkLR9Psq1mqR9Ja0haTNJu+cV/K+8sjMT0o7akyVtDJCX62aPODZ+zyuRfgAWAosk7Q28\nrWH4dfKyPpjzgH0l7SFpPGnf2v+Q9jMW6fihvoj4MvBx4HjSB/EwqSn/kzzIScBc0p7g20k7604q\nnNflpD3Jt5GOZFRX+jG5jkdJTde/A171SxcRT5D2vh9LWik+AewXEY+X1NQw7WsjYrDW1aXAL0k7\nPf9EWiirC/bASXJPSLp5pPnkTcazgC9ExO8j4l7gU8AP8kLfTt/PNT8C3EXagVj1EVLLZAGpFTab\ntBATEc+SVogDSd/LAtIveVM1RsRLpJ2h/9bktM4BTiB9/28khetQ054L/F/g66T9UfeR9hWRp/l5\n0k7aBaQDAAM/Vl8FfgZcJunZ/Hls38z7oeF7zu/paFIQ/IXU2vtZpca7SZ/n/XmTqbo5RkTck9/j\n13Ktbwfenj+3Iso7S8y6QtIXgNdExKEdnu/3SDscj+/kfEebFeVkI+sRkjaXtFXeDHgT6XydV+1E\ntv7gM+ys09YgNbOnkLbZvwz8tKsVWTFvwphZMW/CmFkxB4iZFeu7AJG0l6R7JN0n6bhu1zMSSRtK\nulLSXZLulHRMt2tqRj6j9BZJy3W+S6dIWkvS+ZLuzmfwvrnbNY1E0sfyMnGHpNmSVul2Ta3qqwCR\nNBb4BrA36WSugyRt0d2qRrQIODYitgB2AI7sg5ohXQQ2r9tFtOCrpGuQNiddlNbTtUuaSjqnY2ZE\nbEm6TujA7lbVur4KEOBNwH0RcX8++eVc2nMfkdpExPyIuDn//SxpwZ46/FjdJWka6arP2u5k1U75\nzMtdSbcZICJeioinultVU8YBq+YT/SZQfslG1/RbgExl2TMy/0yPr4xVkqaTLgu/obuVjOgrpDNu\nBzu1vxdtQjqr+bt5s+uMfIlCz8rXwpxCugXDfODpiOi722j2W4D0rXyx1gXARyPimW7XMxRJ+wGP\nRcRN3a6lBeOAbUm3GJhBuoiyp/ePSVqb1HrehHROzGqShjyVvlf1W4A8wrJXb05j+a+KrV2+cOkC\n4OyIuLDb9YxgJ+Adkh4kbSLurhbuy9klfyadlj7QsjufFCi9bE/Snc4WRsTLpIsMd+xyTS3rtwCZ\nA7xe0ib5CsoDqVxM1IvyJdPfAeZFxH90u56RRMQnI2JaREwnfb6/joie/mWMiAXAw5I2y532IF3I\n18seAnbIVyWLVHNP7/gdTF+dyh4RiyR9hHS16ljgvyLizi6XNZKdSJfP3y7p1tztUxFxSRdrGo2O\nAs7OPyz3k25l2LMi4gZJ55OuNl8E3AKc1t2qWudT2c2sWL9twphZD3GAmFkxB4iZFXOAmFkxB4iZ\nFevbAJE0q9s1tKLf6gXX3An9Vm+jvg0QoN8++H6rF1xzJ/Rbvcvo5wAxsy7rqRPJJk+eHNOnT29q\n2IULF7Luuus2NexNN/XTdWFm3RERGnmoZfXUqezTp09nzpw5bZ/umDFuaJnVwWuWmRVzgJhZMQeI\nmRVzgJhZMQeImRWrNUD67RkuZtaa2gKkT5/hYmYtqLMF0nfPcDGz1tQZIH39DBczG1nXd6JKmiVp\nrqS5Cxcu7HY5ZtaCOgOkqWe4RMRpETEzImY2e22LmfWGOgOk757hYmatqe1iuj59houZtaDWq3Hz\nw5P8ACWzUarrO1HNrH85QMysmAPEzIo5QMysmAPEzIr11E2VJYXU8n1dR7R48eK2T3OA77dqo0XJ\nTZW99JtZMQeImRVzgJhZMQeImRVzgJhZMQeImRVzgJhZMQeImRVzgJhZMQeImRVzgJhZMQeImRVz\ngJhZMQeImRVzgJhZMQeImRVzgJhZMQeImRVzgJhZMQeImRVzgJhZMQeImRWr9eHaJep4zESdj16o\n67EYdTzewqzd3AIxs2IOEDMr5gAxs2IOEDMr5gAxs2IOEDMr5gAxs2K1BYikDSVdKekuSXdKOqau\neZlZd6jGE6E2ADaIiJslrQHcBLwrIu4aZpx6iqmRTySz0SIiWl7oamuBRMT8iLg5//0sMA+YWtf8\nzKzzOnIqu6TpwAzghkH6zQJmdaIOM2uv2jZhls5AWh34DXByRFw4wrDehMm8CWOd1lObMACSxgMX\nAGePFB5m1n/q3Ikq4EzgyYj4aJPjuAWSuQVinVbSAqkzQHYGrgFuB5bkzp+KiEuGGccBkjlArNN6\nKkBKOEBe4QCxTuu5fSBmNro5QMysmAPEzIo5QMysmAPEzIr13F3Z+01dR0vqPDrmIzzWLm6BmFkx\nB4iZFXOAmFkxB4iZFXOAmFkxB4iZFXOAmFkxB4iZFXOAmFkxB4iZFXOAmFkxB4iZFWspQCStLWmr\nuooxs/4yYoBIukrSmpImATcDp0v6j/pLM7Ne10wLZGJEPAO8G/h+RGwP7FlvWWbWD5oJkHH5Qdnv\nAS6quR4z6yPNBMiJwKXAfRExR9JrgXvrLcvM+oGfC9OjfEcy67SS58IMeUtDSV8DhlyKI+LoVmdm\nZqPLcPdEnduxKsysLzW9CSNpQkS8UGsx3oRZypsw1mm1PNpS0psl3QXcnV9vLembBfWZ2SgzYgtE\n0g3A/sDPImJG7nZHRGzZ9mLcAukIPxDcBlPbw7Uj4uGGTotbnZGZjT7NPFjqYUk7AiFpPHAMMK/e\nssysHzTTAjkCOBKYCjwKbJNfm9kKzieSrYC8D8QGU9dRmNdK+rmkhZIek/TTfDq7ma3gmtmEOQc4\nD9gAmAL8CJhdZ1Fm1h+aOYx7W0Rs1dDt9xGxdduL8SZMR3gTxgbT7mthJuU/fyHpOOBc0rUxBwCX\nNDsDSWNJp8U/EhH7tVqgmfWuIVsgkh4gBcZgqRQR0dR+EEkfB2YCa44UIG6BdIZbIDaYtrZAImKT\n5SsHJE0D9gVOBj6+vNMzs97SzIlkSNoS2AJYZaBbRHy/iVG/AnwCWGOYac8CZjVTh5n1lhEDRNIJ\nwG6kALkE2Bu4Fhg2QCTtBzwWETdJ2m2o4SLiNOC0PI43Ycz6SDOHcfcH9gAWRMThwNbAxCbG2wl4\nh6QHSTtgd5d0VmmhZtZ7mgmQFyNiCbBI0prAY8CGI40UEZ+MiGkRMR04EPh1RByyXNWaWU9pZh/I\nXElrAacDNwHPAdfVWpWZ9YWWroWRNB1YE3g8Ih5tezHeB9IRPoxrgyk5jFt0MZ2khyJio5ZHHHm6\nDpAOcIDYYGq7odAgvKSYWXGAuKVgZkXPhRGwVm0VmVnfKH0ujJ8ZY2a+I5m1j3fO9rdO7kQ1M3OA\nmFk5B4iZFSs5CgNARBxdS0Vm1jdKj8KYmfkojLWPj8L0t7be0nCApHWBf+HVdyTbvdWZmdno0sxO\n1LNJz8LdBPgM8CAwp8aazKxPNPNcmJsi4o3V58NImhMR27W9GG/C9DVvwvS3WjZhgJfz//Ml7Ut6\nwPakYYY3sxVEMwFykqSJwLHA10g3FPpYrVWZWV/wURhrG2/C9Le6jsJ8l0FOKIuI97U6MzMbXZrZ\nhLmo8vcqwN+T9oOY2Qqu5U0YSWOAayNix7YX402YvuZNmP7Wqcv5Xw+sVzCemY0yzewDeZZl94Es\nIJ2ZamYruBEDJCKGfDC2ma3YRtyEkXRFM93MbMUz3P1AVgEmAJMlrc0rz4JZE5jagdrMrMcNtwnz\nQeCjwBTSM3EHAuQZ4Os112VmfaCZi+mOioivdaQYH8a1QSxevLi2aY8b18ypUK3rpTO8m1XXYdwl\nkpY+SErS2pI+3OqMzGz0aaYFcmtEbNPQ7ZaImNH2YtwCsUG4BdIZdbVAxqpyKqCkscBKrc7IzEaf\nZuL3l8APJX07v/5g7mZmK7hmNmHGALOAPXOny4HTI2JJ24vxJowNwpswnVGyCVNyMd0uwIERcWSr\nM2ti2v33qVvtHCCdUdctDZE0AzgIeA/wAHBhqzMys9FnuDNRNyWFxkHA48APSS2WtzQ78Xz49wxg\nS9IFee+LiOuWq2Iz6xlDbsJIWgJcA7w/Iu7L3e6PiNc2PXHpTOCaiDhD0krAhIh4apjh+6/dZ7Xz\nJkxntPsw7ruB+cCVkk6XtAevnM4+onwj5l2B7+TiXhouPMys/wwZIBHxk4g4ENgcuJJ0Xcx6kk6V\n9LYmpr0JsBD4rqRbJJ0habW2VG1mPWHEE8ki4vmIOCci3g5MA26huRsKjQO2BU7NZ60+DxzXOJCk\nWZLmSvLDvM36TG2PdZD0GuD6iJieX+8CHBcR+w4zTv9tOFrtvA+kMzp1T9SmRMQC4GFJm+VOewB3\n1TU/M+u8euL3FUcBZ+cjMPcDh9c8PzPrID+ZznqeN2E6o6c2Ycxs9HOAmFkxB4iZFXOAmFkxB4iZ\nFXOAmFmxus8DMVtuY8eOrW3aNZ6JXct0e41bIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZW\nzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFi\nZsUcIGZWzHdltxVaXXdPr/Ph2r10x3e3QMysmAPEzIo5QMysmAPEzIo5QMysmAPEzIo5QMysWK0B\nIuljku6UdIek2ZJWqXN+ZtZZtQWIpKnA0cDMiNgSGAscWNf8zKzz6t6EGQesKmkcMAF4tOb5mVkH\n1RYgEfEIcArwEDAfeDoiLmscTtIsSXMlza2rFjOrR52bMGsD7wQ2AaYAq0k6pHG4iDgtImZGxMy6\najGzetS5CbMn8EBELIyIl4ELgR1rnJ+ZdVidAfIQsIOkCUqXD+4BzKtxfmbWYXXuA7kBOB+4Gbg9\nz+u0uuZnZp2nOu9b0CpJvVOM2XLox/uBRETLE/aZqGZWzAFiZsUcIGZWzAFiZsUcIGZWzAFiZsX8\nWAfreXU+xqCuw6111rxkyZK2T3O77bYrGs8tEDMr5gAxs2IOEDMr5gAxs2IOEDMr5gAxs2IOEDMr\n5gAxs2IOEDMr5gAxs2IOEDMr5gAxs2IOEDMr5gAxs2IOEDMr5gAxs2IOEDMr5gAxs2IOEDMr5gAx\ns2IOEDMr1mt3ZX8c+FOTw07Ow/eLfqsXeqTmFu+c3hM1t6DleseMqeV3f+OSkVTnU8TrJGluRMzs\ndh3N6rd6wTV3Qr/V28ibMGZWzAFiZsX6OUBO63YBLVqueiUtlnSrpDsk/UjShOWY1vck7Z//PkPS\nFkMMepqk3STtWDCPByVNbrb7ENM4TNLXW5z19Gan3yP6bTleRt8GSET01QffhnpfjIhtImJL4CXg\niGpPSUU7xCPiAxFx1xD9TgN2A1oOkC56rtsFtKLfluNGfRsgK7hrgNfl1sE1kn4G3CVprKQvSZoj\n6TZJHwRQ8nVJ90j6FbDewIQkXSVpZv57L0k3S/q9pCskTScF1cdy62cXSetKuiDPY46knfK460i6\nTNKdks4Amn44rKQ3SbpO0i2Sfidps0rvDXON90o6oTLOIZJuzHV9W9LYhmmuJuni/F7ukHRAi5+x\nNaHXDuPaCHJLY2/gl7nTtsCWEfGApFnA0xGxnaSVgd9KugyYAWwGbAGsD9wF/FfDdNcFTgd2zdOa\nFBFPSvoW8FxEnJKHOwf4z4i4VtJGwKXAG4ATgGsj4kRJ+wLvb+Ft3Q3sEhGLJO0JfA74h9zvTcCW\nwAvAHEkXA88DBwA7RcTLkr4JHAx8vzLNvYBHI2LfXPfEFuqxJjlA+seqkm7Nf18DfIe0aXFjRDyQ\nu78N2Gpg/wYwEXg9sCswOyIWA49K+vUg098BuHpgWhHx5BB17AlsUXn6/JqSVs/zeHce92JJf2nh\nvU0EzpT0eiCA8ZV+l0fEEwCSLgR2BhYBbyQFCsCqwGMN07wd+LKkLwAXRcQ1LdRjTXKA9I8XI2Kb\naoe88jxf7QQcFRGXNgy3TxvrGAPsEBF/HaSWUp8FroyIv8+bTVdV+jWeqBSk93lmRHxyqAlGxB8k\nbQvsA5wk6YqIOHF5irRX8z6Q0eVS4EOSxgNI2lTSasDVwAF5H8kGwFsGGfd6YFdJm+RxJ+XuzwJr\nVIa7DDhq4IWkgVC7Gnhv7rY3sHYLdU8EHsl/H9bQ762SJklaFXgX8FvgCmB/SesN1CppmTMpJU0B\nXoiIs4AvkTb1rM3cAhldzgCmAzcrNQkWkla6HwO7k/Z9PARc1zhiRCzM+1AulDSGtEnwVuDnwPmS\n3kkKjqOBb0i6jbT8XE3a0foZYLakO4Hf5fkM5TZJS/Lf5wFfJG3CHA9c3DDsjcAFwDTgrIiYC5CH\nvSzX+jJwJMteBvG/gC/l+bwMfGiYeqxQ357Kbmbd500YMyvmADGzYg4QMyvmADGzYg4QMyvmADGz\nYg4QMyvmADGzYv8fd73+bjIXoQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(model_crnn_cm, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix Image Representation\", x=0.5, y=1)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "sHcNAVwx8Ka6",
    "outputId": "f250adcc-dc4f-4bc6-ab7e-79f69be9a9c4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAEcCAYAAACrolO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVkRHGZmVoT/D3JjXl08ULczAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Now lets check where the errors are occuring most\n",
    "\n",
    "row_sums = model_crnn_cm.sum(axis=1, keepdims=True)\n",
    "norm_model_crnn_cm = model_crnn_cm / row_sums\n",
    "\n",
    "## Filling the leading diagonal with zeros to only keep the errors and plot results\n",
    "\n",
    "np.fill_diagonal(norm_model_crnn_cm, 0)\n",
    "plt.matshow(norm_model_crnn_cm, cmap=plt.cm.gray)\n",
    "plt.title(\"Confusion Matrix Image Representation of Errors\", x=0.5, y=1)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IilS8bl88KXg",
    "outputId": "2a6a1fde-f6c3-4c4d-8527-47ca59aee07e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision: 0.996226352060381\n",
      "Training Recall: 0.9962222222222222\n"
     ]
    }
   ],
   "source": [
    "## Comparing precision and recall scores from training data\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Training Precision:\", precision_score(rounded_labels_crnn, model_pred_crnn, average='weighted'))\n",
    "print(\"Training Recall:\", recall_score(rounded_labels_crnn, model_pred_crnn, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQmF7YSQln9x"
   },
   "source": [
    "# 9. Evaluating Our Models on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oS1kr-Yaqla7"
   },
   "source": [
    "# 9.1 Original ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmSTsqTAlXhC"
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "UvdcRFx6m7_f",
    "outputId": "27d41c69-38aa-475c-b9dd-502a3c87cf5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99950033, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.99950033, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.99950033, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.99950033, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.99950033,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8YbobRyKn31j",
    "outputId": "d0362207-7c65-49c9-96bd-a49ae30c8d16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biRswaK_q2az"
   },
   "source": [
    "# 9.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vp11LN76q9Ql"
   },
   "outputs": [],
   "source": [
    "y_test_pred_cnn = model_cnn.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Eu1gzCQIq9N0",
    "outputId": "cbc024cb-3ca2-44bc-9b20-45900dc54c5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_cnn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eCPpCEaEq9K5",
    "outputId": "0efce998-be13-4ec4-e7f1-e97f5c9e5ad2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cnn = model_cnn.predict_classes(X_test_cnn)\n",
    "y_pred_cnn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvpfR4M7toOv"
   },
   "source": [
    "# 9.3 CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NJJE5zwtq6-"
   },
   "outputs": [],
   "source": [
    "y_test_pred_crnn = model_crnn.predict(X_test_crnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "7Lehb7_5trU4",
    "outputId": "dac49452-b4e3-4f75-cc22-5da685031f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9769092e-01, 7.5192272e-04, 4.2705412e-04, 5.9628379e-05,\n",
       "        5.8803329e-07, 9.8773410e-07, 3.7408778e-08, 1.8218140e-07,\n",
       "        1.0685846e-03, 1.3456344e-07],\n",
       "       [1.5012069e-03, 9.9843770e-01, 3.6081539e-07, 5.8547248e-05,\n",
       "        7.3954872e-08, 6.4452166e-07, 8.7789498e-10, 1.4709934e-06,\n",
       "        1.2649532e-08, 5.2620952e-10],\n",
       "       [3.2995806e-10, 5.4812319e-09, 9.9999857e-01, 1.3764516e-06,\n",
       "        3.6379889e-13, 4.8411736e-10, 1.5995593e-09, 1.5664505e-09,\n",
       "        2.1729070e-12, 1.0891378e-12],\n",
       "       [1.7272156e-11, 1.8597663e-11, 2.4999391e-09, 9.9999976e-01,\n",
       "        4.8233792e-11, 2.7806044e-08, 1.3843905e-11, 1.9747050e-07,\n",
       "        2.1284446e-12, 6.8497372e-13],\n",
       "       [3.2020529e-14, 5.6548954e-10, 5.3274388e-11, 1.2260405e-07,\n",
       "        9.9999988e-01, 3.6251052e-08, 1.8134584e-11, 4.8905862e-12,\n",
       "        6.7391337e-09, 2.1046873e-12]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_crnn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7ifxq0mKtrQT",
    "outputId": "ea762d26-26d0-4899-8529-9d2bbb07f645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_crnn = model_crnn.predict_classes(X_test_crnn)\n",
    "y_pred_crnn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5418hcjoXpi"
   },
   "source": [
    "# 10. Creating DataFrames for Our Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_Lll5MGuXzC"
   },
   "source": [
    "# 10.1 Original ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xcm3BDbrnYNP",
    "outputId": "a91a673d-9964-4df4-fae7-b80ea4f09310"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      0\n",
       "1  60002      1\n",
       "2  60003      2\n",
       "3  60004      3\n",
       "4  60005      4"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating columns for submission in pandas dataframe\n",
    "\n",
    "ann_sub = pd.DataFrame({\"id\":mnist_test[\"id\"], \"label\":y_pred})\n",
    "ann_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipNPk1xSujYM"
   },
   "source": [
    "# 10.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "wWb17lWBujxr",
    "outputId": "07f9e3e0-0ed2-43e1-c5a0-208872913894"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      0\n",
       "1  60002      1\n",
       "2  60003      2\n",
       "3  60004      3\n",
       "4  60005      4"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating columns for submission in pandas dataframe\n",
    "\n",
    "cnn_sub = pd.DataFrame({\"id\":mnist_test[\"id\"], \"label\":y_pred_cnn})\n",
    "cnn_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whpVRfndukH9"
   },
   "source": [
    "# 10.3 CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "szohbrUjukcD",
    "outputId": "dc2b1cef-3216-4ac9-8780-3437ba3db928"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      0\n",
       "1  60002      1\n",
       "2  60003      2\n",
       "3  60004      3\n",
       "4  60005      4"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating columns for submission in pandas dataframe\n",
    "\n",
    "crnn_sub = pd.DataFrame({\"id\":mnist_test[\"id\"], \"label\":y_pred_crnn})\n",
    "crnn_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ihA004lpEHy"
   },
   "source": [
    "# 11. Converting our Predictions into CSV Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxsMH5rnvK8m"
   },
   "source": [
    "# 11.1 Original ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4t3QEXJhpDbM"
   },
   "outputs": [],
   "source": [
    "#Converting data frame to csv for submission\n",
    "\n",
    "ann_filename = \"MNIST_ANN_Model_Predictions2.csv\"\n",
    "\n",
    "ann_sub.to_csv(ann_filename, index = False, header = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcYl25tmvPuh"
   },
   "source": [
    "# 11.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCcAnbTVvP4e"
   },
   "outputs": [],
   "source": [
    "#Converting data frame to csv for submission\n",
    "\n",
    "cnn_filename = \"MNIST_CNN_Model_Predictions2.csv\"\n",
    "\n",
    "cnn_sub.to_csv(cnn_filename, index = False, header = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJCkwbYlvQCC"
   },
   "source": [
    "# 11.3 CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lm82mdl1vS6P"
   },
   "outputs": [],
   "source": [
    "#Converting data frame to csv for submission\n",
    "\n",
    "crnn_filename = \"MNIST_CRNN_Model_Predictions2.csv\"\n",
    "\n",
    "crnn_sub.to_csv(crnn_filename, index = False, header = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQxIBoqv4zRq"
   },
   "source": [
    "# 12. Summary of the Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fO36sg-o5CCr"
   },
   "outputs": [],
   "source": [
    "# Comparing all of the models accuracy scores for the training and test data\n",
    "\n",
    "model_performance_acc = pd.DataFrame({'Model': ['Original ANN',\n",
    "                                                 'CNN',\n",
    "                                                 'CRNN'],\n",
    "                                       'Accuracy - Train (Normal)' : [model_acc,\n",
    "                                                model_acc_cnn,\n",
    "                                                model_acc_crnn],\n",
    "                                       'Accuracy - Train (Cross-Val)' : [model_acc_cv,\n",
    "                                                model_acc_cnn_cv,\n",
    "                                                model_acc_crnn_cv],\n",
    "                                        'Accuracy - Test': ['0.89900',\n",
    "                                                        '0.98066',\n",
    "                                                        '0.97466']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "hCJv4tuI5Fm3",
    "outputId": "c3dacac0-8bef-477a-8c54-a14467b7b22d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy - Train (Normal)</th>\n",
       "      <th>Accuracy - Train (Cross-Val)</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original ANN</td>\n",
       "      <td>0.994111</td>\n",
       "      <td>0.963667</td>\n",
       "      <td>0.89900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.994463</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>0.98066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRNN</td>\n",
       "      <td>0.996222</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.97466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  ...  Accuracy - Test\n",
       "0  Original ANN  ...          0.89900\n",
       "1           CNN  ...          0.98066\n",
       "2          CRNN  ...          0.97466\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6Klt-lrRpDd"
   },
   "source": [
    "**Original ANN** - For the orginal ANN model, the two training accuracy scores of 0.9941 and 0.9637 are from the normal model and the cross-validation model, respectively. This shows that the normal training model was much more accurate than the cross-validation model, which suggests overfitting. Furthermore, with reference to the accuracy of the test model (0.8990), this gives further evidence that the model has been overfitting. Despite this, the original ANN model was primarily used as a baseline for our other two models. Therefore, an accuracy close to 90% is a suitable boundary for this specific dataset.\n",
    "\n",
    "**CNN** - With reference to both of our training accuracy scores for the CNN model, these were both very similar with a difference of only 0.0040. This is a major indication that our model has not been susceptible to overfitting the data and can be ready for testing. In addition, our test model gave us an accuracy score of 0.9807. However, even though this is slightly less accurate than our training models, it is highly expected that a test model will be at least slightly less accurate which is the case here. Despite this, our test accuracy is the highest out of our three models and at the moment is within the top 10 submissions on the Kaggle competition page.\n",
    "\n",
    "**CRNN** - As was the case with the CNN model, the training accuracy scores for the normal model (0.9962) and the cross-validation model (0.9907) imply that overfitting of the data was not encountered here. Moreover, as our CRNN model still encorporates a CNN model, we would expect the results to be relatively similar. This is emphasised due to the fact that the accuracy difference between the training scores was 0.0056; only 0.0014 greater than the CNN model. Taking all of this into account, as the difference in scores was slightly greater for this model, this evidently is the reason behind it falling just short of the CNN model test accuracy.\n",
    "\n",
    "**NB**: The test accuracy scores given above are the most accurate for each individual model tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2hfX4PD8VbI"
   },
   "source": [
    "# 13. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Qm7rFElUtVS"
   },
   "source": [
    "In conclusion, we have successfully carried out the predominant aim of the investigation to classify the digits between 0 and 9 of the Kannada MNIST test dataset. This involved taking a training dataset and applying a host of machine learning techniques involving neural networks to achieve a high accuracy for this classification problem. Unlike our first assignment, feature engineering was not necessary for this specific dataset. However, with respect to our CNN and CRNN models, data augmentation was required. This provided the models with more images of each digit and, hence, improved the accuracy of our test scores.\n",
    "\n",
    "The three ML models we chose to use were as follows: An original ANN, a CNN, and a CRNN. The original ANN was crucial as it acted as a starting point to our investigation. This baseline allowed us to compare the test accuracy with more complex models. The CNN gave us the highest test accuracy score of 0.9807. This ended up being much greater than our baseline accuracy of 0.8990. Furthermore, this was also slightly greater than our CRNN model of 0.9747. This shows that convolutional neural networks are essentially needed to achieve high accuracy in tasks such as this. To improve our accuracy, one method we could implement next time could be to add more hidden layers to the CNN model. However, we cannot add too many more otherwise overfitting could occur."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2 - Kannada MNIST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
